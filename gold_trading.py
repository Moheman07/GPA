#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Gold Trading â€“ Technical + Fundamental (News) unified script
ØªØ´ØºÙŠÙ„ Ø¯Ø§Ø®Ù„ GitHub Actions
"""

# --------------------------- IMPORTS ---------------------------
import os
import json
import logging
from datetime import datetime
import pytz

import pandas as pd
import yfinance as yf
import pandas_ta as ta
import requests
from dotenv import load_dotenv
from transformers import pipeline
from tqdm import tqdm

# --------------------------- CONFIG LOADER ---------------------------
DEFAULT_CONFIG = {
    "tickers": {"gold": "XAUUSD=X", "vix": "^VIX", "yield": "^TNX", "eurusd": "EURUSD=X"},
    "period": "2y",
    "interval": "1d",
    "technical": {
        "sma_fast": 50,
        "sma_slow": 200,
        "rsi_length": 14,
        "rsi_upper": 60,
        "rsi_lower": 40,
        "atr_length": 14,
        "atr_multiplier_sl": 1.8,
        "risk_reward_ratio": 2.0,
        "obv_sma": 20,
    },
    "signal_mapping": {"Strong Buy": 4, "Buy": 3, "Neutral": 2, "Sell": 1, "Strong Sell": 0},
    "sentiment": {
        "keywords": (
            "gold OR XAU OR gold price OR gold spot OR gold futures OR "
            "federal reserve OR Fed OR inflation OR CPI OR "
            "interest rates OR non-farm payrolls OR NFP OR geopolitical OR dollar OR DXY"
        ),
        "sources": "reuters,bloomberg,associated-press,the-wall-street-journal",
        "sources_weights": {
            "Reuters": 1.2,
            "Bloomberg": 1.1,
            "Associated Press": 1.0,
            "The Wall Street Journal": 1.3,
        },
        "max_pages": 3,
        "page_size": 100,
        "positive_threshold": 0.30,
        "negative_threshold": -0.30,
    },
    "output": {
        "technical_json": "technical_analysis.json",
        "news_json": "news_analysis.json",
        "combined_json": "combined_signal.json",
        "history_csv": "historical_signals.csv",
    },
    "logging": {"log_file": "gold_trading.log", "level": "INFO"},
    "run_backtest": False,
}


def load_config() -> dict:
    """
    1ï¸âƒ£ ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù config.json Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ÙˆØ¬ÙˆØ¯Ù‹Ø§
    2ï¸âƒ£ Ø¥Ø±Ø¬Ø§Ø¹ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ø¥Ø°Ø§ Ù„Ù… ÙŠÙÙˆØ¬Ø¯ Ø§Ù„Ù…Ù„Ù
    """
    cfg_path = "config.json"
    if os.path.isfile(cfg_path):
        try:
            with open(cfg_path, "r", encoding="utf-8") as f:
                cfg = json.load(f)
            logging.info("ØªÙ… ØªØ­Ù…ÙŠÙ„ config.json")
            # Ø¯Ù…Ø¬ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ù…Ø¹ Ù…Ø§ ØªÙ… Ù‚Ø±Ø§Ø¡ØªÙ‡ Ù„ØªÙØ§Ø¯ÙŠ Ù†Ù‚Øµ Ø§Ù„Ù…ÙØ§ØªÙŠØ­
            merged = DEFAULT_CONFIG.copy()
            merged.update(cfg)
            return merged
        except Exception as e:
            logging.error(f"Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© config.json: {e}")
    return DEFAULT_CONFIG


def setup_logging(cfg: dict) -> None:
    log_file = cfg["logging"]["log_file"]
    level = getattr(logging, cfg["logging"]["level"].upper(), logging.INFO)
    logging.basicConfig(
        filename=log_file,
        level=level,
        format="%(asctime)s %(levelname)s %(message)s",
        datefmt="%Y-%m-%d %H:%M:%S",
    )
    # Ø¥Ø¸Ù‡Ø§Ø± Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø¹Ù„Ù‰ Ø§Ù„Ù€ console ÙÙŠ GitHub Actions
    logging.getLogger().addHandler(logging.StreamHandler())


# --------------------------- MARKET DATA ---------------------------
def download_market_data(tickers: dict, period: str, interval: str) -> pd.DataFrame:
    logging.info("Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø³ÙˆÙ‚ Ù…Ù† Yahoo Finance â€¦")
    data = yf.download(
        list(tickers.values()),
        period=period,
        interval=interval,
        auto_adjust=False,
        threads=True,
        progress=False,
    )
    if data.empty:
        raise ValueError("Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªÙ„Ù…Ø© ÙØ§Ø±ØºØ©.")
    gold_key = ("Close", tickers["gold"])
    data.dropna(subset=[gold_key], inplace=True)
    if data.empty:
        raise ValueError("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ØµØ§Ù„Ø­Ø© Ù„Ù„Ø°Ù‡Ø¨ Ø¨Ø¹Ø¯ Ø§Ù„ØªÙ†Ø¸ÙŠÙ.")
    logging.info(f"ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(data)} ØµÙÙ‹Ø§.")
    return data


# --------------------------- TECHNICAL ---------------------------
def prepare_gold_dataframe(data: pd.DataFrame, cfg: dict) -> pd.DataFrame:
    t = cfg["tickers"]["gold"]
    gold = pd.DataFrame(
        {
            "Open": data[("Open", t)],
            "High": data[("High", t)],
            "Low": data[("Low", t)],
            "Close": data[("Close", t)],
            "Volume": data[("Volume", t)],
        }
    )

    tech_cfg = cfg["technical"]
    gold.ta.sma(length=tech_cfg["sma_fast"], append=True, col_names=("SMA_fast",))
    gold.ta.sma(length=tech_cfg["sma_slow"], append=True, col_names=("SMA_slow",))
    gold.ta.rsi(length=tech_cfg["rsi_length"], append=True)               # RSI_14
    gold.ta.macd(append=True)                                            # MACD_12_26_9, MACDs_12_26_9, MACDh_12_26_9
    gold.ta.bbands(append=True)                                          # BBU_20_2.0, BBM_20_2.0, BBL_20_2.0
    gold.ta.atr(length=tech_cfg["atr_length"], append=True)              # ATRr_14
    gold.ta.obv(append=True)                                             # OBV
    gold["OBV_SMA_20"] = ta.sma(gold["OBV"], length=tech_cfg["obv_sma"])

    # ---------- Pivot points ----------
    gold["Prev_High"] = gold["High"].shift(1)
    gold["Prev_Low"] = gold["Low"].shift(1)
    gold["Prev_Close"] = gold["Close"].shift(1)
    gold["Pivot"] = (gold["Prev_High"] + gold["Prev_Low"] + gold["Prev_Close"]) / 3
    gold["R1"] = 2 * gold["Pivot"] - gold["Prev_Low"]
    gold["S1"] = 2 * gold["Pivot"] - gold["Prev_High"]
    gold["R2"] = gold["Pivot"] + (gold["Prev_High"] - gold["Prev_Low"])
    gold["S2"] = gold["Pivot"] - (gold["Prev_High"] - gold["Prev_Low"])

    gold.dropna(inplace=True)
    logging.info("ØªÙ… Ø­Ø³Ø§Ø¨ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ÙÙ†ÙŠØ©.")
    return gold


def evaluate_technical_signal(row: pd.Series, cfg: dict) -> dict:
    price = row["Close"]
    sma_fast = row["SMA_fast"]
    sma_slow = row["SMA_slow"]
    rsi = row["RSI_14"]
    macd_line = row["MACD_12_26_9"]
    macd_signal = row["MACDs_12_26_9"]
    atr = row["ATRr_14"]
    obv = row["OBV"]
    obv_sma = row["OBV_SMA_20"]
    upper_bb = row.get("BBU_20_2.0")
    lower_bb = row.get("BBL_20_2.0")
    pivot = row["Pivot"]
    r1 = row["R1"]
    s1 = row["S1"]

    # Ø§Ù„Ø§ØªØ¬Ø§Ù‡
    is_uptrend = price > sma_slow and sma_fast > sma_slow
    is_downtrend = price < sma_slow and sma_fast < sma_slow

    # MACD
    macd_bullish = macd_line > macd_signal
    macd_bearish = macd_line < macd_signal

    # RSI
    rsi_up = rsi >= cfg["technical"]["rsi_upper"]
    rsi_down = rsi <= cfg["technical"]["rsi_lower"]

    # OBV
    obv_confirm = obv > obv_sma

    # Bollinger
    price_overbought_bb = price > upper_bb if pd.notna(upper_bb) else False
    price_oversold_bb = price < lower_bb if pd.notna(lower_bb) else False

    # Pivot level checks
    price_above_r1 = price > r1
    price_below_s1 = price < s1

    # Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø¥Ø´Ø§Ø±Ø©
    signal = "Neutral"
    if is_uptrend and macd_bullish and obv_confirm:
        signal = "Buy"
        if not rsi_up and not price_overbought_bb:
            signal = "Strong Buy"
    elif is_downtrend and macd_bearish:
        signal = "Sell"
        if rsi_down:
            signal = "Strong Sell"

    return {
        "signal": signal,
        "price": price,
        "sma_fast": sma_fast,
        "sma_slow": sma_slow,
        "rsi": rsi,
        "rsi_up": rsi_up,
        "rsi_down": rsi_down,
        "macd_bullish": macd_bullish,
        "macd_bearish": macd_bearish,
        "obv_confirm": obv_confirm,
        "price_overbought_bb": price_overbought_bb,
        "price_oversold_bb": price_oversold_bb,
        "price_above_r1": price_above_r1,
        "price_below_s1": price_below_s1,
        "atr": atr,
        "is_uptrend": is_uptrend,
        "is_downtrend": is_downtrend,
    }


def calculate_risk_management(price: float, atr: float, signal: str, cfg: dict) -> dict:
    mult = cfg["technical"]["atr_multiplier_sl"]
    rr = cfg["technical"]["risk_reward_ratio"]
    if signal in ("Buy", "Strong Buy"):
        sl = price - atr * mult
        risk = price - sl
        tp = price + risk * rr
    elif signal in ("Sell", "Strong Sell"):
        sl = price + atr * mult
        risk = sl - price
        tp = price - risk * rr
    else:
        sl, tp = None, None
    return {"stop_loss": round(sl, 2) if sl else None,
            "take_profit": round(tp, 2) if tp else None}


# --------------------------- NEWS & SENTIMENT ---------------------------
def fetch_all_news(cfg: dict) -> list:
    api_key = os.getenv("NEWS_API_KEY")
    if not api_key:
        logging.error("Ù…ØªØºÙŠÙ‘Ø± Ø§Ù„Ø¨ÙŠØ¦Ø© NEWS_API_KEY ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯.")
        return []

    all_articles = []
    for page in range(1, cfg["sentiment"]["max_pages"] + 1):
        params = {
            "q": cfg["sentiment"]["keywords"],
            "sources": cfg["sentiment"]["sources"],
            "language": "en",
            "sortBy": "publishedAt",
            "pageSize": cfg["sentiment"]["page_size"],
            "page": page,
            "apiKey": api_key,
        }

        try:
            resp = requests.get("https://newsapi.org/v2/everything", params=params, timeout=12)
            resp.raise_for_status()
            data = resp.json()
            articles = data.get("articles", [])
            if not articles:
                logging.info(f"Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ù‚Ø§Ù„Ø§Øª ÙÙŠ Ø§Ù„ØµÙØ­Ø© {page}. Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ø¬Ù„Ø¨.")
                break
            for a in articles:
                all_articles.append({
                    "source": a["source"]["name"],
                    "title": a["title"],
                    "description": a["description"] or "",
                    "url": a["url"],
                    "publishedAt": a["publishedAt"]
                })
            logging.info(f"Ø¬Ù„Ø¨ {len(articles)} Ù…Ù‚Ø§Ù„Ø§Øª (ØµÙØ­Ø© {page}).")
        except Exception as e:
            logging.error(f"Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø¬Ù„Ø¨ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± (ØµÙØ­Ø© {page}): {e}")
            break
    return all_articles


def analyze_sentiment(articles: list) -> list:
    if not articles:
        return []

    try:
        pipeline_sent = pipeline("sentiment-analysis", model="ProsusAI/finbert")
    except Exception as e:
        logging.error(f"ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ FinBERT: {e}")
        return articles

    analyzed = []
    for art in tqdm(articles, desc="ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±"):
        text = art["description"] if art["description"] else art["title"]
        if not text:
            continue
        try:
            result = pipeline_sent(text[:512])[0]   # Ù‚Øµ Ø§Ù„Ù†Øµ Ù„ØªØ¬Ù†Ø¨ Ø­Ø¯Ù‘ Ø§Ù„Ø·ÙˆÙ„
            art["sentiment_label"] = result["label"].capitalize()   # Positive/Negative/Neutral
            art["sentiment_score"] = round(float(result["score"]), 4)
            analyzed.append(art)
        except Exception as e:
            logging.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ {art['title']}: {e}")
    logging.info(f"ØªÙ… ØªØ­Ù„ÙŠÙ„ Ù…Ø´Ø§Ø¹Ø± {len(analyzed)} Ù…Ù‚Ø§Ù„Ø§Øª.")
    return analyzed


def compute_weighted_sentiment(articles: list, cfg: dict) -> dict:
    if not articles:
        return {
            "overall_sentiment_score": 0.0,
            "sentiment_label": "Neutral",
            "article_counts": {"positive": 0, "negative": 0, "neutral": 0}
        }

    src_weights = cfg["sentiment"]["sources_weights"]
    total_w = 0.0
    cum_score = 0.0
    counts = {"positive": 0, "negative": 0, "neutral": 0}
    for art in articles:
        label = art.get("sentiment_label", "Neutral").lower()
        score = art.get("sentiment_score", 0.0)
        src_w = src_weights.get(art["source"], 1.0)
        # ÙˆØ²Ù† ÙŠØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ø·ÙˆÙ„ Ø§Ù„Ù†Øµ (ÙƒÙ„ 100 Ø­Ø±Ù â‰ˆ ÙˆØ²Ù† 1)
        length_factor = max(len(art.get("description", "")) or len(art.get("title", "")), 1) / 100.0
        w = src_w * length_factor
        total_w += w
        if label == "positive":
            cum_score += w * score
            counts["positive"] += 1
        elif label == "negative":
            cum_score -= w * score
            counts["negative"] += 1
        else:
            counts["neutral"] += 1

    overall = cum_score / total_w if total_w != 0 else 0.0
    # ØªØµÙ†ÙŠÙ Ù†Ù‡Ø§Ø¦ÙŠ
    pos_th = cfg["sentiment"]["positive_threshold"]
    neg_th = cfg["sentiment"]["negative_threshold"]
    if overall >= pos_th:
        final_label = "Positive"
    elif overall <= neg_th:
        final_label = "Negative"
    else:
        final_label = "Neutral"

    return {
        "overall_sentiment_score": round(overall, 4),
        "sentiment_label": final_label,
        "article_counts": counts
    }


# --------------------------- COMBINATION ---------------------------
def combine_signals(tech: dict, sentiment: dict, cfg: dict) -> dict:
    tech_score = cfg["signal_mapping"].get(tech["signal"], 2)       # 2 = Neutral
    # Ù†Ø¶Ø±Ø¨ Ø§Ù„Ù€ sentiment ÙÙŠ 2 Ù„ØªÙ‚Ø±ÙŠØ¨ Ø§Ù„Ù†Ø·Ø§Ù‚ Ø¥Ù„Ù‰ -2â€¦+2
    sentiment_factor = sentiment["overall_sentiment_score"] * 2
    combined_score = tech_score + sentiment_factor

    if combined_score >= 4.5:
        final_decision = "Strong Buy"
    elif combined_score >= 3.5:
        final_decision = "Buy"
    elif combined_score <= 1.5:
        final_decision = "Strong Sell"
    elif combined_score <= 2.5:
        final_decision = "Sell"
    else:
        final_decision = "Neutral"

    return {
        "tech_score": tech_score,
        "sentiment_factor": round(sentiment_factor, 2),
        "combined_score": round(combined_score, 2),
        "final_decision": final_decision
    }


# --------------------------- HISTORY LOG ---------------------------
def append_history(record: dict, cfg: dict) -> None:
    csv_path = cfg["output"]["history_csv"]
    df = pd.DataFrame([record])
    header = not os.path.isfile(csv_path)
    df.to_csv(csv_path, mode="a", header=header, index=False, encoding="utf-8")
    logging.info(f"ØªÙ… ØªØ­Ø¯ÙŠØ« Ø³Ø¬Ù„ Ø§Ù„ØªØ§Ø±ÙŠØ® â†’ {csv_path}")


# --------------------------- OPTIONAL BACKâ€‘TEST (vectorbt) ---------------------------
def run_backtest(gold_df: pd.DataFrame, cfg: dict):
    try:
        import vectorbt as vbt
    except Exception:
        logging.warning("Ù…ÙƒØªØ¨Ø© vectorbt ØºÙŠØ± Ù…Ø«Ø¨ØªØ© â†’ ØªØ®Ø·ÙŠ backâ€‘testing.")
        return None

    gold_df["tech_signal"] = gold_df.apply(lambda r: evaluate_technical_signal(r, cfg)["signal"], axis=1)
    entries = gold_df["tech_signal"].isin(["Buy", "Strong Buy"])
    exits = gold_df["tech_signal"].isin(["Sell", "Strong Sell"])

    atr = gold_df["ATRr_14"]
    sl_series = gold_df["Close"] - atr * cfg["technical"]["atr_multiplier_sl"]

    pf = vbt.Portfolio.from_signals(
        gold_df["Close"], entries, exits,
        init_cash=100_000,
        fees=0.0005,
        sl_stop=sl_series,
        sl_stop_pct=False,
        direction="both"
    )
    logging.info("Ù†ØªØ§Ø¦Ø¬ backâ€‘testing:")
    logging.info(pf.stats())
    return pf


# --------------------------- MAIN ---------------------------
def main():
    # 0ï¸âƒ£ Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø£ÙˆÙ„ÙŠ
    cfg = load_config()
    setup_logging(cfg)

    logging.info("===== Ø¨Ø¯Ø¡ ØªÙ†ÙÙŠØ° ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø°Ù‡Ø¨ =====")
    # 1ï¸âƒ£ Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø³ÙˆÙ‚
    data = download_market_data(cfg["tickers"], cfg["period"], cfg["interval"])

    # 2ï¸âƒ£ Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ÙÙ†ÙŠØ©
    gold_df = prepare_gold_dataframe(data, cfg)

    # 3ï¸âƒ£ Ø¥Ø´Ø§Ø±Ø© ÙÙ†ÙŠØ© Ù„Ø¢Ø®Ø± ØµÙ (Ø§Ù„ÙŠÙˆÙ…/Ø§Ù„ØªØ§Ø±ÙŠØ® Ø§Ù„Ø£Ø®ÙŠØ±)
    latest = gold_df.iloc[-1]
    tech_signal = evaluate_technical_signal(latest, cfg)

    # 4ï¸âƒ£ Ø­Ø³Ø§Ø¨ ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø© / Ù‡Ø¯Ù Ø§Ù„Ø±Ø¨Ø­
    risk = calculate_risk_management(
        price=tech_signal["price"],
        atr=tech_signal["atr"],
        signal=tech_signal["signal"],
        cfg=cfg
    )

    # 5ï¸âƒ£ Ø¬Ù„Ø¨ Ø£Ø®Ø¨Ø§Ø± ÙˆØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±
    articles = fetch_all_news(cfg)
    articles_analyzed = analyze_sentiment(articles)
    sentiment = compute_weighted_sentiment(articles_analyzed, cfg)

    # 6ï¸âƒ£ Ø¯Ù…Ø¬ Ø§Ù„Ø¥Ø´Ø§Ø±ØªÙŠÙ†
    combined = combine_signals(tech_signal, sentiment, cfg)

    # 7ï¸âƒ£ ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø®Ø±Ø¬ Ø§Ù„Ø¹Ø§Ù…
    now_est = datetime.now(pytz.timezone("America/New_York")).strftime("%Y-%m-%d %H:%M:%S")
    result = {
        "timestamp_est": now_est,
        "price_usd": round(tech_signal["price"], 2),
        "technical": {
            "signal": tech_signal["signal"],
            "details": {
                "trend": "Uptrend" if tech_signal["is_uptrend"] else ("Downtrend" if tech_signal["is_downtrend"] else "Sideways"),
                "macd": "Bullish" if tech_signal["macd_bullish"] else ("Bearish" if tech_signal["macd_bearish"] else "Neutral"),
                "rsi": round(tech_signal["rsi"], 2),
                "rsi_status": ("Overbought" if tech_signal["rsi_up"] else ("Oversold" if tech_signal["rsi_down"] else "Neutral")),
                "obv_confirm": tech_signal["obv_confirm"]
            },
            "risk_management": risk,
            "indicators": {
                "SMA_50": round(tech_signal["sma_fast"], 2) if not pd.isna(tech_signal["sma_fast"]) else None,
                "SMA_200": round(tech_signal["sma_slow"], 2) if not pd.isna(tech_signal["sma_slow"]) else None,
                "ATR": round(tech_signal["atr"], 2) if not pd.isna(tech_signal["atr"]) else None
            }
        },
        "sentiment": {
            "overall_score": sentiment["overall_sentiment_score"],
            "sentiment_label": sentiment["sentiment_label"],
            "article_counts": sentiment["article_counts"]
        },
        "combined_signal": {
            "final_decision": combined["final_decision"],
            "combined_score": combined["combined_score"]
        },
        "market_sentiment": {
            "vix": round(data[("Close", cfg["tickers"]["vix"])].iloc[-1], 2),
            "yield_10y": round(data[("Close", cfg["tickers"]["yield"])].iloc[-1], 2),
            "eur_usd": round(data[("Close", cfg["tickers"]["eurusd"])].iloc[-1], 4)
        }
    }

    # 8ï¸âƒ£ Ø­ÙØ¸ Ø§Ù„Ù…Ù„ÙØ§Øª
    out = cfg["output"]
    with open(out["technical_json"], "w", encoding="utf-8") as f:
        json.dump(result["technical"], f, ensure_ascii=False, indent=4)
    with open(out["news_json"], "w", encoding="utf-8") as f:
        json.dump(articles_analyzed, f, ensure_ascii=False, indent=2)
    with open(out["combined_json"], "w", encoding="utf-8") as f:
        json.dump(result, f, ensure_ascii=False, indent=4)

    logging.info("âœ… Ø­ÙØ¸ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª âœ…")

    # 9ï¸âƒ£ ØªØ­Ø¯ÙŠØ« Ø³Ø¬Ù„ Ø§Ù„ØªØ§Ø±ÙŠØ® (CSV)
    rec = {
        "timestamp_est": now_est,
        "price_usd": result["price_usd"],
        "technical_signal": tech_signal["signal"],
        "sentiment_label": sentiment["sentiment_label"],
        "overall_sentiment_score": sentiment["overall_sentiment_score"],
        "combined_score": combined["combined_score"],
        "final_decision": combined["final_decision"],
        "stop_loss": risk["stop_loss"],
        "take_profit": risk["take_profit"]
    }
    append_history(rec, cfg)

    # ğŸ”Ÿ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ) ØªØ´ØºÙŠÙ„ backâ€‘testing
    if cfg.get("run_backtest", False):
        logging.info("ğŸš€ ØªØ´ØºÙŠÙ„ backâ€‘testing â€¦")
        run_backtest(gold_df, cfg)

    # ğŸ–¨ï¸ Ø¹Ø±Ø¶ Ù…Ù„Ø®Øµ Ø³Ø±ÙŠØ¹
    summary = f"""
===== Ù…Ù„Ø®Øµ Ø§Ù„ØªØ­Ù„ÙŠÙ„ (Ø§Ù„Ø°Ù‡Ø¨) =====
Ø§Ù„ØªÙˆÙ‚ÙŠØª (EST)   : {now_est}
Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ø­Ø§Ù„ÙŠ     : ${result["price_usd"]}
Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ø§Ù„ÙÙ†ÙŠØ©   : {tech_signal["signal"]}
Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ø§Ù„Ø®Ø¨Ø±ÙŠØ© : {sentiment["sentiment_label"]} (score {sentiment["overall_sentiment_score"]})
Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ø§Ù„Ù…Ø¯Ù…Ø¬Ø©   : {combined["final_decision"]} (score {combined["combined_score"]})

ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø©      : {risk["stop_loss"] if risk["stop_loss"] else "N/A"}
Ù‡Ø¯Ù Ø§Ù„Ø±Ø¨Ø­        : {risk["take_profit"] if risk["take_profit"] else "N/A"}
---------------------------------
"""
    print(summary)
    logging.info("===== Ø§Ù†ØªÙ‡Ù‰ ØªØ´ØºÙŠÙ„ Ø§Ù„Ù†Ø¸Ø§Ù… =====")


if __name__ == "__main__":
    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ØªØºÙŠÙ‘Ø±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦ÙŠØ© (Ø§Ù„Ù…ÙØªØ§Ø­ NewsAPI)
    load_dotenv()
    main()
