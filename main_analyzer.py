#!/usr/bin/env python3
import yfinance as yf
import pandas as pd
import numpy as np
import requests
import json
import os
import sqlite3
import joblib
from datetime import datetime, timedelta
import warnings
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import xgboost as xgb
from textblob import TextBlob
import spacy
import backtrader as bt
from concurrent.futures import ThreadPoolExecutor, as_completed
import asyncio
import aiohttp

warnings.filterwarnings('ignore')

# ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ spaCy
try:
    nlp = spacy.load("en_core_web_sm")
except:
    os.system("python -m spacy download en_core_web_sm")
    nlp = spacy.load("en_core_web_sm")

class MLPredictor:
    """Ù†Ø¸Ø§Ù… Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ"""
    def __init__(self):
        self.model = None
        self.scaler = StandardScaler()
        self.feature_columns = []
        self.model_path = "gold_ml_model.pkl"
        self.scaler_path = "gold_scaler.pkl"

    def prepare_features(self, analysis_data):
        """ØªØ­Ø¶ÙŠØ± Ø§Ù„Ù…Ù…ÙŠØ²Ø§Øª Ù…Ù† Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ­Ù„ÙŠÙ„"""
        features = {}

        if 'gold_analysis' in analysis_data:
            scores = analysis_data['gold_analysis'].get('component_scores', {})
            features.update({f'score_{k}': v for k, v in scores.items()})
            features['total_score'] = analysis_data['gold_analysis'].get('total_score', 0)

            tech_summary = analysis_data['gold_analysis'].get('technical_summary', {})
            features.update({f'tech_{k}': v for k, v in tech_summary.items()})

        if 'volume_analysis' in analysis_data:
            vol = analysis_data['volume_analysis']
            features['volume_ratio'] = vol.get('volume_ratio', 1)
            features['volume_strength_encoded'] = self._encode_volume_strength(vol.get('volume_strength', 'Ø·Ø¨ÙŠØ¹ÙŠ'))

        if 'market_correlations' in analysis_data:
            corr = analysis_data['market_correlations'].get('correlations', {})
            features.update({f'corr_{k}': v for k, v in corr.items()})

        if 'economic_data' in analysis_data:
            features['economic_score'] = analysis_data['economic_data'].get('score', 0)

        if 'fibonacci_levels' in analysis_data:
            fib = analysis_data['fibonacci_levels']
            features['fib_position'] = fib.get('current_position', 50)

        return features

    def _encode_volume_strength(self, strength):
        """ØªØ­ÙˆÙŠÙ„ Ù‚ÙˆØ© Ø§Ù„Ø­Ø¬Ù… Ø¥Ù„Ù‰ Ø±Ù‚Ù…"""
        mapping = {'Ø¶Ø¹ÙŠÙ': 0, 'Ø·Ø¨ÙŠØ¹ÙŠ': 1, 'Ù‚ÙˆÙŠ': 2, 'Ù‚ÙˆÙŠ Ø¬Ø¯Ø§Ù‹': 3}
        return mapping.get(strength, 1)

    def train_model(self, historical_data):
        """ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ"""
        print("ğŸ¤– Ø¨Ø¯Ø¡ ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ...")

        X, y = [], []
        for record in historical_data:
            features = self.prepare_features(record['analysis'])
            if features:
                X.append(list(features.values()))
                y.append(1 if record['price_change_5d'] > 1.0 else 0)

        if len(X) < 100:
            print("âš ï¸ Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± ÙƒØ§ÙÙŠØ© Ù„Ù„ØªØ¯Ø±ÙŠØ¨")
            return False

        X, y = np.array(X), np.array(y)
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)

        models = {
            'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42),
            'GradientBoosting': GradientBoostingClassifier(n_estimators=100, random_state=42),
            'XGBoost': xgb.XGBClassifier(n_estimators=100, random_state=42, use_label_encoder=False)
        }

        best_model, best_score = None, 0

        for name, model in models.items():
            print(f"ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ {name}...")
            model.fit(X_train_scaled, y_train)

            y_pred = model.predict(X_test_scaled)
            f1 = f1_score(y_test, y_pred)

            print(f"  - F1 Score: {f1:.2%}")

            if f1 > best_score:
                best_score = f1
                best_model = model
                self.model = model

        print(f"\nâœ… Ø£ÙØ¶Ù„ Ù†Ù…ÙˆØ°Ø¬: {type(best_model).__name__} Ù…Ø¹ F1 Score: {best_score:.2%}")

        joblib.dump(self.model, self.model_path)
        joblib.dump(self.scaler, self.scaler_path)

        return True

    def predict_probability(self, analysis_data):
        """Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ© Ù†Ø¬Ø§Ø­ Ø§Ù„Ø¥Ø´Ø§Ø±Ø©"""
        try:
            if self.model is None:
                if os.path.exists(self.model_path):
                    self.model = joblib.load(self.model_path)
                    self.scaler = joblib.load(self.scaler_path)
                else:
                    return None, "Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØºÙŠØ± Ù…Ø¯Ø±Ø¨ Ø¨Ø¹Ø¯"

            features = self.prepare_features(analysis_data)
            X = np.array([list(features.values())])

            X_scaled = self.scaler.transform(X)
            probability = self.model.predict_proba(X_scaled)[0][1]

            if probability > 0.75:
                interpretation = "Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ© Ø¹Ø§Ù„ÙŠØ© Ø¬Ø¯Ø§Ù‹ Ù„Ù„Ù†Ø¬Ø§Ø­"
            elif probability > 0.60:
                interpretation = "Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ© Ø¬ÙŠØ¯Ø© Ù„Ù„Ù†Ø¬Ø§Ø­"
            elif probability > 0.45:
                interpretation = "Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ© Ù…ØªÙˆØ³Ø·Ø© - Ø­Ø°Ø±"
            else:
                interpretation = "Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ© Ù…Ù†Ø®ÙØ¶Ø© - ØªØ¬Ù†Ø¨"

            return probability, interpretation

        except Exception as e:
            print(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªÙ†Ø¨Ø¤: {e}")
            return None, str(e)

class MultiTimeframeAnalyzer:
    """Ù…Ø­Ù„Ù„ Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ø£Ø·Ø± Ø§Ù„Ø²Ù…Ù†ÙŠØ©"""
    def __init__(self):
        self.timeframes = {
            '1h': {'period': '5d', 'weight': 0.2},
            '4h': {'period': '1mo', 'weight': 0.3},
            '1d': {'period': '3mo', 'weight': 0.5}
        }

    def analyze_timeframe(self, symbol, interval, period):
        """ØªØ­Ù„ÙŠÙ„ Ø¥Ø·Ø§Ø± Ø²Ù…Ù†ÙŠ ÙˆØ§Ø­Ø¯"""
        try:
            data = yf.download(symbol, period=period, interval=interval, progress=False)
            if data.empty:
                return None

            # ØªØµØ­ÙŠØ­: Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª DataFrame ÙˆÙ„ÙŠØ³Øª Series
            if isinstance(data['Close'], pd.Series):
                close_prices = data['Close']
            else:
                close_prices = data['Close'].squeeze()

            data['SMA_20'] = close_prices.rolling(20).mean()
            data['RSI'] = self._calculate_rsi(close_prices)

            exp1 = close_prices.ewm(span=12).mean()
            exp2 = close_prices.ewm(span=26).mean()
            data['MACD'] = exp1 - exp2
            data['MACD_Signal'] = data['MACD'].ewm(span=9).mean()

            latest = data.iloc[-1]
            score = 0

            if latest['Close'] > latest['SMA_20']:
                score += 1
            else:
                score -= 1

            if 30 <= latest['RSI'] <= 70:
                score += 0.5 if latest['RSI'] > 50 else -0.5
            elif latest['RSI'] < 30:
                score += 1
            else:
                score -= 1

            if latest['MACD'] > latest['MACD_Signal']:
                score += 1
            else:
                score -= 1

            return {
                'score': score,
                'trend': 'ØµØ§Ø¹Ø¯' if score > 0 else 'Ù‡Ø§Ø¨Ø·',
                'strength': abs(score),
                'rsi': latest['RSI'],
                'price': latest['Close']
            }

        except Exception as e:
            print(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¥Ø·Ø§Ø± Ø§Ù„Ø²Ù…Ù†ÙŠ {interval}: {e}")
            return None

    def _calculate_rsi(self, prices, period=14):
        """Ø­Ø³Ø§Ø¨ RSI"""
        delta = prices.diff()
        gain = delta.where(delta > 0, 0).rolling(window=period).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
        rs = gain / loss
        rsi = 100 - (100 / (1 + rs))
        return rsi

    def get_coherence_score(self, symbol):
        """Ø­Ø³Ø§Ø¨ Ù†Ù‚Ø§Ø· Ø§Ù„ØªÙˆØ§ÙÙ‚ Ø¨ÙŠÙ† Ø§Ù„Ø£Ø·Ø± Ø§Ù„Ø²Ù…Ù†ÙŠØ©"""
        print("â° ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø·Ø± Ø§Ù„Ø²Ù…Ù†ÙŠØ© Ø§Ù„Ù…ØªØ¹Ø¯Ø¯Ø©...")

        results = {}
        total_weighted_score = 0
        total_weight = 0

        for tf_name, tf_config in self.timeframes.items():
            interval = {'1h': '1h', '4h': '4h', '1d': '1d'}[tf_name]

            analysis = self.analyze_timeframe(symbol, interval, tf_config['period'])

            if analysis:
                results[tf_name] = analysis
                total_weighted_score += analysis['score'] * tf_config['weight']
                total_weight += tf_config['weight']

        if total_weight == 0:
            return 0, results

        coherence_score = total_weighted_score / total_weight

        trends = [r['trend'] for r in results.values() if r]
        if all(t == 'ØµØ§Ø¹Ø¯' for t in trends):
            coherence_score += 2
            coherence_analysis = "ØªÙˆØ§ÙÙ‚ ÙƒØ§Ù…Ù„ ØµØ§Ø¹Ø¯ - Ù‚ÙˆØ© Ø§Ø³ØªØ«Ù†Ø§Ø¦ÙŠØ©"
        elif all(t == 'Ù‡Ø§Ø¨Ø·' for t in trends):
            coherence_score -= 2
            coherence_analysis = "ØªÙˆØ§ÙÙ‚ ÙƒØ§Ù…Ù„ Ù‡Ø§Ø¨Ø· - Ø¶Ø¹Ù Ø´Ø¯ÙŠØ¯"
        elif len(set(trends)) > 1:
            coherence_analysis = "ØªØ¶Ø§Ø±Ø¨ Ø¨ÙŠÙ† Ø§Ù„Ø£Ø·Ø± Ø§Ù„Ø²Ù…Ù†ÙŠØ© - Ø­Ø°Ø±"
        else:
            coherence_analysis = "ØªÙˆØ§ÙÙ‚ Ø¬Ø²Ø¦ÙŠ"

        return coherence_score, {
            'timeframes': results,
            'coherence_score': round(coherence_score, 2),
            'analysis': coherence_analysis,
            'recommendation': self._get_mtf_recommendation(coherence_score)
        }

    def _get_mtf_recommendation(self, score):
        """ØªÙˆØµÙŠØ© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ØªÙˆØ§ÙÙ‚"""
        if score > 2:
            return "Ø¯Ø®ÙˆÙ„ Ù‚ÙˆÙŠ - Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø·Ø± Ù…ØªÙˆØ§ÙÙ‚Ø©"
        elif score > 1:
            return "Ø¯Ø®ÙˆÙ„ Ù…Ø¹ØªØ¯Ù„ - ØªÙˆØ§ÙÙ‚ Ø¬ÙŠØ¯"
        elif score > -1:
            return "Ø§Ù†ØªØ¸Ø§Ø± - Ø¹Ø¯Ù… ÙˆØ¶ÙˆØ­"
        elif score > -2:
            return "ØªØ¬Ù†Ø¨ Ø§Ù„Ø´Ø±Ø§Ø¡ - Ø¶Ø¹Ù"
        else:
            return "Ø¨ÙŠØ¹ Ø£Ùˆ ØªØ¬Ù†Ø¨ ÙƒØ§Ù…Ù„ - ØªÙˆØ§ÙÙ‚ Ù‡Ø§Ø¨Ø·"

class AdvancedNewsAnalyzer:
    """Ù…Ø­Ù„Ù„ Ø£Ø®Ø¨Ø§Ø± Ù…ØªÙ‚Ø¯Ù… Ù…Ø¹ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø­Ø¯Ø§Ø«"""
    def __init__(self, api_key):
        self.api_key = api_key
        self.event_patterns = {
            'interest_rate': {
                'keywords': ['interest rate', 'rate decision', 'fomc', 'federal reserve', 'fed meeting'],
                'entities': ['Federal Reserve', 'Fed', 'FOMC', 'Jerome Powell'],
                'impact_multiplier': 3
            },
            'inflation': {
                'keywords': ['inflation', 'cpi', 'consumer price', 'pce'],
                'entities': ['Bureau of Labor Statistics', 'BLS'],
                'impact_multiplier': 2.5
            },
            'employment': {
                'keywords': ['employment', 'jobs', 'nfp', 'non-farm payroll', 'unemployment'],
                'entities': ['Labor Department', 'BLS'],
                'impact_multiplier': 2
            },
            'geopolitical': {
                'keywords': ['war', 'conflict', 'sanctions', 'crisis', 'tension'],
                'entities': ['Russia', 'China', 'Middle East', 'Ukraine'],
                'impact_multiplier': 2.5
            },
            'central_bank': {
                'keywords': ['central bank', 'ecb', 'boe', 'boj', 'monetary policy'],
                'entities': ['ECB', 'Bank of England', 'Bank of Japan'],
                'impact_multiplier': 2
            },
            'dollar': {
                'keywords': ['dollar', 'dxy', 'usd', 'currency'],
                'entities': ['Dollar Index', 'DXY'],
                'impact_multiplier': 1.5
            }
        }

    def extract_events(self, articles):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø­Ø¯Ø§Ø« Ù…Ù† Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… NLP"""
        extracted_events = []

        for article in articles:
            if not article.get('title'):
                continue

            text = f"{article['title']} {article.get('description', '')}"
            doc = nlp(text)

            entities = [(ent.text, ent.label_) for ent in doc.ents]
            event_type = self._classify_event(text.lower(), entities)

            if event_type:
                sentiment_score = self._advanced_sentiment_analysis(text)
                numbers = self._extract_numbers(doc)

                event = {
                    'type': event_type,
                    'title': article['title'],
                    'source': article.get('source', {}).get('name', 'Unknown'),
                    'published': article.get('publishedAt', ''),
                    'entities': entities,
                    'numbers': numbers,
                    'sentiment_score': sentiment_score,
                    'impact_score': self._calculate_impact_score(event_type, sentiment_score),
                    'url': article.get('url', '')
                }
                extracted_events.append(event)

        return self._analyze_events_impact(extracted_events)

    def _classify_event(self, text, entities):
        """ØªØµÙ†ÙŠÙ Ù†ÙˆØ¹ Ø§Ù„Ø­Ø¯Ø«"""
        for event_type, patterns in self.event_patterns.items():
            if any(keyword in text for keyword in patterns['keywords']):
                return event_type

            entity_texts = [ent[0] for ent in entities]
            if any(entity in ' '.join(entity_texts) for entity in patterns['entities']):
                return event_type
        return None

    def _advanced_sentiment_analysis(self, text):
        """ØªØ­Ù„ÙŠÙ„ Ù…ØªÙ‚Ø¯Ù… Ù„Ù„Ù…Ø´Ø§Ø¹Ø±"""
        blob = TextBlob(text)
        basic_sentiment = blob.sentiment.polarity

        gold_positive = ['surge', 'rally', 'gain', 'rise', 'bullish', 'support', 'demand']
        gold_negative = ['fall', 'drop', 'decline', 'bearish', 'pressure', 'weak']

        positive_count = sum(1 for word in gold_positive if word in text.lower())
        negative_count = sum(1 for word in gold_negative if word in text.lower())

        final_sentiment = basic_sentiment + (positive_count - negative_count) * 0.1
        return max(-1, min(1, final_sentiment))

    def _extract_numbers(self, doc):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… ÙˆØ§Ù„Ù†Ø³Ø¨ Ø§Ù„Ù…Ø¦ÙˆÙŠØ©"""
        numbers = []
        for token in doc:
            if token.like_num or '%' in token.text:
                context = []
                for i in range(max(0, token.i - 3), min(len(doc), token.i + 3)):
                    context.append(doc[i].text)
                numbers.append({
                    'value': token.text,
                    'context': ' '.join(context)
                })
        return numbers

    def _calculate_impact_score(self, event_type, sentiment):
        """Ø­Ø³Ø§Ø¨ Ù†Ù‚Ø§Ø· Ø§Ù„ØªØ£Ø«ÙŠØ±"""
        base_impact = self.event_patterns.get(event_type, {}).get('impact_multiplier', 1)

        if event_type in ['interest_rate', 'inflation']:
            impact = base_impact * (-sentiment)
        else:
            impact = base_impact * sentiment

        return round(impact, 2)

    def _analyze_events_impact(self, events):
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªØ£Ø«ÙŠØ± Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ù„Ù„Ø£Ø­Ø¯Ø§Ø«"""
        if not events:
            return {
                'events': [],
                'total_impact': 0,
                'dominant_theme': None,
                'recommendation': 'Ù„Ø§ ØªÙˆØ¬Ø¯ Ø£Ø­Ø¯Ø§Ø« Ù…Ø¤Ø«Ø±Ø©'
            }

        event_groups = {}
        for event in events:
            event_type = event['type']
            if event_type not in event_groups:
                event_groups[event_type] = []
            event_groups[event_type].append(event)

        total_impact = sum(event['impact_score'] for event in events)
        dominant_theme = max(event_groups.keys(), 
                           key=lambda k: sum(e['impact_score'] for e in event_groups[k]))

        if total_impact > 5:
            recommendation = "Ø£Ø®Ø¨Ø§Ø± Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ© Ù‚ÙˆÙŠØ© Ø¬Ø¯Ø§Ù‹ Ù„Ù„Ø°Ù‡Ø¨"
        elif total_impact > 2:
            recommendation = "Ø£Ø®Ø¨Ø§Ø± Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ© Ù„Ù„Ø°Ù‡Ø¨"
        elif total_impact < -5:
            recommendation = "Ø£Ø®Ø¨Ø§Ø± Ø³Ù„Ø¨ÙŠØ© Ù‚ÙˆÙŠØ© Ø¬Ø¯Ø§Ù‹ Ù„Ù„Ø°Ù‡Ø¨"
        elif total_impact < -2:
            recommendation = "Ø£Ø®Ø¨Ø§Ø± Ø³Ù„Ø¨ÙŠØ© Ù„Ù„Ø°Ù‡Ø¨"
        else:
            recommendation = "ØªØ£Ø«ÙŠØ± Ù…Ø­Ø§ÙŠØ¯ Ø£Ùˆ Ù…Ø®ØªÙ„Ø·"

        return {
            'events': events[:10],
            'event_summary': {t: len(e) for t, e in event_groups.items()},
            'total_impact': round(total_impact, 2),
            'dominant_theme': dominant_theme,
            'recommendation': recommendation
        }

    async def fetch_news_async(self):
        """Ø¬Ù„Ø¨ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø¨Ø´ÙƒÙ„ ØºÙŠØ± Ù…ØªØ²Ø§Ù…Ù†"""
        keywords = ['"gold price"', '"federal reserve"', '"interest rates"', '"inflation data"', '"XAU/USD"']

        async with aiohttp.ClientSession() as session:
            tasks = []
            for keyword in keywords:
                url = f"https://newsapi.org/v2/everything?q={keyword}&language=en&sortBy=publishedAt&pageSize=20&apiKey={self.api_key}"
                tasks.append(self._fetch_url(session, url))

            results = await asyncio.gather(*tasks)

        all_articles = []
        for result in results:
            if result and 'articles' in result:
                all_articles.extend(result['articles'])

        seen_urls = set()
        unique_articles = []
        for article in all_articles:
            if article.get('url') not in seen_urls:
                seen_urls.add(article.get('url'))
                unique_articles.append(article)

        return unique_articles

    async def _fetch_url(self, session, url):
        """Ø¬Ù„Ø¨ URL ÙˆØ§Ø­Ø¯"""
        try:
            async with session.get(url, timeout=10) as response:
                return await response.json()
        except Exception as e:
            print(f"Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ø§Ù„Ø£Ø®Ø¨Ø§Ø±: {e}")
            return None

class ProfessionalBacktester:
    """Ù†Ø¸Ø§Ù… Ø§Ø®ØªØ¨Ø§Ø± Ø®Ù„ÙÙŠ Ø§Ø­ØªØ±Ø§ÙÙŠ"""

    class GoldStrategy(bt.Strategy):
        params = (
            ('analyzer', None),
            ('risk_percent', 0.02),
        )

        def __init__(self):
            self.order = None
            self.buyprice = None
            self.buycomm = None
            self.trades = []

        def next(self):
            if self.order:
                return

            current_data = self._prepare_current_data()
            signal = self.params.analyzer.generate_signal_for_backtest(current_data)

            if not self.position:
                if signal['action'] in ['Strong Buy', 'Buy']:
                    size = self._calculate_position_size(signal['confidence'], self.data.close[0])
                    if size > 0:
                        self.order = self.buy(size=size)
            else:
                if signal['action'] in ['Strong Sell', 'Sell']:
                    self.order = self.sell()
                elif self.position.size > 0:
                    current_price = self.data.close[0]
                    entry_price = self.position.price

                    if current_price < entry_price * 0.98:
                        self.order = self.sell()
                    elif current_price > entry_price * 1.05:
                        self.order = self.sell()

        def _prepare_current_data(self):
            """ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø­Ø§Ù„ÙŠØ© Ù„Ù„ØªØ­Ù„ÙŠÙ„"""
            return {
                'close': self.data.close[0],
                'open': self.data.open[0],
                'high': self.data.high[0],
                'low': self.data.low[0],
                'volume': self.data.volume[0]
            }

        def _calculate_position_size(self, confidence, price):
            """Ø­Ø³Ø§Ø¨ Ø­Ø¬Ù… Ø§Ù„Ù…Ø±ÙƒØ²"""
            if price <= 0:
                return 0

            cash_to_risk = self.broker.getcash() * self.params.risk_percent
            base_size = cash_to_risk / price

            if confidence == 'Very High':
                return base_size * 2
            elif confidence == 'High':
                return base_size * 1.5
            else:
                return base_size

        def notify_order(self, order):
            if order.status in [order.Submitted, order.Accepted]:
                return

            if order.status in [order.Completed]:
                if order.isbuy():
                    self.buyprice = order.executed.price
                    self.buycomm = order.executed.comm
                else:
                    profit = (order.executed.price - self.buyprice) * order.executed.size
                    self.trades.append({
                        'profit': profit,
                        'return': (order.executed.price - self.buyprice) / self.buyprice
                    })

            self.order = None

    def __init__(self, analyzer):
        self.analyzer = analyzer

    def run_backtest(self, data, initial_cash=10000):
        """ØªØ´ØºÙŠÙ„ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø®Ù„ÙÙŠ"""
        print("ğŸ”„ Ø¨Ø¯Ø¡ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø®Ù„ÙÙŠ Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠ...")

        cerebro = bt.Cerebro()
        data_feed = bt.feeds.PandasData(dataname=data)
        cerebro.adddata(data_feed)

        cerebro.addstrategy(self.GoldStrategy, analyzer=self.analyzer)

        cerebro.broker.setcash(initial_cash)
        cerebro.broker.setcommission(commission=0.001)

        cerebro.addanalyzer(bt.analyzers.SharpeRatio, _name='sharpe')
        cerebro.addanalyzer(bt.analyzers.DrawDown, _name='drawdown')
        cerebro.addanalyzer(bt.analyzers.Returns, _name='returns')
        cerebro.addanalyzer(bt.analyzers.TradeAnalyzer, _name='trades')

        results = cerebro.run()
        strat = results[0]

        sharpe = strat.analyzers.sharpe.get_analysis()
        drawdown = strat.analyzers.drawdown.get_analysis()
        returns = strat.analyzers.returns.get_analysis()
        trades = strat.analyzers.trades.get_analysis()

        final_value = cerebro.broker.getvalue()
        total_return = (final_value - initial_cash) / initial_cash * 100

        backtest_results = {
            'initial_capital': initial_cash,
            'final_value': round(final_value, 2),
            'total_return': round(total_return, 2),
            'sharpe_ratio': round(sharpe.get('sharperatio', 0), 3),
            'max_drawdown': round(drawdown.get('max', {}).get('drawdown', 0), 2),
            'total_trades': trades.get('total', {}).get('total', 0),
            'winning_trades': trades.get('won', {}).get('total', 0),
            'losing_trades': trades.get('lost', {}).get('total', 0),
            'win_rate': round(trades.get('won', {}).get('total', 0) / max(trades.get('total', {}).get('total', 1), 1) * 100, 2),
            'avg_trade_return': round(returns.get('rtot', 0) / max(trades.get('total', {}).get('total', 1), 1), 4),
            'best_trade': round(trades.get('won', {}).get('pnl', {}).get('max', 0), 2),
            'worst_trade': round(trades.get('lost', {}).get('pnl', {}).get('max', 0), 2),
            'avg_win': round(trades.get('won', {}).get('pnl', {}).get('average', 0), 2),
            'avg_loss': round(trades.get('lost', {}).get('pnl', {}).get('average', 0), 2),
            'profit_factor': self._calculate_profit_factor(trades),
            'recovery_factor': self._calculate_recovery_factor(total_return, drawdown),
            'risk_reward_ratio': self._calculate_risk_reward(trades)
        }

        self._generate_backtest_report(backtest_results)
        return backtest_results

    def _calculate_profit_factor(self, trades):
        """Ø­Ø³Ø§Ø¨ Ø¹Ø§Ù…Ù„ Ø§Ù„Ø±Ø¨Ø­"""
        try:
            gross_profit = abs(trades.get('won', {}).get('pnl', {}).get('total', 0))
            gross_loss = abs(trades.get('lost', {}).get('pnl', {}).get('total', 0))
            return round(gross_profit / gross_loss, 2) if gross_loss > 0 else 0
        except:
            return 0

    def _calculate_recovery_factor(self, total_return, drawdown):
        """Ø­Ø³Ø§Ø¨ Ø¹Ø§Ù…Ù„ Ø§Ù„Ø§Ø³ØªØ±Ø¯Ø§Ø¯"""
        try:
            max_dd = abs(drawdown.get('max', {}).get('drawdown', 1))
            return round(total_return / max_dd, 2) if max_dd > 0 else 0
        except:
            return 0

    def _calculate_risk_reward(self, trades):
        """Ø­Ø³Ø§Ø¨ Ù†Ø³Ø¨Ø© Ø§Ù„Ù…Ø®Ø§Ø·Ø±Ø© Ø¥Ù„Ù‰ Ø§Ù„Ù…ÙƒØ§ÙØ£Ø©"""
        try:
            avg_win = abs(trades.get('won', {}).get('pnl', {}).get('average', 0))
            avg_loss = abs(trades.get('lost', {}).get('pnl', {}).get('average', 1))
            return round(avg_win / avg_loss, 2) if avg_loss > 0 else 0
        except:
            return 0

    def _generate_backtest_report(self, results):
        """ØªÙˆÙ„ÙŠØ¯ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø®Ù„ÙÙŠ"""
        print("\n" + "="*60)
        print("ğŸ“Š ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø®Ù„ÙÙŠ Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠ")
        print("="*60)

        print(f"\nğŸ’° Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù…Ø§Ù„ÙŠ:")
        print(f"  â€¢ Ø±Ø£Ø³ Ø§Ù„Ù…Ø§Ù„ Ø§Ù„Ø£ÙˆÙ„ÙŠ: ${results['initial_capital']:,}")
        print(f"  â€¢ Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©: ${results['final_value']:,}")
        print(f"  â€¢ Ø§Ù„Ø¹Ø§Ø¦Ø¯ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ: {results['total_return']}%")
        print(f"  â€¢ Ù†Ø³Ø¨Ø© Ø´Ø§Ø±Ø¨: {results['sharpe_ratio']}")
        print(f"  â€¢ Ø£Ù‚ØµÙ‰ Ø§Ù†Ø®ÙØ§Ø¶: {results['max_drawdown']}%")

        print(f"\nğŸ“ˆ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ØªØ¯Ø§ÙˆÙ„:")
        print(f"  â€¢ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ØµÙÙ‚Ø§Øª: {results['total_trades']}")
        print(f"  â€¢ Ø§Ù„ØµÙÙ‚Ø§Øª Ø§Ù„Ø±Ø§Ø¨Ø­Ø©: {results['winning_trades']}")
        print(f"  â€¢ Ø§Ù„ØµÙÙ‚Ø§Øª Ø§Ù„Ø®Ø§Ø³Ø±Ø©: {results['losing_trades']}")
        print(f"  â€¢ Ù…Ø¹Ø¯Ù„ Ø§Ù„ÙÙˆØ²: {results['win_rate']}%")

        print(f"\nğŸ’µ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø±Ø¨Ø§Ø­ ÙˆØ§Ù„Ø®Ø³Ø§Ø¦Ø±:")
        print(f"  â€¢ Ù…ØªÙˆØ³Ø· Ø§Ù„Ø±Ø¨Ø­: ${results['avg_win']}")
        print(f"  â€¢ Ù…ØªÙˆØ³Ø· Ø§Ù„Ø®Ø³Ø§Ø±Ø©: ${results['avg_loss']}")
        print(f"  â€¢ Ø£ÙØ¶Ù„ ØµÙÙ‚Ø©: ${results['best_trade']}")
        print(f"  â€¢ Ø£Ø³ÙˆØ£ ØµÙÙ‚Ø©: ${results['worst_trade']}")
        print(f"  â€¢ Ø¹Ø§Ù…Ù„ Ø§Ù„Ø±Ø¨Ø­: {results['profit_factor']}")
        print(f"  â€¢ Ù†Ø³Ø¨Ø© Ø§Ù„Ù…Ø®Ø§Ø·Ø±Ø©/Ø§Ù„Ù…ÙƒØ§ÙØ£Ø©: {results['risk_reward_ratio']}")

        # âœ… ØªØµØ­ÙŠØ­ Ø§Ù„Ù…Ø³Ø§ÙØ© Ø§Ù„Ø¨Ø§Ø¯Ø¦Ø© Ù‡Ù†Ø§
        print(f"\nğŸ¯ ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ©:")
        if results['sharpe_ratio'] > 2:
            print("  âœ… Ø£Ø¯Ø§Ø¡ Ù…Ù…ØªØ§Ø² - Ù†Ø³Ø¨Ø© Ø´Ø§Ø±Ø¨ Ø¹Ø§Ù„ÙŠØ© Ø¬Ø¯Ø§Ù‹")
        elif results['sharpe_ratio'] > 1:
            print("  âœ… Ø£Ø¯Ø§Ø¡ Ø¬ÙŠØ¯ - Ù†Ø³Ø¨Ø© Ø´Ø§Ø±Ø¨ Ø¬ÙŠØ¯Ø©")
        elif results['sharpe_ratio'] > 0.5:
            print("  âš ï¸ Ø£Ø¯Ø§Ø¡ Ù…Ù‚Ø¨ÙˆÙ„ - ÙŠØ­ØªØ§Ø¬ ØªØ­Ø³ÙŠÙ†")
        else:
            print("  âŒ Ø£Ø¯Ø§Ø¡ Ø¶Ø¹ÙŠÙ - ÙŠØ­ØªØ§Ø¬ Ù…Ø±Ø§Ø¬Ø¹Ø© Ø´Ø§Ù…Ù„Ø©")

        if results['win_rate'] > 60:
            print("  âœ… Ù…Ø¹Ø¯Ù„ ÙÙˆØ² Ù…Ù…ØªØ§Ø²")
        elif results['win_rate'] > 50:
            print("  âœ… Ù…Ø¹Ø¯Ù„ ÙÙˆØ² Ø¬ÙŠØ¯")
        else:
            print("  âš ï¸ Ù…Ø¹Ø¯Ù„ ÙÙˆØ² ÙŠØ­ØªØ§Ø¬ ØªØ­Ø³ÙŠÙ†")

        if results['profit_factor'] > 2:
            print("  âœ… Ø¹Ø§Ù…Ù„ Ø±Ø¨Ø­ Ù…Ù…ØªØ§Ø²")
        elif results['profit_factor'] > 1.5:
            print("  âœ… Ø¹Ø§Ù…Ù„ Ø±Ø¨Ø­ Ø¬ÙŠØ¯")
        else:
            print("  âš ï¸ Ø¹Ø§Ù…Ù„ Ø±Ø¨Ø­ Ø¶Ø¹ÙŠÙ")

        print("="*60)

class DatabaseManager:
    """Ù…Ø¯ÙŠØ± Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ©"""
    def __init__(self, db_path="analysis_history.db"):
        self.db_path = db_path
        self.init_database()

    def init_database(self):
        """ØªÙ‡ÙŠØ¦Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        cursor.execute('''
            CREATE TABLE IF NOT EXISTS analysis_history (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                analysis_date DATE UNIQUE,
                gold_price REAL,
                signal TEXT,
                confidence TEXT,
                total_score REAL,
                component_scores TEXT,
                technical_indicators TEXT,
                volume_analysis TEXT,
                correlations TEXT,
                economic_score REAL,
                news_sentiment TEXT,
                mtf_coherence REAL,
                ml_probability REAL,
                price_after_1d REAL,
                price_after_5d REAL,
                price_after_10d REAL,
                price_change_1d REAL,
                price_change_5d REAL,
                price_change_10d REAL,
                signal_success BOOLEAN
            )
        ''')

        cursor.execute('''
            CREATE TABLE IF NOT EXISTS performance_metrics (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                date DATE,
                metric_name TEXT,
                metric_value REAL,
                details TEXT
            )
        ''')

        conn.commit()
        conn.close()

    def save_analysis(self, analysis_data):
        """Ø­ÙØ¸ Ø§Ù„ØªØ­Ù„ÙŠÙ„ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        try:
            gold_analysis = analysis_data.get('gold_analysis', {})
            if not gold_analysis or 'error' in gold_analysis:
                print("âš ï¸ ØªÙ… ØªØ®Ø·ÙŠ Ø§Ù„Ø­ÙØ¸ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø³Ø¨Ø¨ ÙˆØ¬ÙˆØ¯ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„")
                return

            # âœ… ØªØµØ­ÙŠØ­: Ø§Ø³ØªØ®Ø¯Ø§Ù… INSERT OR REPLACE Ù„ØªØ­Ø¯ÙŠØ« Ø³Ø¬Ù„ Ø§Ù„ÙŠÙˆÙ… Ø§Ù„ÙˆØ§Ø­Ø¯
            analysis_date_str = datetime.now().date().isoformat()
            cursor.execute('''
                INSERT OR REPLACE INTO analysis_history (
                    analysis_date, gold_price, signal, confidence, total_score,
                    component_scores, technical_indicators, volume_analysis,
                    correlations, economic_score, news_sentiment, mtf_coherence,
                    ml_probability
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                analysis_date_str,
                gold_analysis.get('current_price'),
                gold_analysis.get('signal'),
                gold_analysis.get('confidence'),
                gold_analysis.get('total_score'),
                json.dumps(gold_analysis.get('component_scores', {})),
                json.dumps(gold_analysis.get('technical_summary', {})),
                json.dumps(analysis_data.get('volume_analysis', {})),
                json.dumps(analysis_data.get('market_correlations', {}).get('correlations', {})),
                analysis_data.get('economic_data', {}).get('score', 0),
                analysis_data.get('news_analysis', {}).get('events_analysis', {}).get('recommendation'),
                analysis_data.get('mtf_analysis', {}).get('coherence_score', 0),
                gold_analysis.get('ml_prediction', {}).get('probability')
            ))

            conn.commit()
            print("âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„ØªØ­Ù„ÙŠÙ„ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")

        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ Ø§Ù„ØªØ­Ù„ÙŠÙ„: {e}")
            conn.rollback()
        finally:
            conn.close()

    def update_future_prices(self):
        """ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø£Ø³Ø¹Ø§Ø± Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠØ© Ù„Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        try:
            cursor.execute("PRAGMA table_info(analysis_history)")
            columns = [column[1] for column in cursor.fetchall()]
            if 'price_after_10d' not in columns:
                return

            cursor.execute('''
                SELECT id, analysis_date, gold_price 
                FROM analysis_history 
                WHERE price_after_10d IS NULL 
                AND analysis_date <= date('now', '-10 days')
            ''')
            records = cursor.fetchall()

            for record_id, analysis_date_str, original_price in records:
                future_prices = self._get_future_prices(analysis_date_str)
                if future_prices:
                    changes = {
                        '1d': ((future_prices.get('1d', original_price) - original_price) / original_price * 100),
                        '5d': ((future_prices.get('5d', original_price) - original_price) / original_price * 100),
                        '10d': ((future_prices.get('10d', original_price) - original_price) / original_price * 100)
                    }
                    signal_success = changes['5d'] > 1.0
                    cursor.execute('''
                        UPDATE analysis_history 
                        SET price_after_1d=?, price_after_5d=?, price_after_10d=?,
                            price_change_1d=?, price_change_5d=?, price_change_10d=?,
                            signal_success=?
                        WHERE id=?
                    ''', (
                        future_prices.get('1d'), future_prices.get('5d'), future_prices.get('10d'),
                        changes['1d'], changes['5d'], changes['10d'],
                        signal_success, record_id
                    ))
            conn.commit()
            if len(records) > 0:
                print(f"âœ… ØªÙ… ØªØ­Ø¯ÙŠØ« {len(records)} Ø³Ø¬Ù„ Ø¨Ø§Ù„Ø£Ø³Ø¹Ø§Ø± Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠØ©")
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø£Ø³Ø¹Ø§Ø± Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠØ©: {e}")
            conn.rollback()
        finally:
            conn.close()

    def _get_future_prices(self, analysis_date_str):
        try:
            analysis_date = datetime.strptime(analysis_date_str, '%Y-%m-%d').date()
            end_date = analysis_date + timedelta(days=15)
            data = yf.download('GC=F', start=analysis_date, end=end_date, progress=False)
            if data.empty: return None
            prices = {}
            for days in [1, 5, 10]:
                target_date = analysis_date + timedelta(days=days)
                future_dates = data.index[data.index >= pd.to_datetime(target_date)]
                if not future_dates.empty:
                    prices[f'{days}d'] = data.loc[future_dates.min(), 'Close']
            return prices
        except Exception as e:
            print(f"Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ø§Ù„Ø£Ø³Ø¹Ø§Ø± Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠØ©: {e}")
            return None

    def get_training_data(self, min_records=100):
        """Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ù„Ù„Ù†Ù…ÙˆØ°Ø¬"""
        try:
            conn = sqlite3.connect(self.db_path)
            df = pd.read_sql_query("SELECT * FROM analysis_history WHERE signal_success IS NOT NULL", conn)
            conn.close()
        except sqlite3.Error as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {e}")
            return None

        if len(df) < min_records:
            print(f"âš ï¸ Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± ÙƒØ§ÙÙŠØ© Ù„Ù„ØªØ¯Ø±ÙŠØ¨: {len(df)} Ø³Ø¬Ù„ ÙÙ‚Ø·")
            return None

        training_data = []
        for _, row in df.iterrows():
            record = {
                'analysis': {
                    'gold_analysis': {
                        'current_price': row['gold_price'], 'signal': row['signal'],
                        'confidence': row['confidence'], 'total_score': row['total_score'],
                        'component_scores': json.loads(row['component_scores'] or '{}'),
                        'technical_summary': json.loads(row['technical_indicators'] or '{}')
                    },
                    'volume_analysis': json.loads(row['volume_analysis'] or '{}'),
                    'market_correlations': {'correlations': json.loads(row['correlations'] or '{}')},
                    'economic_data': {'score': row['economic_score']}
                },
                'price_change_5d': row['price_change_5d'],
                'signal_success': row['signal_success']
            }
            training_data.append(record)
        return training_data

class ProfessionalGoldAnalyzerV3:
    """Ø§Ù„Ø¥ØµØ¯Ø§Ø± 3.0 Ù…Ù† Ù…Ø­Ù„Ù„ Ø§Ù„Ø°Ù‡Ø¨ Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠ"""
    def __init__(self):
        self.symbols = {
            'gold': 'GC=F', 'gold_etf': 'GLD', 'dxy': 'DX-Y.NYB',
            'vix': '^VIX', 'treasury': '^TNX', 'oil': 'CL=F',
            'spy': 'SPY', 'usdeur': 'EURUSD=X', 'silver': 'SI=F'
        }
        self.ml_predictor = MLPredictor()
        self.mtf_analyzer = MultiTimeframeAnalyzer()
        self.news_api_key = os.getenv("NEWS_API_KEY")
        self.news_analyzer = AdvancedNewsAnalyzer(self.news_api_key)
        self.db_manager = DatabaseManager()
        self.backtester = ProfessionalBacktester(self)

    def fetch_multi_timeframe_data(self):
        """Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø© Ø§Ù„Ø£Ø·Ø± Ø§Ù„Ø²Ù…Ù†ÙŠØ©"""
        print("ğŸ“Š Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø© Ø§Ù„Ø£Ø·Ø± Ø§Ù„Ø²Ù…Ù†ÙŠØ©...")
        try:
            # ØªØ¹Ø·ÙŠÙ„ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…ØªÙˆØ§Ø²ÙŠØ© Ù„ØªØ¬Ù†Ø¨ Ø£Ø®Ø·Ø§Ø¡ yfinance
            daily_data = yf.download(list(self.symbols.values()), 
                                    period="3y", interval="1d", 
                                    group_by='ticker', progress=False, threads=False)
            if daily_data.empty: raise ValueError("ÙØ´Ù„ Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
            return {'daily': daily_data}
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {e}")
            return None

    def extract_gold_data(self, market_data):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø°Ù‡Ø¨"""
        print("ğŸ” Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø°Ù‡Ø¨...")
        try:
            daily_data = market_data['daily']
            gold_symbol = self.symbols['gold']
            if not (isinstance(daily_data.columns, pd.MultiIndex) and gold_symbol in daily_data.columns.levels[0] and not daily_data[gold_symbol].dropna().empty):
                gold_symbol = self.symbols['gold_etf']
                if not (isinstance(daily_data.columns, pd.MultiIndex) and gold_symbol in daily_data.columns.levels[0] and not daily_data[gold_symbol].dropna().empty):
                    raise ValueError("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ø°Ù‡Ø¨")
            
            gold_daily = daily_data[gold_symbol].copy()
            gold_daily.dropna(subset=['Close'], inplace=True)
            if len(gold_daily) < 200: raise ValueError("Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± ÙƒØ§ÙÙŠØ©")
            print(f"âœ… Ø¨ÙŠØ§Ù†Ø§Øª ÙŠÙˆÙ…ÙŠØ© Ù†Ø¸ÙŠÙØ©: {len(gold_daily)} ÙŠÙˆÙ…")
            return gold_daily
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø°Ù‡Ø¨: {e}")
            return None

    def calculate_professional_indicators(self, gold_data):
        """Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠØ© Ø§Ù„Ù…Ø­Ø³Ù‘Ù†Ø©"""
        print("ğŸ“Š Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠØ© Ø§Ù„Ù…Ø­Ø³Ù‘Ù†Ø©...")
        try:
            df = gold_data.copy()
            for period in [10, 20, 50, 100, 200]: df[f'SMA_{period}'] = df['Close'].rolling(window=period).mean()
            df['EMA_9'] = df['Close'].ewm(span=9, adjust=False).mean()
            df['EMA_21'] = df['Close'].ewm(span=21, adjust=False).mean()
            df['Golden_Cross'] = (df['SMA_50'] > df['SMA_200']).astype(int)
            df['Death_Cross'] = (df['SMA_50'] < df['SMA_200']).astype(int)
            delta = df['Close'].diff()
            gain = delta.where(delta > 0, 0).rolling(window=14).mean()
            loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
            df['RSI'] = 100 - (100 / (1 + gain / loss.replace(0, 1e-9)))
            df['RSI_MA'] = df['RSI'].rolling(window=5).mean()
            exp1 = df['Close'].ewm(span=12, adjust=False).mean()
            exp2 = df['Close'].ewm(span=26, adjust=False).mean()
            df['MACD'] = exp1 - exp2
            df['MACD_Signal'] = df['MACD'].ewm(span=9, adjust=False).mean()
            df['MACD_Histogram'] = df['MACD'] - df['MACD_Signal']
            df['MACD_Cross'] = np.where(df['MACD'] > df['MACD_Signal'], 1, -1)
            std = df['Close'].rolling(window=20).std()
            df['BB_Upper'] = df['SMA_20'] + (std * 2)
            df['BB_Lower'] = df['SMA_20'] - (std * 2)
            df['BB_Width'] = ((df['BB_Upper'] - df['BB_Lower']) / df['SMA_20'].replace(0, 1e-9)) * 100
            df['BB_Position'] = (df['Close'] - df['BB_Lower']) / ((df['BB_Upper'] - df['BB_Lower']).replace(0, 1e-9))
            high_low = df['High'] - df['Low']
            high_close = np.abs(df['High'] - df['Close'].shift())
            low_close = np.abs(df['Low'] - df['Close'].shift())
            true_range = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)
            df['ATR'] = true_range.rolling(14).mean()
            df['ATR_Percent'] = (df['ATR'] / df['Close'].replace(0, 1e-9)) * 100
            df['Volume_SMA'] = df['Volume'].rolling(20).mean()
            df['Volume_Ratio'] = df['Volume'] / df['Volume_SMA'].replace(0, 1)
            df['OBV'] = (np.sign(df['Close'].diff()) * df['Volume']).fillna(0).cumsum()
            df['Volume_Price_Trend'] = (np.sign(df['Close'].diff()) * df['Volume']).cumsum()
            return df.dropna()
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª: {e}")
            return None

    def calculate_support_resistance(self, data, window=20):
        try:
            recent_data = data.tail(window * 3)
            highs = recent_data[recent_data['High'] == recent_data['High'].rolling(5, center=True).max()]['High']
            lows = recent_data[recent_data['Low'] == recent_data['Low'].rolling(5, center=True).min()]['Low']
            resistance_levels = highs.nlargest(3).tolist()
            support_levels = lows.nsmallest(3).tolist()
            current_price = data['Close'].iloc[-1]
            nearest_resistance = min((r for r in resistance_levels if r > current_price), default=None)
            nearest_support = max((s for s in support_levels if s < current_price), default=None)
            return {
                'nearest_resistance': round(nearest_resistance, 2) if nearest_resistance else None,
                'nearest_support': round(nearest_support, 2) if nearest_support else None
            }
        except Exception as e:
            print(f"Ø®Ø·Ø£ ÙÙŠ Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¯Ø¹Ù… ÙˆØ§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø©: {e}")
            return {}

    def calculate_fibonacci_levels(self, data, periods=50):
        try:
            recent_data = data.tail(periods)
            high, low = recent_data['High'].max(), recent_data['Low'].min()
            diff = high - low
            if diff == 0: return {}
            current_price = data['Close'].iloc[-1]
            return {
                'fib_38_2': round(high - (diff * 0.382), 2),
                'fib_61_8': round(high - (diff * 0.618), 2),
                'current_position': round(((current_price - low) / diff * 100), 2)
            }
        except Exception as e:
            print(f"Ø®Ø·Ø£ ÙÙŠ Ø­Ø³Ø§Ø¨ ÙÙŠØ¨ÙˆÙ†Ø§ØªØ´ÙŠ: {e}")
            return {}
            
    def fetch_economic_data(self):
        return {'score': 3}

    def analyze_volume_profile(self, data):
        try:
            latest = data.iloc[-1]
            volume_ratio = latest.get('Volume_Ratio', 1)
            if volume_ratio > 2.0: volume_strength = 'Ù‚ÙˆÙŠ Ø¬Ø¯Ø§Ù‹'
            elif volume_ratio > 1.5: volume_strength = 'Ù‚ÙˆÙŠ'
            else: volume_strength = 'Ø·Ø¨ÙŠØ¹ÙŠ'
            return {'volume_strength': volume_strength, 'obv_trend': 'ØµØ§Ø¹Ø¯' if data['OBV'].iloc[-1] > data['OBV'].iloc[-5] else 'Ù‡Ø§Ø¨Ø·'}
        except Exception as e:
            print(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø­Ø¬Ù…: {e}")
            return {}

    def analyze_correlations(self, market_data):
        try:
            print("ğŸ“Š ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø·Ø§Øª...")
            close_prices = market_data['daily'].xs('Close', level=1, axis=1)
            correlations = close_prices.tail(90).corr()
            gold_symbol = self.symbols['gold']
            if gold_symbol not in correlations: gold_symbol = self.symbols['gold_etf']
            gold_corrs = correlations[gold_symbol]
            return {'correlations': {name: round(gold_corrs.get(symbol, 0), 3) for name, symbol in self.symbols.items()}}
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø·Ø§Øª: {e}")
            return {}

    async def fetch_news_enhanced(self):
        print("ğŸ“° Ø¬Ù„Ø¨ ÙˆØªØ­Ù„ÙŠÙ„ Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ø°Ù‡Ø¨...")
        if not self.news_api_key: return {"status": "no_api_key"}
        try:
            articles = await self.news_analyzer.fetch_news_async()
            return self.news_analyzer.analyze_news(articles)
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ø§Ù„Ø£Ø®Ø¨Ø§Ø±: {e}")
            return {"status": "error"}

    def generate_professional_signals_v3(self, tech_data, correlations, volume, fib_levels, support_resistance, economic_data, news_analysis, mtf_analysis, ml_prediction):
        print("ğŸ¯ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª...")
        try:
            latest = tech_data.iloc[-1]
            scores = {}
            weights = {'trend': 0.2, 'momentum': 0.15, 'volume': 0.1, 'fibonacci': 0.08, 'correlation': 0.05, 'support_resistance': 0.08, 'economic': 0.08, 'news': 0.06, 'ma_cross': 0.1, 'mtf_coherence': 0.1}
            
            scores['trend'] = 4 if latest['Close'] > latest['SMA_50'] > latest['SMA_200'] else (-4 if latest['Close'] < latest['SMA_50'] < latest['SMA_200'] else 0)
            scores['momentum'] = (1 if latest['MACD'] > latest['MACD_Signal'] else -1) + (1.5 if latest['RSI'] > 60 else (-1.5 if latest['RSI'] < 40 else 0))
            strength_map = {'Ø·Ø¨ÙŠØ¹ÙŠ': 0, 'Ù‚ÙˆÙŠ': 2, 'Ù‚ÙˆÙŠ Ø¬Ø¯Ø§Ù‹': 4}
            scores['volume'] = strength_map.get(volume.get('volume_strength', 'Ø·Ø¨ÙŠØ¹ÙŠ'), 0)
            pos = fib_levels.get('current_position', 50)
            scores['fibonacci'] = 2 if pos > 61.8 else (-2 if pos < 38.2 else 0)
            price_to_support = (latest['Close'] - support_resistance.get('nearest_support', 0)) / latest['Close'] * 100 if support_resistance.get('nearest_support') else 100
            scores['support_resistance'] = 2 if price_to_support < 1.5 else 0
            dxy_corr = correlations.get('correlations', {}).get('dxy', 0)
            scores['correlation'] = 1 if dxy_corr < -0.5 else (-1 if dxy_corr > 0.5 else 0)
            scores['economic'] = economic_data.get('score', 0)
            scores['news'] = news_analysis.get('total_impact', 0)
            scores['mtf_coherence'] = mtf_analysis.get('coherence_score', 0)

            total_score = sum(scores[k] * v for k, v in weights.items())
            
            ml_interpretation = ""
            if ml_prediction and ml_prediction[0] is not None:
                ml_prob = ml_prediction[0]
                ml_interpretation = ml_prediction[1]
                total_score *= (1.0 + (ml_prob - 0.5) * 0.5)
            
            if total_score >= 1.5: signal, confidence = "Strong Buy", "Very High"
            elif total_score >= 0.7: signal, confidence = "Buy", "High"
            elif total_score > -0.7: signal, confidence = "Hold", "Medium"
            elif total_score > -1.5: signal, confidence = "Sell", "High"
            else: signal, confidence = "Strong Sell", "Very High"
            
            return {
                'signal': signal, 'confidence': confidence, 'total_score': round(total_score, 2),
                'component_scores': {k: round(v, 2) for k, v in scores.items()},
                'current_price': round(latest['Close'], 2),
                'technical_summary': {'rsi': round(latest.get('RSI', 50), 1), 'macd': round(latest.get('MACD', 0), 2)},
                'ml_prediction': {'probability': ml_prediction[0] if ml_prediction and ml_prediction[0] is not None else None, 'interpretation': ml_interpretation}
            }
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª: {e}")
            return {"error": str(e)}

    def generate_signal_for_backtest(self, data):
        return {'action': 'Buy' if data['close'] > data.get('open', data['close']) else 'Sell'}

    def generate_report_v3(self, analysis_result):
        if analysis_result.get('status') != 'success': return "ÙØ´Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„."
        ga = analysis_result.get('gold_analysis', {})
        return f"ğŸ“Š Ø§Ù„ØªÙ‚Ø±ÙŠØ±: {ga.get('signal')} Ø¨Ø«Ù‚Ø© {ga.get('confidence')} | Ø§Ù„Ø³Ø¹Ø±: ${ga.get('current_price')} | Ø§Ù„Ù†Ù‚Ø§Ø·: {ga.get('total_score')}"

    async def run_analysis_v3(self):
        print("ğŸš€ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠ...")
        final_result = {'timestamp': datetime.now().isoformat(), 'version': '3.0'}
        try:
            market_data = self.fetch_multi_timeframe_data()
            if market_data is None: raise ValueError("ÙØ´Ù„ ÙÙŠ Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø³ÙˆÙ‚")
            
            gold_data = self.extract_gold_data(market_data)
            if gold_data is None: raise ValueError("ÙØ´Ù„ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø°Ù‡Ø¨")

            technical_data = self.calculate_professional_indicators(gold_data)
            if technical_data is None: raise ValueError("ÙØ´Ù„ ÙÙŠ Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª")

            # Execute all analyses
            news_data = await self.fetch_news_enhanced()
            coherence_score, mtf_analysis = self.mtf_analyzer.get_coherence_score(self.symbols['gold'])
            fib_levels = self.calculate_fibonacci_levels(technical_data)
            support_resistance = self.calculate_support_resistance(technical_data)
            volume_analysis = self.analyze_volume_profile(technical_data)
            correlations = self.analyze_correlations(market_data)
            economic_data = self.fetch_economic_data()

            self.db_manager.update_future_prices()
            training_data = self.db_manager.get_training_data()
            ml_prediction = None
            if training_data:
                if not os.path.exists(self.ml_predictor.model_path):
                    self.ml_predictor.train_model(training_data)
                
                temp_signals = self.generate_professional_signals_v3(technical_data, correlations, volume_analysis, fib_levels, support_resistance, economic_data, news_data, mtf_analysis, None)
                temp_analysis_for_ml = {
                    'gold_analysis': temp_signals, 'volume_analysis': volume_analysis, 
                    'market_correlations': correlations, 'economic_data': economic_data, 'fibonacci_levels': fib_levels
                }
                ml_prediction = self.ml_predictor.predict_probability(temp_analysis_for_ml)

            signals = self.generate_professional_signals_v3(
                technical_data, correlations, volume_analysis, fib_levels, 
                support_resistance, economic_data, news_data, mtf_analysis, ml_prediction
            )
            
            backtest_results = self.backtester.run_backtest(technical_data)
            
            final_result.update({
                'status': 'success',
                'gold_analysis': signals,
                'backtest_results': backtest_results,
                'market_correlations': correlations,
                'news_analysis': news_data,
                'mtf_analysis': mtf_analysis,
                'volume_analysis': volume_analysis,
                'economic_data': economic_data,
                'fibonacci_levels': fib_levels,
                'support_resistance': support_resistance
            })
            self.db_manager.save_analysis(final_result)
        except Exception as e:
            print(f"âŒ ÙØ´Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠ: {e}")
            final_result.update({'status': 'error', 'error': str(e)})
        
        self.save_results_v3(final_result)
        report = self.generate_report_v3(final_result)
        print(report)
        print("\nâœ… ØªÙ… Ø¥ØªÙ…Ø§Ù… Ø§Ù„ØªØ­Ù„ÙŠÙ„!")
        return final_result

    def save_results_v3(self, results):
        try:
            with open("gold_analysis_v3.json", 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2, default=str)
            print(f"ğŸ’¾ ØªÙ… Ø­ÙØ¸ Ø§Ù„ØªØ­Ù„ÙŠÙ„ ÙÙŠ: gold_analysis_v3.json")
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬: {e}")

def main():
    analyzer = ProfessionalGoldAnalyzerV3()
    asyncio.run(analyzer.run_analysis_v3())

if __name__ == "__main__":
    main()
