#!/usr/bin/env python3
"""
Professional Gold Analyzer â€“ Ù†Ø³Ø®Ø© Ù…Ø­Ø³Ù‘Ù†Ø©

Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª Ø§Ù„Ù…Ø¶Ù…Ù‘Ù†Ø© (9 Ù†Ù‚Ø§Ø·):
1ï¸âƒ£  ØªØ­Ø³ÙŠÙ† Ø£Ø¯Ø§Ø¡ Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (caching + threads)
2ï¸âƒ£  Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ØªÙ‚Ù†ÙŠØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…ÙƒØªØ¨Ø© `ta`
3ï¸âƒ£  Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù‚ØªØµØ§Ø¯ÙŠØ© Ø­Ù‚ÙŠÙ‚ÙŠØ© Ø¹Ø¨Ø± FRED (Ø£Ùˆ Ù…Ø­Ø§ÙƒØ§Ø© Ø¥Ø°Ø§ Ù„Ù… ÙŠØªÙˆÙØ± Ø§Ù„Ù…ÙØªØ§Ø­)
4ï¸âƒ£  ØªØ­Ø³ÙŠÙ† ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… VADER + fallback Ø¹Ø±Ø¨ÙŠ
5ï¸âƒ£  ØªÙˆÙ„ÙŠØ¯ Ø¥Ø´Ø§Ø±Ø§Øª Ù…ÙØ­Ø³Ù‘Ù†Ø© Ù…Ø¹ ÙˆØ²Ù† Ù†Ù‚Ø§Ø· ÙˆØ§Ø¶Ø­
6ï¸âƒ£  Ø§Ø®ØªØ¨Ø§Ø± Ø±Ø¬Ø¹ÙŠ Ø¨Ø³ÙŠØ· (Backâ€‘testing) ÙˆÙ…Ù‚Ø§ÙŠÙŠØ³ Ø£Ø¯Ø§Ø¡
7ï¸âƒ£  ØªÙ‚Ø±ÙŠØ± Ø¨ØµØ±ÙŠ (Ù…Ø®Ø·Ø· Ø³Ø¹Ø± + SMA/EMA + Bollinger)
8ï¸âƒ£  ØªØ³Ø¬ÙŠÙ„â€¯logging Ù…ÙØµÙ‘Ù„ Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† `print`
9ï¸âƒ£  ØªØ­Ø³ÙŠÙ†Ø§Øª Ø§Ø³ØªÙ‚Ø±Ø§Ø± (Ù…Ø¹Ø§Ù„Ø¬Ø© NaNØŒ Ø£Ø®Ø·Ø§Ø¡ Ù…Ø¯Ù…Ø¬Ø©ØŒ ØªÙˆØ«ÙŠÙ‚)

Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª (pip install -r requirements.txt):
    yfinance pandas numpy requests python-dotenv joblib ta fredapi vaderSentiment matplotlib
"""

import os
import json
import warnings
import logging
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional

import yfinance as yf
import pandas as pd
import numpy as np
import requests
from dotenv import load_dotenv
from joblib import Memory
from ta.trend import SMAIndicator, EMAIndicator, MACD, IchimokuIndicator
from ta.volatility import BollingerBands, AverageTrueRange
from ta.momentum import RSIIndicator, StochasticOscillator, WilliamsRIndicator
from fredapi import Fred
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
import matplotlib.pyplot as plt

warnings.filterwarnings("ignore")

# --------------------------------------------------------------
# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù€ logging
# --------------------------------------------------------------
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)s | %(name)s | %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S",
)
logger = logging.getLogger("GoldAnalyzer")

# Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…ØªØºÙŠÙ‘Ø±Ø§Øª Ù…Ù† .env (Ù…ÙÙŠØ¯ ÙÙŠ GitHub Actions)
load_dotenv()

# Ù…Ø¬Ù„Ø¯ Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª
CACHE_DIR = "./cache"
_memory = Memory(location=CACHE_DIR, verbose=0)


# --------------------------------------------------------------
# Ø§Ø³ØªØ«Ù†Ø§Ø¡ Ù…Ø®ØµØµ
# --------------------------------------------------------------
class GoldAnalyzerError(Exception):
    """Raised when a critical step of the analysis fails."""


# --------------------------------------------------------------
# Ø§Ù„ÙƒÙ„Ø§Ø³ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ (Ù…Ø³ØªÙ…Ø± ÙÙŠ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙƒÙ…Ø§ Ù‡Ùˆ)
# --------------------------------------------------------------
class ProfessionalGoldAnalyzer:
    """
    ÙƒÙ„Ø§Ø³ ÙŠØ¯Ù…Ø¬ ÙƒÙ„ Ø§Ù„Ø®Ø·ÙˆØ§Øª:
        â€¢ Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ø£Ø·Ø±)
        â€¢ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø°Ù‡Ø¨
        â€¢ Ø­Ø³Ø§Ø¨ Ù…Ø¤Ø´Ø±Ø§Øª ØªÙ‚Ù†ÙŠØ© (ta)
        â€¢ Ø­Ø³Ø§Ø¨ Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„ÙÙŠØ¨ÙˆÙ†Ø§ØªØ´ÙŠØŒ Ø§Ù„Ø¯Ø¹Ù…/Ø§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø©
        â€¢ ØªØ­Ù„ÙŠÙ„ Ø­Ø¬Ù… Ø§Ù„ØªØ¯Ø§ÙˆÙ„
        â€¢ ØªØ­Ù„ÙŠÙ„ Ø§Ø±ØªØ¨Ø§Ø·Ø§Øª Ø§Ù„Ø£ØµÙˆÙ„ Ø§Ù„Ø£Ø®Ø±Ù‰
        â€¢ Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù‚ØªØµØ§Ø¯ÙŠØ© Ù…Ù† FRED / Ù…Ø­Ø§ÙƒØ§Ø©
        â€¢ Ø¬Ù„Ø¨ ÙˆØªØ­Ù„ÙŠÙ„ Ø£Ø®Ø¨Ø§Ø± (VADER + Arabic fallback)
        â€¢ ØªÙˆÙ„ÙŠØ¯ Ø¥Ø´Ø§Ø±Ø© Ù†Ù‡Ø§Ø¦ÙŠØ© Ù…Ø¹ Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ø®Ø§Ø·Ø±
        â€¢ Ø§Ø®ØªØ¨Ø§Ø± Ø±Ø¬Ø¹ÙŠ Ø¨Ø³ÙŠØ·
        â€¢ ØªÙ‚Ø±ÙŠØ± Ø¨ØµØ±ÙŠ
        â€¢ Ø­ÙØ¸ Ù†ØªØ§Ø¦Ø¬ JSON + ØªÙ‚Ø±ÙŠØ± Ù†ØµÙŠ
    """

    def __init__(self) -> None:
        # Ø±Ù…ÙˆØ² yfinance
        self.symbols = {
            "gold": "GC=F",
            "gold_etf": "GLD",
            "dxy": "DX-Y.NYB",
            "vix": "^VIX",
            "treasury": "^TNX",
            "oil": "CL=F",
            "spy": "SPY",
            "usdeur": "EURUSD=X",
            "silver": "SI=F",
        }

        # Ù…ÙØ§ØªÙŠØ­ API
        self.news_api_key = os.getenv("NEWS_API_KEY")
        self.fred_api_key = os.getenv("FRED_API_KEY")
        self.fred = Fred(api_key=self.fred_api_key) if self.fred_api_key else None

        # Ù…Ø­Ù„Ù„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± (Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠ)
        self.sentiment_analyzer = SentimentIntensityAnalyzer()

    # ------------------------------------------------------------------
    # 1ï¸âƒ£ Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Ù…Ø¹ caching)
    # ------------------------------------------------------------------
    @_memory.cache
    def _download(self, symbols: List[str], period: str, interval: str) -> pd.DataFrame:
        """ØªÙ†Ø²ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª yfinance ÙˆØªØ®Ø²ÙŠÙ†Ù‡Ø§ Ù…Ø¤Ù‚ØªØ§Ù‹."""
        logger.info(
            "Downloading symbols=%s period=%s interval=%s", symbols, period, interval
        )
        df = yf.download(
            tickers=symbols,
            period=period,
            interval=interval,
            group_by="ticker",
            auto_adjust=True,
            progress=False,
            threads=True,
        )
        if df.empty:
            raise GoldAnalyzerError("yfinance returned empty DataFrame")
        return df

    def fetch_multi_timeframe_data(self) -> Optional[Dict[str, pd.DataFrame]]:
        """Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙŠÙˆÙ…ÙŠØ© Ù„Ø³Ù†Ø© ÙƒØ§Ù…Ù„Ø© + Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø°Ù‡Ø¨ Ø¹Ù„Ù‰ ÙØ§ØµÙ„ 1â€‘Ø³Ø§Ø¹Ø© Ù„Ù„Ø´Ù‡Ø± Ø§Ù„Ø£Ø®ÙŠØ±."""
        logger.info("ğŸ“Š Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø© Ø§Ù„Ø£Ø·Ø± Ø§Ù„Ø²Ù…Ù†ÙŠØ©...")
        try:
            daily = self._download(list(self.symbols.values()), period="1y", interval="1d")
            hourly = self._download([self.symbols["gold"]], period="1mo", interval="1h")
            return {"daily": daily, "hourly": hourly}
        except Exception as exc:
            logger.exception("Failed to fetch market data")
            return None

    # ------------------------------------------------------------------
    # 2ï¸âƒ£ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø°Ù‡Ø¨
    # ------------------------------------------------------------------
    def extract_gold_data(self, market_data: Dict[str, pd.DataFrame]) -> Optional[pd.DataFrame]:
        logger.info("ğŸ” Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø°Ù‡Ø¨...")
        try:
            daily = market_data["daily"]
            gold_sym = self.symbols["gold"]

            # Ø¥Ø°Ø§ Ù„Ù… ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¹Ù‚ÙˆØ¯ Ø§Ù„ÙÙˆØ±ÙŠØ© Ù†Ù„Ø¬Ø¦ Ù„Ù„Ù€ ETF
            if gold_sym not in daily.columns.levels[0] or daily[gold_sym]["Close"].dropna().empty:
                gold_sym = self.symbols["gold_etf"]
                if gold_sym not in daily.columns.levels[0] or daily[gold_sym]["Close"].dropna().empty:
                    raise GoldAnalyzerError("Gold data not found")

            gold = daily[gold_sym].copy()
            gold.dropna(subset=["Close"], inplace=True)

            if len(gold) < 200:
                raise GoldAnalyzerError("Insufficient gold history (<200 rows)")

            logger.info("âœ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ %d ØµÙ Ù…Ù† Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø°Ù‡Ø¨", len(gold))
            return gold
        except Exception as exc:
            logger.exception("Failed to extract gold data")
            return None

    # ------------------------------------------------------------------
    # 3ï¸âƒ£ Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ØªÙ‚Ù†ÙŠØ© (Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…ÙƒØªØ¨Ø© `ta`)
    # ------------------------------------------------------------------
    def calculate_technical_indicators(self, gold_data: pd.DataFrame) -> pd.DataFrame:
        """Ø¥Ø¶Ø§ÙØ© Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ØªÙ‚Ù†ÙŠØ© Ø§Ù„Ø¶Ø±ÙˆØ±ÙŠØ©."""
        logger.info("ğŸ“ˆ Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ØªÙ‚Ù†ÙŠØ©...")
        df = gold_data.copy()

        # ------------------- Ø§Ù„Ù…ØªÙˆØ³Ø·Ø§Øª Ø§Ù„Ù…ØªØ­Ø±ÙƒØ© -------------------
        df["SMA_10"] = SMAIndicator(df["Close"], window=10).sma_indicator()
        df["SMA_20"] = SMAIndicator(df["Close"], window=20).sma_indicator()
        df["SMA_50"] = SMAIndicator(df["Close"], window=50).sma_indicator()
        df["SMA_100"] = SMAIndicator(df["Close"], window=100).sma_indicator()
        df["SMA_200"] = SMAIndicator(df["Close"], window=200).sma_indicator()

        df["EMA_9"] = EMAIndicator(df["Close"], window=9).ema_indicator()
        df["EMA_21"] = EMAIndicator(df["Close"], window=21).ema_indicator()

        # ------------------- ØªÙ‚Ø§Ø·Ø¹Ø§Øª Ø§Ù„Ø°Ù‡Ø¨/Ø§Ù„Ù…ÙˆØª -------------------
        df["Golden_Cross"] = (df["SMA_50"] > df["SMA_200"]).astype(int)
        df["Death_Cross"] = (df["SMA_50"] < df["SMA_200"]).astype(int)

        # ------------------- RSI -------------------
        df["RSI"] = RSIIndicator(df["Close"], window=14).rsi()
        df["RSI_MA"] = df["RSI"].rolling(window=5).mean()

        # ------------------- MACD -------------------
        macd = MACD(df["Close"], window_slow=26, window_fast=12, window_sign=9)
        df["MACD"] = macd.macd()
        df["MACD_Signal"] = macd.macd_signal()
        df["MACD_Histogram"] = macd.macd_diff()
        df["MACD_Cross"] = np.where(df["MACD"] > df["MACD_Signal"], 1, -1)

        # ------------------- Bollinger Bands -------------------
        bb = BollingerBands(df["Close"], window=20, window_dev=2)
        df["BB_Upper"] = bb.bollinger_hband()
        df["BB_Lower"] = bb.bollinger_lband()
        df["BB_Width"] = (df["BB_Upper"] - df["BB_Lower"]) / df["SMA_20"] * 100
        df["BB_Position"] = (df["Close"] - df["BB_Lower"]) / (df["BB_Upper"] - df["BB_Lower"])

        # ------------------- ATR -------------------
        df["ATR"] = AverageTrueRange(df["High"], df["Low"], df["Close"], window=14).average_true_range()
        df["ATR_Percent"] = df["ATR"] / df["Close"] * 100

        # ------------------- Ø­Ø¬Ù… Ø§Ù„ØªØ¯Ø§ÙˆÙ„ -------------------
        df["Volume_SMA"] = df["Volume"].rolling(window=20).mean()
        df["Volume_Ratio"] = df["Volume"] / df["Volume_SMA"]

        # OBV â€“ Ø§Ù„Ø§ØªØ¬Ø§Ù‡ +1 Ø¥Ø°Ø§ Ø§Ø±ØªÙØ¹ Ø§Ù„Ø³Ø¹Ø±ØŒ -1 Ø¥Ø°Ø§ Ù‡Ø¨Ø·
        price_diff = df["Close"].diff()
        direction = np.sign(price_diff).replace(0, 1)  # treat flat as +1 Ù„ØªØ¬Ù†Ø¨ 0
        df["OBV"] = (df["Volume"] * direction).cumsum()
        df["Volume_Price_Trend"] = (df["Close"].pct_change().fillna(0) * df["Volume"]).cumsum()

        # ------------------- Ø¥Ø¶Ø§ÙÙŠØ© -------------------
        df["ROC"] = df["Close"].pct_change(periods=14) * 100
        df["Williams_R"] = WilliamsRIndicator(
            high=df["High"], low=df["Low"], close=df["Close"], lbp=14
        ).williams_r()

        # Stochastic
        stoch = StochasticOscillator(
            high=df["High"], low=df["Low"], close=df["Close"], window=14, smooth_window=3
        )
        df["Stoch_K"] = stoch.stoch()
        df["Stoch_D"] = stoch.stoch_signal()

        # Ichimoku Cloud
        ich = IchimokuIndicator(
            high=df["High"], low=df["Low"], window1=9, window2=26, window3=52
        )
        df["Tenkan_sen"] = ich.ichimoku_conversion_line()
        df["Kijun_sen"] = ich.ichimoku_base_line()
        df["Senkou_Span_A"] = ich.ichimoku_a()
        df["Senkou_Span_B"] = ich.ichimoku_b()

        logger.info("âœ… Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ØªÙ‚Ù†ÙŠØ© Ø£ÙØ¶ÙŠÙØª")
        return df.dropna()

    # ------------------------------------------------------------------
    # 4ï¸âƒ£ Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ø¯Ø¹Ù… ÙˆØ§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø©
    # ------------------------------------------------------------------
    def calculate_support_resistance(
        self, data: pd.DataFrame, window: int = 20
    ) -> Dict[str, Any]:
        """Ø­Ø³Ø§Ø¨ Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ø¯Ø¹Ù…/Ø§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø© Ø§Ù„Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ©."""
        try:
            recent = data.tail(window * 3)

            # Ø§Ù„Ù‚Ù…Ù… ÙˆØ§Ù„Ù‚ÙŠØ¹Ø§Ù† (Ù†Ø§ÙØ°Ø© 5 Ø£ÙŠØ§Ù…)
            highs = recent["High"].rolling(5, center=True).max() == recent["High"]
            lows = recent["Low"].rolling(5, center=True).min() == recent["Low"]

            resistance_levels = recent.loc[highs, "High"].nlargest(3).astype(float).tolist()
            support_levels = recent.loc[lows, "Low"].nsmallest(3).astype(float).tolist()

            price = data["Close"].iloc[-1]

            # Ø£Ù‚Ø±Ø¨ Ù…Ø³ØªÙˆÙŠØ§Øª
            nearest_res = min([r for r in resistance_levels if r > price], default=None)
            nearest_sup = max([s for s in support_levels if s < price], default=None)

            return {
                "resistance_levels": [round(r, 2) for r in resistance_levels],
                "support_levels": [round(s, 2) for s in support_levels],
                "nearest_resistance": round(nearest_res, 2) if nearest_res else None,
                "nearest_support": round(nearest_sup, 2) if nearest_sup else None,
                "price_to_resistance": round(((nearest_res - price) / price * 100), 2)
                if nearest_res
                else None,
                "price_to_support": round(((price - nearest_sup) / price * 100), 2)
                if nearest_sup
                else None,
            }
        except Exception as exc:
            logger.exception("Support/Resistance calculation failed")
            return {}

    # ------------------------------------------------------------------
    # 5ï¸âƒ£ Ù…Ø³ØªÙˆÙŠØ§Øª ÙÙŠØ¨ÙˆÙ†Ø§ØªØ´ÙŠ
    # ------------------------------------------------------------------
    def calculate_fibonacci_levels(self, data: pd.DataFrame, periods: int = 50) -> Dict[str, Any]:
        """Ø­Ø³Ø§Ø¨ Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„ÙÙŠØ¨ÙˆÙ†Ø§ØªØ´ÙŠ Ù…Ø¹ ØªØ­Ù„ÙŠÙ„ Ù…ÙˆØ¶Ø¹ Ø§Ù„Ø³Ø¹Ø±."""
        try:
            recent = data.tail(periods)
            high, low = recent["High"].max(), recent["Low"].min()
            diff = high - low
            price = data["Close"].iloc[-1]

            fibs = {
                "high": round(high, 2),
                "low": round(low, 2),
                "fib_23_6": round(high - diff * 0.236, 2),
                "fib_38_2": round(high - diff * 0.382, 2),
                "fib_50_0": round(high - diff * 0.5, 2),
                "fib_61_8": round(high - diff * 0.618, 2),
                "fib_78_6": round(high - diff * 0.786, 2),
            }

            # ØªØ­Ù„ÙŠÙ„ Ø³Ø±ÙŠØ¹ Ù„Ù„Ù…ÙˆØ¶Ø¹
            if price > fibs["fib_23_6"]:
                analysis = "Ø§Ù„Ø³Ø¹Ø± ÙÙˆÙ‚ 23.6% - Ø§ØªØ¬Ø§Ù‡ ØµØ§Ø¹Ø¯ Ù‚ÙˆÙŠ"
            elif price > fibs["fib_38_2"]:
                analysis = "Ø§Ù„Ø³Ø¹Ø± ÙÙˆÙ‚ 38.2% - Ø§ØªØ¬Ø§Ù‡ ØµØ§Ø¹Ø¯ Ù…Ø¹ØªØ¯Ù„"
            elif price > fibs["fib_50_0"]:
                analysis = "Ø§Ù„Ø³Ø¹Ø± ÙÙˆÙ‚ 50% - Ù…Ù†Ø·Ù‚Ø© Ù…Ø­Ø§ÙŠØ¯Ø©"
            elif price > fibs["fib_61_8"]:
                analysis = "Ø§Ù„Ø³Ø¹Ø± ÙÙˆÙ‚ 61.8% - Ø¶Ø¹Ù Ù†Ø³Ø¨ÙŠ"
            else:
                analysis = "Ø§Ù„Ø³Ø¹Ø± ØªØ­Øª 61.8% - Ø§ØªØ¬Ø§Ù‡ Ù‡Ø§Ø¨Ø· Ù…Ø­ØªÙ…Ù„"

            fibs["analysis"] = analysis
            fibs["current_position"] = round(((price - low) / diff * 100), 2)
            return fibs
        except Exception as exc:
            logger.exception("Fibonacci calculation failed")
            return {}

    # ------------------------------------------------------------------
    # 6ï¸âƒ£ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ÙŠØ© Ù…Ù† FRED (Ø£Ùˆ Ù…Ø­Ø§ÙƒØ§Ø©)
    # ------------------------------------------------------------------
    def fetch_economic_data(self) -> Dict[str, Any]:
        logger.info("ğŸ“Š Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ÙŠØ©...")
        econ = {"status": "simulated", "last_update": datetime.now().isoformat(), "indicators": {}}
        if not self.fred:
            logger.warning("FRED API key ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ â†’ Ø¥Ø±Ø¬Ø§Ø¹ Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø­Ø§ÙƒØ§Ø©")
            # Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø­Ø§ÙƒØ§Ø© (Ù†ÙØ³Ù‡Ø§ ÙÙŠ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©)
            econ["indicators"] = {
                "US_CPI": {
                    "value": 3.2,
                    "previous": 3.4,
                    "impact": "Ø¥ÙŠØ¬Ø§Ø¨ÙŠ Ù„Ù„Ø°Ù‡Ø¨ - ØªØ¶Ø®Ù… Ù…Ù†Ø®ÙØ¶",
                    "next_release": "2025-02-12",
                },
                "US_Interest_Rate": {
                    "value": 4.5,
                    "previous": 4.75,
                    "impact": "Ø¥ÙŠØ¬Ø§Ø¨ÙŠ Ù„Ù„Ø°Ù‡Ø¨ - Ø®ÙØ¶ Ø§Ù„ÙØ§Ø¦Ø¯Ø©",
                    "next_release": "2025-01-29 FOMC",
                },
                "US_NFP": {
                    "value": 256000,
                    "previous": 227000,
                    "impact": "Ø³Ù„Ø¨ÙŠ Ù„Ù„Ø°Ù‡Ø¨ - Ø³ÙˆÙ‚ Ø¹Ù…Ù„ Ù‚ÙˆÙŠ",
                    "next_release": "2025-02-07",
                },
                "DXY_Index": {
                    "value": 108.5,
                    "trend": "Ù‡Ø§Ø¨Ø·",
                    "impact": "Ø¥ÙŠØ¬Ø§Ø¨ÙŠ Ù„Ù„Ø°Ù‡Ø¨ - Ø¶Ø¹Ù Ø§Ù„Ø¯ÙˆÙ„Ø§Ø±",
                },
                "Geopolitical_Risk": {
                    "level": "Ù…ØªÙˆØ³Ø·",
                    "events": ["ØªÙˆØªØ±Ø§Øª ØªØ¬Ø§Ø±ÙŠØ©", "Ù‚Ù„Ù‚ Ù…Ù† Ø§Ù„ØªØ¶Ø®Ù…"],
                    "impact": "Ù…Ø­Ø§ÙŠØ¯ Ø¥Ù„Ù‰ Ø¥ÙŠØ¬Ø§Ø¨ÙŠ Ù„Ù„Ø°Ù‡Ø¨",
                },
            }
        else:
            try:
                # CPI (Ø§Ù„Ù…Ø¤Ø´Ø± Ø§Ù„Ø¹Ø§Ù… Ù„Ù„Ù…Ø³ØªÙ‡Ù„ÙƒÙŠÙ†)
                cpi_series = self.fred.get_series(
                    "CPILFESL", observation_start=datetime.now() - timedelta(days=60)
                )
                cpi = round(cpi_series.iloc[-1], 2)
                cpi_prev = round(cpi_series.iloc[-2], 2)

                # Ù…Ø¹Ø¯Ù„ Ø§Ù„ÙØ§Ø¦Ø¯Ø© Ø§Ù„ÙÙŠØ¯Ø±Ø§Ù„ÙŠØ©
                fed_series = self.fred.get_series(
                    "FEDFUNDS", observation_start=datetime.now() - timedelta(days=60)
                )
                fed = round(fed_series.iloc[-1], 2)
                fed_prev = round(fed_series.iloc[-2], 2)

                # ØªÙˆØ¸ÙŠÙ ØºÙŠØ± Ø²Ø±Ø§Ø¹ÙŠ (NFP)
                nfp_series = self.fred.get_series(
                    "PAYEMS", observation_start=datetime.now() - timedelta(days=30)
                )
                nfp = int(nfp_series.iloc[-1])
                nfp_prev = int(nfp_series.iloc[-2])

                econ["status"] = "real"
                econ["indicators"] = {
                    "US_CPI": {
                        "value": cpi,
                        "previous": cpi_prev,
                        "impact": "Ø¥ÙŠØ¬Ø§Ø¨ÙŠ Ù„Ù„Ø°Ù‡Ø¨ - ØªØ¶Ø®Ù… Ù…Ù†Ø®ÙØ¶"
                        if cpi < cpi_prev
                        else "Ø³Ù„Ø¨ÙŠ Ù„Ù„Ø°Ù‡Ø¨ - ØªØ¶Ø®Ù… Ù…Ø±ØªÙØ¹",
                        "next_release": "2025-02-12",
                    },
                    "US_Interest_Rate": {
                        "value": fed,
                        "previous": fed_prev,
                        "impact": "Ø¥ÙŠØ¬Ø§Ø¨ÙŠ Ù„Ù„Ø°Ù‡Ø¨ - Ø®ÙØ¶ Ø§Ù„ÙØ§Ø¦Ø¯Ø©"
                        if fed < fed_prev
                        else "Ø³Ù„Ø¨ÙŠ Ù„Ù„Ø°Ù‡Ø¨ - Ø±ÙØ¹ Ø§Ù„ÙØ§Ø¦Ø¯Ø©",
                        "next_release": "2025-01-29 FOMC",
                    },
                    "US_NFP": {
                        "value": nfp,
                        "previous": nfp_prev,
                        "impact": "Ø¥ÙŠØ¬Ø§Ø¨ÙŠ Ù„Ù„Ø°Ù‡Ø¨ - Ø§Ù†Ø®ÙØ§Ø¶ Ø§Ù„ØªÙˆØ¸ÙŠÙ"
                        if nfp < nfp_prev
                        else "Ø³Ù„Ø¨ÙŠ Ù„Ù„Ø°Ù‡Ø¨ - Ø³ÙˆÙ‚ Ø¹Ù…Ù„ Ù‚ÙˆÙŠ",
                        "next_release": "2025-02-07",
                    },
                    "DXY_Index": {
                        "value": 108.5,
                        "trend": "Ù‡Ø§Ø¨Ø·",
                        "impact": "Ø¥ÙŠØ¬Ø§Ø¨ÙŠ Ù„Ù„Ø°Ù‡Ø¨ - Ø¶Ø¹Ù Ø§Ù„Ø¯ÙˆÙ„Ø§Ø±",
                    },
                }

                # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ£Ø«ÙŠØ± Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ
                pos = sum(
                    1 for i in econ["indicators"].values() if "Ø¥ÙŠØ¬Ø§Ø¨ÙŠ" in i["impact"]
                )
                neg = sum(
                    1 for i in econ["indicators"].values() if "Ø³Ù„Ø¨ÙŠ" in i["impact"]
                )
                if pos > neg:
                    econ["overall_impact"] = "Ø¥ÙŠØ¬Ø§Ø¨ÙŠ Ù„Ù„Ø°Ù‡Ø¨"
                    econ["score"] = pos - neg
                elif neg > pos:
                    econ["overall_impact"] = "Ø³Ù„Ø¨ÙŠ Ù„Ù„Ø°Ù‡Ø¨"
                    econ["score"] = pos - neg
                else:
                    econ["overall_impact"] = "Ù…Ø­Ø§ÙŠØ¯"
                    econ["score"] = 0

            except Exception as exc:
                logger.exception("Failed to fetch real economic data")
                econ["status"] = "error"
                econ["error"] = str(exc)

        return econ

    # ------------------------------------------------------------------
    # 7ï¸âƒ£ Ø¬Ù„Ø¨ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± ÙˆØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±
    # ------------------------------------------------------------------
    def fetch_news(self) -> Dict[str, Any]:
        logger.info("ğŸ“° Ø¬Ù„Ø¨ ÙˆØªØ­Ù„ÙŠÙ„ Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ø°Ù‡Ø¨...")
        if not self.news_api_key:
            logger.warning("NEWS_API_KEY ØºÙŠØ± Ù…ÙØ¹Ø±Ù‘ÙÙ â†’ ØªØ®Ø·ÙŠ Ø¬Ù„Ø¨ Ø§Ù„Ø£Ø®Ø¨Ø§Ø±")
            return {"status": "no_api_key", "message": "Ù…ÙØªØ§Ø­ NewsAPI ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯"}

        try:
            keywords = (
                '"gold price" OR "XAU/USD" OR "federal reserve interest" '
                'OR "US inflation" OR "FOMC meeting"'
            )
            url = (
                f"https://newsapi.org/v2/everything?"
                f"q={keywords}&language=en&sortBy=publishedAt&pageSize=30&apiKey={self.news_api_key}"
            )
            resp = requests.get(url, timeout=15)
            resp.raise_for_status()
            articles = resp.json().get("articles", [])

            # ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ø£Ø«Ø±
            high_kw = [
                "federal reserve",
                "fed",
                "interest rate",
                "fomc",
                "inflation",
                "cpi",
                "employment",
                "nfp",
                "rate decision",
                "policy",
            ]
            med_kw = ["dollar", "dxy", "treasury", "geopolitical", "crisis", "war"]
            gold_kw = ["gold", "xau", "precious metal", "bullion"]

            categorized = {"critical": [], "high_impact": [], "medium_impact": [], "gold_specific": []}

            for art in articles:
                title = art.get("title", "")
                if not title:
                    continue
                description = art.get("description") or ""
                txt = f"{title} {description}".lower()

                item = {
                    "title": title[:150],
                    "source": art.get("source", {}).get("name", "Unknown"),
                    "published": art.get("publishedAt", ""),
                    "url": art.get("url", ""),
                    "impact": None,
                    "sentiment": None,
                }

                # ------------------- ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø£Ø«Ø± -------------------
                if any(kw in txt for kw in ["rate decision", "fomc decision", "emergency"]):
                    cat = "critical"
                elif any(kw in txt for kw in high_kw):
                    cat = "high_impact"
                elif any(kw in txt for kw in med_kw):
                    cat = "medium_impact"
                elif any(kw in txt for kw in gold_kw):
                    cat = "gold_specific"
                else:
                    cat = "medium_impact"

                # ------------------- ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± -------------------
                # VADER Ù„Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©
                vader_score = self.sentiment_analyzer.polarity_scores(txt)["compound"]
                if vader_score >= 0.05:
                    sentiment = "Ø¥ÙŠØ¬Ø§Ø¨ÙŠ"
                elif vader_score <= -0.05:
                    sentiment = "Ø³Ù„Ø¨ÙŠ"
                else:
                    sentiment = "Ù…Ø­Ø§ÙŠØ¯"

                # fallback Ø¹Ø±Ø¨Ù‰ (Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø³ÙŠØ·Ø©)
                if not sentiment:
                    pos_ar = ["Ø§Ø±ØªÙØ§Ø¹", "Ø²ÙŠØ§Ø¯Ø©", "Ù†Ù…Ùˆ", "Ù‚ÙˆØ©"]
                    neg_ar = ["Ù‡Ø¨ÙˆØ·", "Ø§Ù†Ø®ÙØ§Ø¶", "Ø¶Ø¹Ù", "Ø®Ø³Ø§Ø±Ø©"]
                    pos_cnt = sum(p in txt for p in pos_ar)
                    neg_cnt = sum(n in txt for n in neg_ar)
                    sentiment = "Ø¥ÙŠØ¬Ø§Ø¨ÙŠ" if pos_cnt > neg_cnt else ("Ø³Ù„Ø¨ÙŠ" if neg_cnt > pos_cnt else "Ù…Ø­Ø§ÙŠØ¯")

                item["impact"] = cat.replace("_", " ")
                item["sentiment"] = sentiment
                categorized[cat].append(item)

            # Ø®Ù„Ø§ØµØ© Ø§Ù„Ø£Ø®Ø¨Ø§Ø±
            total = sum(len(v) for v in categorized.values())
            summary = {
                "total_relevant_news": total,
                "critical_count": len(categorized["critical"]),
                "high_impact_count": len(categorized["high_impact"]),
                "overall_sentiment": self._aggregate_news_sentiment(categorized),
            }

            return {
                "status": "success",
                "summary": summary,
                "categorized_news": {k: v[:3] for k, v in categorized.items() if v},
            }

        except Exception as exc:
            logger.exception("News fetching failed")
            return {"status": "error", "message": str(exc)}

    def _aggregate_news_sentiment(self, grouped: Dict[str, List[Dict[str, Any]]]) -> str:
        """Ù…Ø¬Ù…ÙˆØ¹ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ù…Ù† Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ù…ØµÙ†ÙØ©."""
        sentiments = [
            n["sentiment"]
            for lst in grouped.values()
            for n in lst
            if n.get("sentiment")
        ]
        if not sentiments:
            return "Ù…Ø­Ø§ÙŠØ¯"
        pos = sentiments.count("Ø¥ÙŠØ¬Ø§Ø¨ÙŠ")
        neg = sentiments.count("Ø³Ù„Ø¨ÙŠ")
        if pos > neg:
            return "Ø¥ÙŠØ¬Ø§Ø¨ÙŠ Ù„Ù„Ø°Ù‡Ø¨"
        if neg > pos:
            return "Ø³Ù„Ø¨ÙŠ Ù„Ù„Ø°Ù‡Ø¨"
        return "Ù…Ø­Ø§ÙŠØ¯"

    # ------------------------------------------------------------------
    # 8ï¸âƒ£ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø·Ø§Øª Ù…Ø¹ Ø§Ù„Ø£ØµÙˆÙ„
    # ------------------------------------------------------------------
    def analyze_correlations(self, market_data: Dict[str, pd.DataFrame]) -> Dict[str, Any]:
        logger.info("ğŸ”— ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø·Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…...")
        try:
            daily = market_data["daily"]
            corrs, strength, interp = {}, {}, {}

            if hasattr(daily.columns, "levels"):
                assets = daily.columns.get_level_values(0).unique()
                gold_sym = (
                    self.symbols["gold"]
                    if self.symbols["gold"] in assets
                    else self.symbols["gold_etf"]
                )
                if gold_sym not in assets:
                    raise GoldAnalyzerError("Gold symbol not in daily data")

                gold_close = daily[gold_sym]["Close"].dropna()

                for name, sym in self.symbols.items():
                    if name in ["gold", "gold_etf"]:
                        continue
                    if sym not in assets:
                        continue
                    asset_close = daily[sym]["Close"].dropna()
                    idx = gold_close.index.intersection(asset_close.index)
                    if len(idx) < 30:
                        continue
                    corr = gold_close.loc[idx].corr(asset_close.loc[idx])
                    if pd.isna(corr):
                        continue
                    corr = round(corr, 3)
                    corrs[name] = corr

                    # Ù‚ÙˆØ© Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø·
                    if abs(corr) > 0.7:
                        strength[name] = "Ù‚ÙˆÙŠ Ø¬Ø¯Ø§Ù‹"
                    elif abs(corr) > 0.5:
                        strength[name] = "Ù‚ÙˆÙŠ"
                    elif abs(corr) > 0.3:
                        strength[name] = "Ù…ØªÙˆØ³Ø·"
                    else:
                        strength[name] = "Ø¶Ø¹ÙŠÙ"

                    # ØªÙØ³ÙŠØ± Ù„Ø¨Ø¹Ø¶ Ø§Ù„Ø£ØµÙˆÙ„ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
                    if name == "dxy":
                        if corr < -0.5:
                            interp[name] = "Ø§Ø±ØªØ¨Ø§Ø· Ø¹ÙƒØ³ÙŠ Ù‚ÙˆÙŠ - Ø¥ÙŠØ¬Ø§Ø¨ÙŠ Ù„Ù„Ø°Ù‡Ø¨ Ø¹Ù†Ø¯ Ø¶Ø¹Ù Ø§Ù„Ø¯ÙˆÙ„Ø§Ø±"
                        elif corr < -0.3:
                            interp[name] = "Ø§Ø±ØªØ¨Ø§Ø· Ø¹ÙƒØ³ÙŠ Ù…Ø¹ØªØ¯Ù„ - ÙØ±ØµØ© Ù…Ø­ØªÙ…Ù„Ø©"
                        else:
                            interp[name] = "Ø§Ø±ØªØ¨Ø§Ø· Ø¶Ø¹ÙŠÙ"
                    elif name == "vix":
                        interp[name] = "Ø§Ù„Ø°Ù‡Ø¨ ÙŠØ³ØªÙÙŠØ¯ Ù…Ù† Ø§Ù„ØªÙ‚Ù„Ø¨Ø§Øª" if corr > 0.3 else "ØªØ£Ø«ÙŠØ± Ù…Ø­Ø¯ÙˆØ¯"
                    elif name == "oil":
                        interp[name] = "Ø§Ø±ØªØ¨Ø§Ø· Ù‚ÙˆÙŠ Ù…Ø¹ Ø§Ù„Ù†ÙØ· - Ù…Ø¤Ø´Ø± ØªØ¶Ø®Ù…" if abs(corr) > 0.5 else "Ø§Ø±ØªØ¨Ø§Ø· Ø¶Ø¹ÙŠÙ"

            return {"correlations": corrs, "strength_analysis": strength, "interpretation": interp}
        except Exception as exc:
            logger.exception("Correlation analysis failed")
            return {}

    # ------------------------------------------------------------------
    # 9ï¸âƒ£ ØªØ­Ù„ÙŠÙ„ Ø­Ø¬Ù… Ø§Ù„ØªØ¯Ø§ÙˆÙ„ (Ù…Ø­Ø³Ù‘Ù†)
    # ------------------------------------------------------------------
    def analyze_volume_profile(self, data: pd.DataFrame) -> Dict[str, Any]:
        logger.info("ğŸ“Š ØªØ­Ù„ÙŠÙ„ Ø­Ø¬Ù… Ø§Ù„ØªØ¯Ø§ÙˆÙ„...")
        try:
            latest = data.iloc[-1]
            avg_5 = data["Volume"].tail(5).mean()
            avg_20 = data["Volume"].tail(20).mean()
            vol_ratio = latest.get("Volume_Ratio", 1)

            if vol_ratio > 2.0:
                strength, signal = "Ù‚ÙˆÙŠ Ø¬Ø¯Ø§Ù‹", "Ø­Ø¬Ù… Ø§Ø³ØªØ«Ù†Ø§Ø¦ÙŠ - Ø§Ø­ØªÙ…Ø§Ù„ Ø­Ø±ÙƒØ© Ù‚ÙˆÙŠØ©"
            elif vol_ratio > 1.5:
                strength, signal = "Ù‚ÙˆÙŠ", "Ø­Ø¬Ù… ÙÙˆÙ‚ Ø§Ù„Ù…ØªÙˆØ³Ø· - Ø§Ù‡ØªÙ…Ø§Ù… Ù…ØªØ²Ø§ÙŠØ¯"
            elif vol_ratio > 0.8:
                strength, signal = "Ø·Ø¨ÙŠØ¹ÙŠ", "Ø­Ø¬Ù… Ø·Ø¨ÙŠØ¹ÙŠ - Ù„Ø§ Ø¥Ø´Ø§Ø±Ø§Øª Ø®Ø§ØµØ©"
            else:
                strength, signal = "Ø¶Ø¹ÙŠÙ", "Ø­Ø¬Ù… Ø¶Ø¹ÙŠÙ - Ø­Ø°Ø± Ù…Ù† Ø§Ù„Ø­Ø±ÙƒØ© Ø§Ù„ÙˆÙ‡Ù…ÙŠØ©"

            obv_trend = "ØµØ§Ø¹Ø¯" if data["OBV"].iloc[-1] > data["OBV"].iloc[-5] else "Ù‡Ø§Ø¨Ø·"

            return {
                "current_volume": int(latest.get("Volume", 0)),
                "avg_volume_5": int(avg_5),
                "avg_volume_20": int(avg_20),
                "volume_ratio": round(vol_ratio, 2),
                "volume_strength": strength,
                "volume_signal": signal,
                "obv_trend": obv_trend,
                "volume_price_correlation": "Ø¥ÙŠØ¬Ø§Ø¨ÙŠ"
                if (latest["Close"] > data["Close"].iloc[-2] and int(latest.get("Volume", 0)) > avg_20)
                else "Ø³Ù„Ø¨ÙŠ",
            }
        except Exception as exc:
            logger.exception("Volume profile analysis failed")
            return {}

    # ------------------------------------------------------------------
    # 10ï¸âƒ£ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
    # ------------------------------------------------------------------
    def generate_professional_signals(
        self,
        tech_data: pd.DataFrame,
        correlations: Dict[str, Any],
        volume: Dict[str, Any],
        fib_levels: Dict[str, Any],
        support_resistance: Dict[str, Any],
        economic_data: Dict[str, Any],
        news_analysis: Dict[str, Any],
    ) -> Dict[str, Any]:
        logger.info("ğŸ¯ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©...")
        try:
            latest = tech_data.iloc[-1]
            prev = tech_data.iloc[-2]

            scores: Dict[str, float] = {
                "trend": 0,
                "momentum": 0,
                "volume": 0,
                "fibonacci": 0,
                "correlation": 0,
                "support_resistance": 0,
                "economic": 0,
                "news": 0,
                "ma_cross": 0,
            }

            # ---------- 1. Ø§Ù„Ø§ØªØ¬Ø§Ù‡ ----------
            if latest["Close"] > latest["SMA_200"]:
                scores["trend"] += 2
                if latest["Close"] > latest["SMA_50"]:
                    scores["trend"] += 1
                    if latest["Close"] > latest["SMA_20"]:
                        scores["trend"] += 1
            else:
                scores["trend"] -= 2
                if latest["Close"] < latest["SMA_50"]:
                    scores["trend"] -= 1
                    if latest["Close"] < latest["SMA_20"]:
                        scores["trend"] -= 1

            # Golden / Death cross
            if latest.get("Golden_Cross", 0) == 1:
                scores["ma_cross"] = 3
            elif latest.get("Death_Cross", 0) == 1:
                scores["ma_cross"] = -3

            # ---------- 2. Ø§Ù„Ø²Ø®Ù… ----------
            if latest["MACD"] > latest["MACD_Signal"]:
                scores["momentum"] += 1
                if latest["MACD_Histogram"] > prev["MACD_Histogram"]:
                    scores["momentum"] += 1
            else:
                scores["momentum"] -= 1
                if latest["MACD_Histogram"] < prev["MACD_Histogram"]:
                    scores["momentum"] -= 1

            rsi = latest.get("RSI", 50)
            if 30 <= rsi <= 70:
                if 45 <= rsi <= 55:
                    scores["momentum"] += 0.5
                elif rsi > 55:
                    scores["momentum"] += 1
                else:
                    scores["momentum"] -= 0.5
            elif rsi < 30:
                scores["momentum"] += 2
            else:  # rsi > 70
                scores["momentum"] -= 2

            if latest.get("Stoch_K", 50) > latest.get("Stoch_D", 50):
                scores["momentum"] += 0.5

            # ---------- 3. Ø§Ù„Ø­Ø¬Ù… ----------
            vol_str = volume.get("volume_strength", "")
            if vol_str == "Ù‚ÙˆÙŠ Ø¬Ø¯Ø§Ù‹":
                scores["volume"] = 3
            elif vol_str == "Ù‚ÙˆÙŠ":
                scores["volume"] = 2
            elif vol_str == "Ø·Ø¨ÙŠØ¹ÙŠ":
                scores["volume"] = 0
            else:
                scores["volume"] = -1

            if volume.get("obv_trend") == "ØµØ§Ø¹Ø¯":
                scores["volume"] += 1

            # ---------- 4. ÙÙŠØ¨ÙˆÙ†Ø§ØªØ´ÙŠ ----------
            price = latest["Close"]
            if price > fib_levels.get("fib_38_2", 0):
                scores["fibonacci"] = 2
            elif price > fib_levels.get("fib_50_0", 0):
                scores["fibonacci"] = 1
            elif price > fib_levels.get("fib_61_8", 0):
                scores["fibonacci"] = -1
            else:
                scores["fibonacci"] = -2

            # ---------- 5. Ø§Ù„Ø¯Ø¹Ù… / Ø§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø© ----------
            if support_resistance.get("price_to_support") and support_resistance["price_to_support"] < 2:
                scores["support_resistance"] = 2
            elif support_resistance.get("price_to_resistance") and support_resistance["price_to_resistance"] < 2:
                scores["support_resistance"] = -2

            # ---------- 6. Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø· ----------
            dxy_corr = correlations.get("correlations", {}).get("dxy", 0)
            if dxy_corr < -0.7:
                scores["correlation"] = 2
            elif dxy_corr < -0.5:
                scores["correlation"] = 1
            elif dxy_corr > 0.5:
                scores["correlation"] = -1

            # ---------- 7. Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ÙŠØ© ----------
            econ_score = economic_data.get("score", 0)
            scores["economic"] = max(min(econ_score, 3), -3)

            # ---------- 8. Ø§Ù„Ø£Ø®Ø¨Ø§Ø± ----------
            if news_analysis.get("status") == "success":
                sentiment = news_analysis.get("summary", {}).get("overall_sentiment", "Ù…Ø­Ø§ÙŠØ¯")
                if sentiment == "Ø¥ÙŠØ¬Ø§Ø¨ÙŠ Ù„Ù„Ø°Ù‡Ø¨":
                    scores["news"] = 2
                elif sentiment == "Ø³Ù„Ø¨ÙŠ Ù„Ù„Ø°Ù‡Ø¨":
                    scores["news"] = -2

                if news_analysis.get("summary", {}).get("critical_count", 0) > 0:
                    scores["news"] *= 2  # ØªØ¶Ø§Ø¹Ù ØªØ£Ø«ÙŠØ± Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ø­Ø±Ø¬Ø©

            # ---------- Ø§Ù„ÙˆØ²Ù† Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ ----------
            weights = {
                "trend": 0.25,
                "momentum": 0.20,
                "volume": 0.15,
                "fibonacci": 0.10,
                "correlation": 0.05,
                "support_resistance": 0.10,
                "economic": 0.10,
                "news": 0.05,
                "ma_cross": 0.10,
            }

            total_score = sum(scores[k] * weights.get(k, 0) for k in scores)

            # ---------- Ø§Ù„Ø¥Ø´Ø§Ø±Ø© ----------
            if total_score >= 2.0:
                signal, confidence, action = "Strong Buy", "Very High", "Ø´Ø±Ø§Ø¡ Ù‚ÙˆÙŠ - Ø­Ø¬Ù… ÙƒØ¨ÙŠØ±"
            elif total_score >= 1.0:
                signal, confidence, action = "Buy", "High", "Ø´Ø±Ø§Ø¡ - Ø­Ø¬Ù… Ù…ØªÙˆØ³Ø·"
            elif total_score >= 0.3:
                signal, confidence, action = "Weak Buy", "Medium", "Ø´Ø±Ø§Ø¡ Ø­Ø°Ø± - Ø­Ø¬Ù… ØµØºÙŠØ±"
            elif total_score <= -2.0:
                signal, confidence, action = "Strong Sell", "Very High", "Ø¨ÙŠØ¹ Ù‚ÙˆÙŠ - Ø­Ø¬Ù… ÙƒØ¨ÙŠØ±"
            elif total_score <= -1.0:
                signal, confidence, action = "Sell", "High", "Ø¨ÙŠØ¹ - Ø­Ø¬Ù… Ù…ØªÙˆØ³Ø·"
            elif total_score <= -0.3:
                signal, confidence, action = "Weak Sell", "Medium", "Ø¨ÙŠØ¹ Ø­Ø°Ø± - Ø­Ø¬Ù… ØµØºÙŠØ±"
            else:
                signal, confidence, action = "Hold", "Low", "Ø§Ù†ØªØ¸Ø§Ø± - Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¥Ø´Ø§Ø±Ø© ÙˆØ§Ø¶Ø­Ø©"

            # ---------- Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ø®Ø§Ø·Ø± ----------
            atr = latest.get("ATR", latest["Close"] * 0.02)
            vol_percent = latest.get("ATR_Percent", 2)
            sl_mult = 1.5 if vol_percent < 1.5 else (2.0 if vol_percent < 2.5 else 2.5)

            risk = {
                "stop_loss_levels": {
                    "tight": round(latest["Close"] - (atr * sl_mult * 0.75), 2),
                    "conservative": round(latest["Close"] - (atr * sl_mult), 2),
                    "moderate": round(latest["Close"] - (atr * sl_mult * 1.5), 2),
                    "wide": round(latest["Close"] - (atr * sl_mult * 2), 2),
                },
                "profit_targets": {
                    "target_1": round(latest["Close"] + (atr * 1.5), 2),
                    "target_2": round(latest["Close"] + (atr * 3), 2),
                    "target_3": round(latest["Close"] + (atr * 5), 2),
                    "target_4": round(latest["Close"] + (atr * 8), 2),
                },
                "position_size_recommendation": self._calculate_position_size(
                    confidence, vol_percent
                ),
                "risk_reward_ratio": round(3 / sl_mult, 2),
                "max_risk_per_trade": "2%" if confidence in ["Very High", "High"] else "1%",
            }

            # ---------- Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„Ø¯Ø®ÙˆÙ„ ----------
            entry = self._generate_entry_strategy(scores, latest, support_resistance)

            # ---------- ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù†ØªÙŠØ¬Ø© ----------
            result = {
                "signal": signal,
                "confidence": confidence,
                "action_recommendation": action,
                "total_score": round(total_score, 2),
                "component_scores": scores,
                "current_price": round(latest["Close"], 2),
                "risk_management": risk,
                "entry_strategy": entry,
                "technical_summary": {
                    "rsi": round(latest.get("RSI", 0), 1),
                    "macd": round(latest.get("MACD", 0), 2),
                    "williams_r": round(latest.get("Williams_R", 0), 1),
                    "stoch_k": round(latest.get("Stoch_K", 0), 1),
                    "bb_position": round(latest.get("BB_Position", 0.5), 2),
                    "volume_ratio": round(latest.get("Volume_Ratio", 1), 2),
                },
                "key_levels": {
                    "sma_20": round(latest.get("SMA_20", 0), 2),
                    "sma_50": round(latest.get("SMA_50", 0), 2),
                    "sma_200": round(latest.get("SMA_200", 0), 2),
                    "bb_upper": round(latest.get("BB_Upper", 0), 2),
                    "bb_lower": round(latest.get("BB_Lower", 0), 2),
                },
            }
            return result

        except Exception as exc:
            logger.exception("Signal generation failed")
            return {"error": str(exc)}

    # ------------------------------------------------------------------
    # Ù…Ø³Ø§Ø¹Ø¯: Ø­Ø³Ø§Ø¨ Ø­Ø¬Ù… Ø§Ù„Ù…Ø±ÙƒØ²
    # ------------------------------------------------------------------
    def _calculate_position_size(self, confidence: str, volatility: float) -> str:
        if confidence == "Very High" and volatility < 2:
            return "ÙƒØ¨ÙŠØ± (75â€‘100% Ù…Ù† Ø±Ø£Ø³ Ø§Ù„Ù…Ø§Ù„ Ø§Ù„Ù…Ø®ØµØµ)"
        if confidence == "High" and volatility < 2.5:
            return "Ù…ØªÙˆØ³Ø·â€‘ÙƒØ¨ÙŠØ± (50â€‘75%)"
        if confidence == "High" or (confidence == "Medium" and volatility < 2):
            return "Ù…ØªÙˆØ³Ø· (25â€‘50%)"
        if confidence == "Medium":
            return "ØµØºÙŠØ± (10â€‘25%)"
        return "ØµØºÙŠØ± Ø¬Ø¯Ø§Ù‹ (5â€‘10%) Ø£Ùˆ Ø¹Ø¯Ù… Ø§Ù„Ø¯Ø®ÙˆÙ„"

    # ------------------------------------------------------------------
    # Ù…Ø³Ø§Ø¹Ø¯: Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„Ø¯Ø®ÙˆÙ„
    # ------------------------------------------------------------------
    def _generate_entry_strategy(
        self, scores: Dict[str, float], latest: pd.Series, support_resistance: Dict[str, Any]
    ) -> Dict[str, Any]:
        strategy = {"entry_type": "", "entry_zones": [], "conditions": [], "warnings": []}

        if scores["trend"] > 2 and scores["momentum"] > 1:
            strategy["entry_type"] = "Ø¯Ø®ÙˆÙ„ Ù‚ÙˆÙŠ - Ø§Ù„Ø³ÙˆÙ‚ ÙÙŠ Ø§ØªØ¬Ø§Ù‡ ÙˆØ§Ø¶Ø­"
            strategy["entry_zones"].append(f"Ø¯Ø®ÙˆÙ„ ÙÙˆØ±ÙŠ Ø¹Ù†Ø¯ {round(latest['Close'], 2)}")
        elif scores["support_resistance"] == 2:
            strategy["entry_type"] = "Ø¯Ø®ÙˆÙ„ Ù…Ù† Ø§Ù„Ø¯Ø¹Ù…"
            if support_resistance.get("nearest_support"):
                strategy["entry_zones"].append(
                    f"Ø§Ù†ØªØ¸Ø± Ø§Ø±ØªØ¯Ø§Ø¯ Ù…Ù† {support_resistance['nearest_support']}"
                )
        elif scores["momentum"] < -1:
            strategy["warnings"].append("âš ï¸ Ø°Ø±ÙˆØ© Ø´Ø±Ø§Ø¡ - Ø§Ù†ØªØ¸Ø± ØªØµØ­ÙŠØ­")
            strategy["entry_type"] = "Ø§Ù†ØªØ¸Ø§Ø± ØªØµØ­ÙŠØ­"
        else:
            strategy["entry_type"] = "Ø¯Ø®ÙˆÙ„ ØªØ¯Ø±ÙŠØ¬ÙŠ"
            strategy["entry_zones"].append("Ù‚Ø³Ù‘Ù… Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø¹Ù„Ù‰ 2â€‘3 Ù…Ø±Ø§Ø­Ù„")

        if latest.get("RSI", 50) > 70:
            strategy["conditions"].append("Ø§Ù†ØªØ¸Ø± RSI < 70")
        if latest.get("Volume_Ratio", 1) < 0.8:
            strategy["warnings"].append("âš ï¸ Ø­Ø¬Ù… Ø¶Ø¹ÙŠÙ - ØªØ£ÙƒÙŠØ¯ Ù…Ø·Ù„ÙˆØ¨")

        return strategy

    # ------------------------------------------------------------------
    # 11ï¸âƒ£ Ø§Ø®ØªØ¨Ø§Ø± Ø±Ø¬Ø¹ÙŠ Ø¨Ø³ÙŠØ· (Backâ€‘testing)
    # ------------------------------------------------------------------
    def _simple_backtest(self, technical_df: pd.DataFrame) -> Dict[str, Any]:
        logger.info("ğŸ”™ ØªØ´ØºÙŠÙ„ Ø§Ø®ØªØ¨Ø§Ø± Ø±Ø¬Ø¹ÙŠ Ù…Ø¨Ø³Ø·...")
        try:
            df = technical_df.copy()
            # Ù‚Ø§Ø¹Ø¯Ø©: Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø¹Ù†Ø¯Ù…Ø§ SMA20 > SMA50 Ùˆ RSI > 55 Ùˆ MACD > 0
            df["position"] = 0
            long_cond = (df["SMA_20"] > df["SMA_50"]) & (df["RSI"] > 55) & (df["MACD"] > 0)
            df.loc[long_cond, "position"] = 1
            df["position"] = df["position"].ffill().fillna(0)

            df["return"] = df["Close"].pct_change().fillna(0)
            df["strategy_return"] = df["position"].shift(1).fillna(0) * df["return"]

            total_ret = (1 + df["strategy_return"]).prod() - 1
            days = (df.index[-1] - df.index[0]).days
            annual_ret = (1 + total_ret) ** (365 / days) - 1 if days > 0 else 0

            # max drawdown
            cum_ret = (1 + df["strategy_return"]).cumprod()
            rolling_max = cum_ret.cummax()
            drawdown = (cum_ret - rolling_max) / rolling_max
            max_dd = drawdown.min()

            # win rate
            wins = (df["strategy_return"] > 0).sum()
            trades = df["position"].diff().abs().sum()  # Ø¹Ø¯Ø¯ Ù…Ø±Ø§Øª Ø§Ù„Ø¯Ø®ÙˆÙ„/Ø§Ù„Ø®Ø±ÙˆØ¬
            win_rate = wins / trades if trades > 0 else 0

            # Sharpe (riskâ€‘free = 0)
            sharpe = (
                df["strategy_return"].mean()
                / df["strategy_return"].std()
                * np.sqrt(252)
                if df["strategy_return"].std() != 0
                else 0
            )

            return {
                "total_return_%": round(total_ret * 100, 2),
                "annualized_return_%": round(annual_ret * 100, 2),
                "max_drawdown_%": round(max_dd * 100, 2),
                "win_rate_%": round(win_rate * 100, 2),
                "sharpe_ratio": round(sharpe, 2),
                "trading_days": days,
                "total_trades": int(trades),
            }
        except Exception as exc:
            logger.exception("Backâ€‘test failed")
            return {}

    # ------------------------------------------------------------------
    # 12ï¸âƒ£ ØªÙ‚Ø±ÙŠØ± Ø¨ØµØ±ÙŠ (Ù…Ø®Ø·Ø· Ø§Ù„Ø³Ø¹Ø± + Ù…Ø¤Ø´Ø±Ø§Øª)
    # ------------------------------------------------------------------
    def generate_visual_report(self, technical_df: pd.DataFrame, timestamp: str) -> str:
        logger.info("ğŸ–¼ï¸ Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± Ø¨ØµØ±ÙŠ...")
        try:
            plt.style.use("seaborn-darkgrid")
            fig, ax = plt.subplots(figsize=(12, 6))

            ax.plot(
                technical_df.index,
                technical_df["Close"],
                label="Close",
                color="black",
                linewidth=1,
            )
            ax.plot(
                technical_df.index,
                technical_df["SMA_20"],
                label="SMA 20",
                color="blue",
                linewidth=0.8,
            )
            ax.plot(
                technical_df.index,
                technical_df["SMA_50"],
                label="SMA 50",
                color="orange",
                linewidth=0.8,
            )
            ax.plot(
                technical_df.index,
                technical_df["EMA_9"],
                label="EMA 9",
                color="green",
                linewidth=0.8,
            )
            ax.plot(
                technical_df.index,
                technical_df["BB_Upper"],
                label="BB Upper",
                color="gray",
                linewidth=0.5,
                linestyle="--",
            )
            ax.plot(
                technical_df.index,
                technical_df["BB_Lower"],
                label="BB Lower",
                color="gray",
                linewidth=0.5,
                linestyle="--",
            )

            ax.set_title(f"Gold Price Chart â€“ {timestamp[:10]}")
            ax.set_xlabel("Date")
            ax.set_ylabel("Price (USD)")
            ax.legend()
            fig.autofmt_xdate()

            img_path = f"gold_chart_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
            plt.tight_layout()
            plt.savefig(img_path, dpi=150)
            plt.close(fig)

            logger.info("ğŸ–¼ï¸ ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù…Ø®Ø·Ø· ÙÙŠ %s", img_path)
            return img_path
        except Exception as exc:
            logger.exception("Visual report generation failed")
            return ""

    # ------------------------------------------------------------------
    # 13ï¸âƒ£ Ù…Ø±Ø­Ù„Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙƒØ§Ù…Ù„Ø© (run_analysis)
    # ------------------------------------------------------------------
    def run_analysis(self) -> Dict[str, Any]:
        logger.info("ğŸš€ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠ Ù„Ù„Ø°Ù‡Ø¨...")
        try:
            # 1ï¸âƒ£ Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            market_data = self.fetch_multi_timeframe_data()
            if market_data is None:
                raise GoldAnalyzerError("Data download failed")

            # 2ï¸âƒ£ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø°Ù‡Ø¨
            gold_daily = self.extract_gold_data(market_data)
            if gold_daily is None:
                raise GoldAnalyzerError("Gold extraction failed")

            # 3ï¸âƒ£ Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ØªÙ‚Ù†ÙŠØ©
            tech_df = self.calculate_technical_indicators(gold_daily)

            # 4ï¸âƒ£ ÙÙŠØ¨ÙˆÙ†Ø§ØªØ´ÙŠ + Ø¯Ø¹Ù…/Ù…Ù‚Ø§ÙˆÙ…Ø©
            fib_levels = self.calculate_fibonacci_levels(tech_df)
            sr_levels = self.calculate_support_resistance(tech_df)

            # 5ï¸âƒ£ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø­Ø¬Ù…
            vol_analysis = self.analyze_volume_profile(tech_df)

            # 6ï¸âƒ£ Ø§Ø±ØªØ¨Ø§Ø·Ø§Øª
            corr = self.analyze_correlations(market_data)

            # 7ï¸âƒ£ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù‚ØªØµØ§Ø¯ÙŠØ©
            econ = self.fetch_economic_data()

            # 8ï¸âƒ£ Ø£Ø®Ø¨Ø§Ø±
            news = self.fetch_news()

            # 9ï¸âƒ£ Ø¥Ø´Ø§Ø±Ø© Ù†Ù‡Ø§Ø¦ÙŠØ©
            signal = self.generate_professional_signals(
                tech_df, corr, vol_analysis, fib_levels, sr_levels, econ, news
            )

            # ğŸ”Ÿ Ø§Ø®ØªØ¨Ø§Ø± Ø±Ø¬Ø¹ÙŠ
            backtest = self._simple_backtest(tech_df)

            # ğŸ“ˆ ØªÙ‚Ø±ÙŠØ± Ø¨ØµØ±ÙŠ
            chart_path = self.generate_visual_report(tech_df, datetime.now().isoformat())

            # ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
            final_result = {
                "timestamp": datetime.now().isoformat(),
                "status": "success",
                "gold_analysis": signal,
                "fibonacci_levels": fib_levels,
                "support_resistance": sr_levels,
                "volume_analysis": vol_analysis,
                "market_correlations": corr,
                "economic_data": econ,
                "news_analysis": news,
                "backtest": backtest,
                "visual_report_path": chart_path,
                "market_summary": {
                    "last_update": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    "data_points": len(tech_df),
                    "timeframe": "Daily",
                    "market_condition": self._determine_market_condition(signal, vol_analysis),
                },
            }

            # Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ (JSON + ØªÙ‚Ø±ÙŠØ± Ù†ØµÙŠ)
            self.save_results(final_result)

            # Ø·Ø¨Ø§Ø¹Ø© ØªÙ‚Ø±ÙŠØ± Ù†ØµÙŠ Ù…Ø¨Ø³Ù‘Ø·
            print(self.generate_report(final_result))

            logger.info("âœ… Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ù…ÙƒØªÙ…Ù„ Ø¨Ù†Ø¬Ø§Ø­")
            return final_result

        except Exception as exc:
            logger.exception("ØªØ­Ù„ÙŠÙ„ ÙØ´Ù„")
            err_res = {
                "timestamp": datetime.now().isoformat(),
                "status": "error",
                "error": str(exc),
            }
            self.save_results(err_res)
            return err_res

    # ------------------------------------------------------------------
    # Ù…Ø³Ø§Ø¹Ø¯Ø©: ØªØ­Ø¯ÙŠØ¯ Ø­Ø§Ù„Ø© Ø§Ù„Ø³ÙˆÙ‚ Ø§Ù„Ø¹Ø§Ù…Ø©
    # ------------------------------------------------------------------
    def _determine_market_condition(self, signals: Dict[str, Any], volume: Dict[str, Any]) -> str:
        if signals.get("signal") in ["Strong Buy", "Buy"] and volume.get(
            "volume_strength"
        ) in ["Ù‚ÙˆÙŠ", "Ù‚ÙˆÙŠ Ø¬Ø¯Ø§Ù‹"]:
            return "ØµØ§Ø¹Ø¯ Ù‚ÙˆÙŠ"
        if signals.get("signal") in ["Strong Sell", "Sell"] and volume.get(
            "volume_strength"
        ) in ["Ù‚ÙˆÙŠ", "Ù‚ÙˆÙŠ Ø¬Ø¯Ø§Ù‹"]:
            return "Ù‡Ø§Ø¨Ø· Ù‚ÙˆÙŠ"
        if signals.get("signal") == "Hold":
            return "Ø¹Ø±Ø¶ÙŠ/Ù…Ø­Ø§ÙŠØ¯"
        return "Ù…ØªÙ‚Ù„Ø¨"

    # ------------------------------------------------------------------
    # ØªÙˆÙ„ÙŠØ¯ ØªÙ‚Ø±ÙŠØ± Ù†ØµÙŠ Ø´Ø§Ù…Ù„
    # ------------------------------------------------------------------
    def generate_report(self, analysis_result: Dict[str, Any]) -> str:
        try:
            lines = []
            lines.append("=" * 60)
            lines.append("ğŸ“Š ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠ Ù„Ù„Ø°Ù‡Ø¨")
            lines.append("=" * 60)
            lines.append(f"Ø§Ù„ØªØ§Ø±ÙŠØ®: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            lines.append("")

            if "gold_analysis" in analysis_result:
                ga = analysis_result["gold_analysis"]
                lines.append("ğŸ¯ Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©:")
                lines.append(f"  â€¢ Ø§Ù„Ø¥Ø´Ø§Ø±Ø©: {ga.get('signal', 'N/A')}")
                lines.append(f"  â€¢ Ø§Ù„Ø«Ù‚Ø©: {ga.get('confidence', 'N/A')}")
                lines.append(f"  â€¢ Ø§Ù„ØªÙˆØµÙŠØ©: {ga.get('action_recommendation', 'N/A')}")
                lines.append(f"  â€¢ Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ø­Ø§Ù„ÙŠ: ${ga.get('current_price', 'N/A')}")
                lines.append(f"  â€¢ Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ©: {ga.get('total_score', 'N/A')}")
                lines.append("")

                if "component_scores" in ga:
                    lines.append("ğŸ“ˆ ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ù…ÙƒÙˆÙ‘Ù†Ø§Øª:")
                    for comp, score in ga["component_scores"].items():
                        lines.append(f"  â€¢ {comp}: {score}")
                    lines.append("")

                if "risk_management" in ga:
                    rm = ga["risk_management"]
                    lines.append("âš ï¸ Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ø®Ø§Ø·Ø±:")
                    lines.append(
                        f"  â€¢ ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø© Ø§Ù„Ù…Ø­Ø§ÙØ¸: ${rm['stop_loss_levels'].get('conservative','N/A')}"
                    )
                    lines.append(f"  â€¢ Ù‡Ø¯Ù 1: ${rm['profit_targets'].get('target_1','N/A')}")
                    lines.append(f"  â€¢ Ø­Ø¬Ù… Ø§Ù„Ù…Ø±ÙƒØ²: {rm.get('position_size_recommendation','N/A')}")
                    lines.append("")

                if "entry_strategy" in ga:
                    es = ga["entry_strategy"]
                    lines.append("ğŸšª Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„Ø¯Ø®ÙˆÙ„:")
                    lines.append(f"  â€¢ Ø§Ù„Ù†ÙˆØ¹: {es.get('entry_type','')}")
                    if es.get("entry_zones"):
                        lines.append(f"  â€¢ Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„Ø¯Ø®ÙˆÙ„: {', '.join(es['entry_zones'])}")
                    if es.get("conditions"):
                        lines.append("  â€¢ Ø§Ù„Ø´Ø±ÙˆØ·:")
                        for c in es["conditions"]:
                            lines.append(f"    - {c}")
                    if es.get("warnings"):
                        lines.append("  â€¢ Ø§Ù„ØªØ­Ø°ÙŠØ±Ø§Øª:")
                        for w in es["warnings"]:
                            lines.append(f"    - {w}")
                    lines.append("")

            if "economic_data" in analysis_result:
                ed = analysis_result["economic_data"]
                lines.append("ğŸ’° Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ÙŠØ©:")
                lines.append(f"  â€¢ Ø§Ù„ØªØ£Ø«ÙŠØ± Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ: {ed.get('overall_impact','N/A')}")
                if "indicators" in ed:
                    for name, val in ed["indicators"].items():
                        lines.append(f"  â€¢ {name}: {val.get('value','N/A')} - {val.get('impact','')}")
                lines.append("")

            if "news_analysis" in analysis_result:
                na = analysis_result["news_analysis"]
                if na.get("status") == "success":
                    sm = na["summary"]
                    lines.append("ğŸ“° Ù…Ù„Ø®Øµ Ø§Ù„Ø£Ø®Ø¨Ø§Ø±:")
                    lines.append(f"  â€¢ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ø§Ù„Ø¹Ø§Ù…Ø©: {sm.get('overall_sentiment','N/A')}")
                    lines.append(f"  â€¢ Ø£Ø®Ø¨Ø§Ø± Ø­Ø±Ø¬Ø©: {sm.get('critical_count',0)}")
                    lines.append(f"  â€¢ Ø£Ø®Ø¨Ø§Ø± Ø¹Ø§Ù„ÙŠØ© Ø§Ù„ØªØ£Ø«ÙŠØ±: {sm.get('high_impact_count',0)}")
                    lines.append("")

            if "backtest" in analysis_result and analysis_result["backtest"]:
                bt = analysis_result["backtest"]
                lines.append("ğŸ”™ Ø§Ø®ØªØ¨Ø§Ø± Ø±Ø¬Ø¹ÙŠ Ù…Ø¨Ø³Ø·:")
                for k, v in bt.items():
                    lines.append(f"  â€¢ {k.replace('_',' ').title()}: {v}")
                lines.append("")

            if "visual_report_path" in analysis_result and analysis_result["visual_report_path"]:
                lines.append(f"ğŸ“ˆ Ù…Ø®Ø·Ø· Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ù…Ø­ÙÙˆØ¸ ÙÙŠ: {analysis_result['visual_report_path']}")
                lines.append("")

            lines.append("=" * 60)
            lines.append("Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„ØªÙ‚Ø±ÙŠØ±")
            return "\n".join(lines)
        except Exception as exc:
            logger.exception("Report generation failed")
            return f"Error generating report: {exc}"

    # ------------------------------------------------------------------
    # Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ (JSON + Ø£Ø±Ø´ÙØ© + ØªÙ‚Ø±ÙŠØ± Ù†ØµÙŠ)
    # ------------------------------------------------------------------
    def save_results(self, results: Dict[str, Any]) -> None:
        try:
            main_path = "gold_analysis.json"
            with open(main_path, "w", encoding="utf-8") as f:
                json.dump(results, f, ensure_ascii=False, indent=2, default=str)
            logger.info("ğŸ’¾ ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ %s", main_path)

            ts = datetime.now().strftime("%Y%m%d_%H%M%S")
            archive_path = f"gold_analysis_{ts}.json"
            with open(archive_path, "w", encoding="utf-8") as f:
                json.dump(results, f, ensure_ascii=False, indent=2, default=str)
            logger.info("ğŸ“ Ù†Ø³Ø®Ø© Ù…Ø¤Ø±Ø´ÙØ© Ù…Ø­ÙÙˆØ¸Ø© ÙÙŠ %s", archive_path)

            if results.get("status") == "success":
                txt_path = f"gold_report_{ts}.txt"
                with open(txt_path, "w", encoding="utf-8") as f:
                    f.write(self.generate_report(results))
                logger.info("ğŸ“„ ØªÙ… Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù†ØµÙŠ ÙÙŠ %s", txt_path)

        except Exception as exc:
            logger.exception("Failed to save results")


# ----------------------------------------------------------------------
# Entrypoint (Ø¨Ø¯ÙˆÙ† ØªØºÙŠÙŠØ±)
# ----------------------------------------------------------------------
def main():
    analyzer = ProfessionalGoldAnalyzer()
    analyzer.run_analysis()


if __name__ == "__main__":
    main()