#!/usr/bin/env python3
import yfinance as yf
import pandas as pd
import numpy as np
import requests
import json
import os
import sqlite3
import logging
from datetime import datetime, timedelta
from transformers import pipeline
import pandas_ta as ta
import warnings
from concurrent.futures import ThreadPoolExecutor
import time
from functools import lru_cache

warnings.filterwarnings('ignore')

# Ø¥Ø¹Ø¯Ø§Ø¯ logging Ù…Ø­Ø³Ù†
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('gold_analysis.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class OptimizedGoldAnalyzer:
    def __init__(self):
        self.symbols = {
            'gold': 'GC=F',
            'gold_etf': 'GLD', 
            'dxy': 'DX-Y.NYB',
            'vix': '^VIX',
            'treasury': '^TNX',
            'oil': 'CL=F',
            'spy': 'SPY'
        }
        
        self.news_api_key = os.getenv("NEWS_API_KEY")
        self.sentiment_pipeline = None
        self.db_path = "gold_analysis_history.db"
        
        # Ø¥Ø¹Ø¯Ø§Ø¯ Ø³Ø±ÙŠØ¹
        self._setup_database()
        self._load_sentiment_model()
        logger.info("ğŸš€ Ù…Ø­Ù„Ù„ Ø§Ù„Ø°Ù‡Ø¨ Ø§Ù„Ø³Ø±ÙŠØ¹ Ø¬Ø§Ù‡Ø²")

    def _setup_database(self):
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS analysis_history (
                    id INTEGER PRIMARY KEY,
                    timestamp_utc TEXT,
                    signal TEXT,
                    total_score REAL,
                    gold_price REAL,
                    signal_strength TEXT,
                    news_score REAL,
                    market_data TEXT
                )
            ''')
            
            conn.commit()
            conn.close()
        except Exception as e:
            logger.warning(f"ØªØ­Ø°ÙŠØ± Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {e}")

    def _load_sentiment_model(self):
        try:
            # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø±Ø© ÙˆØ§Ø­Ø¯Ø© ÙÙ‚Ø·
            self.sentiment_pipeline = pipeline(
                "sentiment-analysis", 
                model="ProsusAI/finbert",
                tokenizer="ProsusAI/finbert",
                return_all_scores=True
            )
        except Exception as e:
            logger.warning(f"ØªØ­Ø°ÙŠØ± Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±: {e}")

    @lru_cache(maxsize=1)
    def fetch_market_data_cached(self):
        """Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø¹ cache Ù„Ù„ØªØ³Ø±ÙŠØ¹"""
        try:
            logger.info("ğŸ“Š Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø³ÙˆÙ‚ (Ù…Ø­Ø³Ù†)...")
            
            symbols_list = list(self.symbols.values())
            data = yf.download(
                symbols_list, 
                period="1y", 
                interval="1d",
                threads=True,
                progress=False,  # Ø¥Ù„ØºØ§Ø¡ Ø´Ø±ÙŠØ· Ø§Ù„ØªÙ‚Ø¯Ù…
                show_errors=False
            )
            
            if data.empty:
                raise ValueError("Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙØ§Ø±ØºØ©")
                
            # ØªÙ†Ø¸ÙŠÙ Ø³Ø±ÙŠØ¹
            gold_col = ('Close', self.symbols['gold'])
            if gold_col not in data.columns:
                self.symbols['gold'] = 'GLD'
                gold_col = ('Close', 'GLD')
            
            data = data.dropna(subset=[gold_col])
            logger.info(f"âœ… Ø¬Ù„Ø¨ {len(data)} ÙŠÙˆÙ… Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
            return data
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {e}")
            return None

    def analyze_news_fast(self):
        """ØªØ­Ù„ÙŠÙ„ Ø£Ø®Ø¨Ø§Ø± Ø³Ø±ÙŠØ¹ ÙˆÙ…Ø­Ø³Ù†"""
        logger.info("ğŸ“° ØªØ­Ù„ÙŠÙ„ Ø£Ø®Ø¨Ø§Ø± Ø³Ø±ÙŠØ¹...")
        
        if not self.news_api_key or not self.sentiment_pipeline:
            return {"status": "skipped", "news_score": 0, "headlines": []}

        try:
            # Ø§Ø³ØªØ¹Ù„Ø§Ù… ÙˆØ§Ø­Ø¯ Ù…Ø­Ø³Ù†
            query = 'gold OR XAU OR "federal reserve" OR inflation OR "interest rate"'
            
            url = (
                f"https://newsapi.org/v2/everything?"
                f"q={query}&language=en&sortBy=publishedAt&pageSize=30&"
                f"from={(datetime.now() - timedelta(days=2)).date()}&"
                f"apiKey={self.news_api_key}"
            )
            
            response = requests.get(url, timeout=10)
            articles = response.json().get('articles', [])
            
            if not articles:
                return {"status": "no_articles", "news_score": 0, "headlines": []}
            
            # ÙÙ„ØªØ±Ø© Ø³Ø±ÙŠØ¹Ø©
            gold_keywords = ['gold', 'xau', 'bullion', 'fed', 'inflation', 'interest rate']
            relevant_articles = []
            
            for article in articles[:20]:  # Ù…Ø¹Ø§Ù„Ø¬Ø© 20 Ù…Ù‚Ø§Ù„ ÙÙ‚Ø·
                content = f"{article.get('title', '').lower()} {article.get('description', '').lower()}"
                if any(keyword in content for keyword in gold_keywords):
                    relevant_articles.append(article)
            
            if not relevant_articles:
                return {"status": "no_relevant", "news_score": 0, "headlines": []}
            
            # ØªØ­Ù„ÙŠÙ„ Ù…Ø´Ø§Ø¹Ø± Ø³Ø±ÙŠØ¹
            sentiment_scores = []
            processed_headlines = []
            
            for article in relevant_articles[:10]:  # Ø£ÙØ¶Ù„ 10 Ù…Ù‚Ø§Ù„Ø§Øª ÙÙ‚Ø·
                try:
                    text = article.get('description') or article.get('title') or ""
                    if len(text) < 10:
                        continue
                        
                    result = self.sentiment_pipeline(text[:200])[0]  # Ù†Øµ Ù…Ù‚ØµÙˆØ±
                    
                    pos_score = next((s['score'] for s in result if s['label'] == 'positive'), 0)
                    neg_score = next((s['score'] for s in result if s['label'] == 'negative'), 0)
                    
                    sentiment_scores.append(pos_score - neg_score)
                    processed_headlines.append({
                        'title': article['title'],
                        'source': article.get('source', {}).get('name', 'Unknown')
                    })
                    
                except Exception:
                    continue
            
            if sentiment_scores:
                avg_sentiment = np.mean(sentiment_scores)
                logger.info(f"ğŸ“Š ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø®Ø¨Ø§Ø±: {avg_sentiment:.3f}")
                
                return {
                    "status": "success",
                    "news_score": round(avg_sentiment, 3),
                    "headlines": processed_headlines[:5]
                }
            else:
                return {"status": "processing_failed", "news_score": 0, "headlines": []}
                
        except Exception as e:
            logger.warning(f"âš ï¸ ØªØ­Ø°ÙŠØ± Ø§Ù„Ø£Ø®Ø¨Ø§Ø±: {e}")
            return {"status": "error", "news_score": 0, "headlines": []}

    def calculate_fast_indicators(self, gold_data):
        """Ø­Ø³Ø§Ø¨ Ù…Ø¤Ø´Ø±Ø§Øª Ø£Ø³Ø§Ø³ÙŠØ© ÙÙ‚Ø· Ù„Ù„Ø³Ø±Ø¹Ø©"""
        try:
            # Ù…Ø¤Ø´Ø±Ø§Øª Ø£Ø³Ø§Ø³ÙŠØ© ÙÙ‚Ø·
            gold_data['SMA_20'] = gold_data['Close'].rolling(20).mean()
            gold_data['SMA_50'] = gold_data['Close'].rolling(50).mean()
            gold_data['SMA_200'] = gold_data['Close'].rolling(200).mean()
            
            # RSI Ø³Ø±ÙŠØ¹
            delta = gold_data['Close'].diff()
            gain = (delta.where(delta > 0, 0)).rolling(14).mean()
            loss = (-delta.where(delta < 0, 0)).rolling(14).mean()
            rs = gain / loss
            gold_data['RSI'] = 100 - (100 / (1 + rs))
            
            # MACD Ø¨Ø³ÙŠØ·
            ema12 = gold_data['Close'].ewm(span=12).mean()
            ema26 = gold_data['Close'].ewm(span=26).mean()
            gold_data['MACD'] = ema12 - ema26
            gold_data['MACD_Signal'] = gold_data['MACD'].ewm(span=9).mean()
            
            # ATR Ù„Ù„Ø³ØªÙˆØ¨ Ù„ÙˆØ³
            high_low = gold_data['High'] - gold_data['Low']
            high_close = np.abs(gold_data['High'] - gold_data['Close'].shift())
            low_close = np.abs(gold_data['Low'] - gold_data['Close'].shift())
            ranges = pd.concat([high_low, high_close, low_close], axis=1)
            true_range = ranges.max(axis=1)
            gold_data['ATR'] = true_range.rolling(14).mean()
            
            return gold_data.dropna()
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª: {e}")
            return gold_data

    def run_fast_analysis(self):
        """Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³Ø±ÙŠØ¹ Ø§Ù„Ø´Ø§Ù…Ù„"""
        start_time = time.time()
        logger.info("ğŸš€ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³Ø±ÙŠØ¹...")
        
        # Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        market_data = self.fetch_market_data_cached()
        if market_data is None:
            return {"status": "error", "error": "ÙØ´Ù„ Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"}
        
        # Ø¥Ø¹Ø¯Ø§Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø°Ù‡Ø¨
        gold_ticker = self.symbols['gold']
        gold_data = pd.DataFrame({
            'Open': market_data[('Open', gold_ticker)],
            'High': market_data[('High', gold_ticker)],
            'Low': market_data[('Low', gold_ticker)], 
            'Close': market_data[('Close', gold_ticker)],
            'Volume': market_data[('Volume', gold_ticker)]
        }).dropna()
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø³Ø±ÙŠØ¹
        gold_data = self.calculate_fast_indicators(gold_data)
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø¨Ø§Ù„ØªÙˆØ§Ø²ÙŠ
        news_analysis = self.analyze_news_fast()
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¥Ø´Ø§Ø±Ø©
        latest = gold_data.iloc[-1]
        current_price = latest['Close']
        
        # Ù†Ù‚Ø§Ø· Ø³Ø±ÙŠØ¹Ø©
        trend_score = 2 if current_price > latest['SMA_200'] else -2
        momentum_score = 1 if latest['MACD'] > latest['MACD_Signal'] else -1
        rsi_score = 1 if 30 < latest['RSI'] < 70 else 0
        
        # DXY correlation
        try:
            dxy_current = market_data[('Close', self.symbols['dxy'])].iloc[-1]
            vix_current = market_data[('Close', self.symbols['vix'])].iloc[-1]
        except:
            dxy_current = 100
            vix_current = 20
        
        correlation_score = 1 if dxy_current < 105 else -1
        news_score = news_analysis.get('news_score', 0) * 2
        
        # Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
        total_score = (trend_score * 0.4) + (momentum_score * 0.25) + (correlation_score * 0.2) + (news_score * 0.15)
        
        # Ø§Ù„Ø¥Ø´Ø§Ø±Ø©
        if total_score >= 1.5:
            signal, strength = "Buy", "Strong Buy"
        elif total_score >= 1.0:
            signal, strength = "Buy", "Buy"
        elif total_score <= -1.5:
            signal, strength = "Sell", "Strong Sell" 
        elif total_score <= -1.0:
            signal, strength = "Sell", "Sell"
        else:
            signal, strength = "Hold", "Hold"
        
        # Ø³ØªÙˆØ¨ Ù„ÙˆØ³
        stop_loss = current_price - (2 * latest['ATR']) if 'buy' in signal.lower() else current_price + (2 * latest['ATR'])
        
        # Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
        result = {
            "timestamp_utc": datetime.utcnow().isoformat(),
            "signal": signal,
            "signal_strength": strength,
            "total_score": round(total_score, 3),
            "components": {
                "trend_score": trend_score,
                "momentum_score": momentum_score,
                "correlation_score": correlation_score,
                "news_score": round(news_score, 2),
                "rsi_score": rsi_score
            },
            "market_data": {
                "gold_price": round(current_price, 2),
                "dxy": round(dxy_current, 2),
                "vix": round(vix_current, 2),
                "rsi": round(latest['RSI'], 2)
            },
            "stop_loss_price": round(stop_loss, 2),
            "news_analysis": news_analysis,
            "execution_time_seconds": round(time.time() - start_time, 2)
        }
        
        # Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        try:
            with open("gold_analysis_enhanced.json", 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
            
            # Ø­ÙØ¸ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute('''
                INSERT INTO analysis_history 
                (timestamp_utc, signal, total_score, gold_price, signal_strength, news_score, market_data)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            ''', (
                result['timestamp_utc'], result['signal'], result['total_score'],
                result['market_data']['gold_price'], result['signal_strength'],
                result['components']['news_score'], json.dumps(result['market_data'])
            ))
            conn.commit()
            conn.close()
            
        except Exception as e:
            logger.warning(f"âš ï¸ ØªØ­Ø°ÙŠØ± Ø§Ù„Ø­ÙØ¸: {e}")
        
        logger.info(f"âœ… Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„ØªØ­Ù„ÙŠÙ„ ÙÙŠ {result['execution_time_seconds']} Ø«Ø§Ù†ÙŠØ©")
        return result

if __name__ == "__main__":
    try:
        analyzer = OptimizedGoldAnalyzer()
        results = analyzer.run_fast_analysis()
        
        if results.get("status") == "error":
            logger.error(f"âŒ ÙØ´Ù„: {results.get('error')}")
        else:
            print(f"\nğŸ¯ Ø§Ù„Ø¥Ø´Ø§Ø±Ø©: {results['signal']} ({results['signal_strength']})")
            print(f"ğŸ“Š Ø§Ù„Ù†ØªÙŠØ¬Ø©: {results['total_score']}")
            print(f"ğŸ’° Ø³Ø¹Ø± Ø§Ù„Ø°Ù‡Ø¨: ${results['market_data']['gold_price']}")
            print(f"ğŸ›‘ ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø©: ${results['stop_loss_price']}")
            print(f"â±ï¸ ÙˆÙ‚Øª Ø§Ù„ØªÙ†ÙÙŠØ°: {results['execution_time_seconds']} Ø«Ø§Ù†ÙŠØ©")
            
            headlines = results['news_analysis'].get('headlines', [])
            if headlines:
                print(f"\nğŸ“° Ø£Ù‡Ù… Ø§Ù„Ø£Ø®Ø¨Ø§Ø±:")
                for i, h in enumerate(headlines[:3], 1):
                    print(f"  {i}. {h['title'][:60]}... [{h['source']}]")
                    
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ Ø¹Ø§Ù…: {e}")