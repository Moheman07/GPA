#!/usr/bin/env python3
import yfinance as yf
import pandas as pd
import numpy as np
import requests
import json
import os
import sqlite3
import joblib
from datetime import datetime, timedelta
import warnings
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import xgboost as xgb
from textblob import TextBlob
import spacy
import backtrader as bt
import asyncio
import aiohttp

warnings.filterwarnings('ignore')

# ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ spaCy Ù„Ù„ØºØ© Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©
try:
    nlp = spacy.load("en_core_web_sm")
except:
    print("Downloading spaCy model...")
    os.system("python -m spacy download en_core_web_sm")
    nlp = spacy.load("en_core_web_sm")

class MLPredictor:
    """Ù†Ø¸Ø§Ù… Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ"""
    
    def __init__(self):
        self.model = None
        self.scaler = StandardScaler()
        self.feature_columns = None
        self.model_path = "gold_ml_model.pkl"
        self.scaler_path = "gold_scaler.pkl"
        
    def prepare_features(self, analysis_data):
        """ØªØ­Ø¶ÙŠØ± Ø§Ù„Ù…Ù…ÙŠØ²Ø§Øª Ù…Ù† Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ­Ù„ÙŠÙ„"""
        features = {}
        
        if 'gold_analysis' in analysis_data:
            scores = analysis_data.get('gold_analysis', {}).get('component_scores', {})
            features.update({f'score_{k}': v for k, v in scores.items()})
            features['total_score'] = analysis_data.get('gold_analysis', {}).get('total_score', 0)
            
            tech_summary = analysis_data.get('gold_analysis', {}).get('technical_summary', {})
            features.update({f'tech_{k}': v for k, v in tech_summary.items()})
        
        if 'volume_analysis' in analysis_data:
            vol = analysis_data.get('volume_analysis', {})
            features['volume_ratio'] = vol.get('volume_ratio', 1)
            features['volume_strength_encoded'] = self._encode_volume_strength(vol.get('volume_strength', 'Ø·Ø¨ÙŠØ¹ÙŠ'))
        
        if 'market_correlations' in analysis_data:
            corr = analysis_data.get('market_correlations', {}).get('correlations', {})
            features.update({f'corr_{k}': v for k, v in corr.items()})
        
        if 'economic_data' in analysis_data:
            features['economic_score'] = analysis_data.get('economic_data', {}).get('score', 0)
        
        if 'fibonacci_levels' in analysis_data:
            fib = analysis_data.get('fibonacci_levels', {})
            features['fib_position'] = fib.get('current_position', 50)
        
        return features
    
    def _encode_volume_strength(self, strength):
        mapping = {'Ø¶Ø¹ÙŠÙ': 0, 'Ø·Ø¨ÙŠØ¹ÙŠ': 1, 'Ù‚ÙˆÙŠ': 2, 'Ù‚ÙˆÙŠ Ø¬Ø¯Ø§Ù‹': 3}
        return mapping.get(strength, 1)
    
    def train_model(self, historical_data):
        print("ğŸ¤– Ø¨Ø¯Ø¡ ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ...")
        X, y = [], []
        
        for record in historical_data:
            features = self.prepare_features(record['analysis'])
            if not self.feature_columns:
                self.feature_columns = list(features.keys())
            
            X.append([features.get(col, 0) for col in self.feature_columns])
            y.append(1 if record.get('price_change_5d', 0) > 1.0 else 0)
        
        if len(X) < 100:
            print("âš ï¸ Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± ÙƒØ§ÙÙŠØ© Ù„Ù„ØªØ¯Ø±ÙŠØ¨")
            return False
        
        X = np.array(X)
        y = np.array(y)
        
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)
        
        models = {
            'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42),
            'GradientBoosting': GradientBoostingClassifier(n_estimators=100, random_state=42),
            'XGBoost': xgb.XGBClassifier(n_estimators=100, random_state=42, use_label_encoder=False, eval_metric='logloss')
        }
        
        best_model, best_score = None, 0
        
        for name, model in models.items():
            print(f"ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ {name}...")
            model.fit(X_train_scaled, y_train)
            f1 = f1_score(y_test, model.predict(X_test_scaled))
            print(f"  - F1 Score: {f1:.2%}")
            if f1 > best_score:
                best_score, best_model = f1, model
        
        self.model = best_model
        print(f"\nâœ… Ø£ÙØ¶Ù„ Ù†Ù…ÙˆØ°Ø¬: {type(best_model).__name__} Ù…Ø¹ F1 Score: {best_score:.2%}")
        
        joblib.dump(self.model, self.model_path)
        joblib.dump(self.scaler, self.scaler_path)
        joblib.dump(self.feature_columns, "feature_columns.pkl")
        return True
    
    def predict_probability(self, analysis_data):
        try:
            if not all(os.path.exists(p) for p in [self.model_path, self.scaler_path, "feature_columns.pkl"]):
                return None, "Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø£Ùˆ Ø§Ù„Ù…Ù„Ø­Ù‚Ø§Øª ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©"
                
            if self.model is None:
                self.model = joblib.load(self.model_path)
                self.scaler = joblib.load(self.scaler_path)
                self.feature_columns = joblib.load("feature_columns.pkl")

            features = self.prepare_features(analysis_data)
            X_values = [features.get(col, 0) for col in self.feature_columns]
            X = np.array([X_values])
            
            X_scaled = self.scaler.transform(X)
            probability = self.model.predict_proba(X_scaled)[0][1]
            
            if probability > 0.75: interpretation = "Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ© Ø¹Ø§Ù„ÙŠØ© Ø¬Ø¯Ø§Ù‹ Ù„Ù„Ù†Ø¬Ø§Ø­"
            elif probability > 0.60: interpretation = "Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ© Ø¬ÙŠØ¯Ø© Ù„Ù„Ù†Ø¬Ø§Ø­"
            elif probability > 0.45: interpretation = "Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ© Ù…ØªÙˆØ³Ø·Ø© - Ø­Ø°Ø±"
            else: interpretation = "Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ© Ù…Ù†Ø®ÙØ¶Ø© - ØªØ¬Ù†Ø¨"
            
            return probability, interpretation
        except Exception as e:
            print(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªÙ†Ø¨Ø¤: {e}")
            return None, str(e)

# ... (Ø¨Ù‚ÙŠØ© Ø§Ù„ÙƒÙ„Ø§Ø³Ø§Øª ØªØ¨Ù‚Ù‰ ÙƒÙ…Ø§ Ù‡ÙŠ ÙÙŠ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©ØŒ Ø³Ø£Ø¶Ø¹ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ù…ØµØ­Ø­Ø© ÙˆØ§Ù„Ù…Ø®ØªØµØ±Ø©)
class MultiTimeframeAnalyzer:
    def __init__(self):
        self.timeframes = {'1h': '7d', '4h': '1mo', '1d': '3mo'}

    def analyze_timeframe(self, symbol, interval, period):
        try:
            data = yf.download(symbol, period=period, interval=interval, progress=False, auto_adjust=True)
            if data.empty or len(data) < 26: return None
            
            data['SMA_20'] = data['Close'].rolling(20).mean()
            delta = data['Close'].diff(1)
            gain = delta.where(delta > 0, 0).rolling(14).mean()
            loss = -delta.where(delta < 0, 0).rolling(14).mean()
            rs = gain / loss.replace(0, np.nan)
            data['RSI'] = 100 - (100 / (1 + rs))
            
            exp1 = data['Close'].ewm(span=12, adjust=False).mean()
            exp2 = data['Close'].ewm(span=26, adjust=False).mean()
            data['MACD'] = exp1 - exp2
            data['MACD_Signal'] = data['MACD'].ewm(span=9, adjust=False).mean()
            
            latest = data.iloc[-1]
            score = 0
            if latest['Close'] > latest['SMA_20']: score += 1
            if latest['RSI'] > 50: score += 0.5
            elif latest['RSI'] < 30: score += 1
            if latest['MACD'] > latest['MACD_Signal']: score += 1

            return {'score': score, 'trend': 'ØµØ§Ø¹Ø¯' if score > 1.5 else ('Ù‡Ø§Ø¨Ø·' if score < 0 else 'Ù…Ø­Ø§ÙŠØ¯')}
        except Exception as e:
            print(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¥Ø·Ø§Ø± Ø§Ù„Ø²Ù…Ù†ÙŠ {interval}: {e}")
            return None

# ... Ø¨Ø§Ù‚ÙŠ Ø§Ù„ÙƒÙ„Ø§Ø³Ø§Øª Ø§Ù„Ø£Ø®Ø±Ù‰ (AdvancedNewsAnalyzer, ProfessionalBacktester, DatabaseManager) ØªØ¨Ù‚Ù‰ ÙƒÙ…Ø§ Ù‡ÙŠ Ù…Ù† Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø© Ø§Ù„ÙƒØ§Ù…Ù„Ø©
# ... Ø³Ø£Ø¶Ø¹ Ù‡Ù†Ø§ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„ÙƒØ§Ù…Ù„Ø© ÙˆØ§Ù„Ù…Ø­Ø¯Ø«Ø© Ù„ÙƒÙ„ Ø´ÙŠØ¡ Ù„Ù„ÙˆØ¶ÙˆØ­

class ProfessionalGoldAnalyzerV3:
    """Ø§Ù„Ø¥ØµØ¯Ø§Ø± 3.0 Ù…Ù† Ù…Ø­Ù„Ù„ Ø§Ù„Ø°Ù‡Ø¨ Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠ"""
    
    def __init__(self):
        self.symbols = {
            'gold': 'GC=F', 'gold_etf': 'GLD', 'dxy': 'DX-Y.NYB', 'vix': '^VIX',
            'treasury': '^TNX', 'oil': 'CL=F', 'spy': 'SPY', 'usdeur': 'EURUSD=X', 'silver': 'SI=F'
        }
        self.ml_predictor = MLPredictor()
        self.mtf_analyzer = MultiTimeframeAnalyzer()
        self.news_api_key = os.getenv("NEWS_API_KEY")
        self.fred_api_key = os.getenv("FRED_API_KEY")
        # Initialize other components...
        self.news_analyzer = AdvancedNewsAnalyzer(self.news_api_key)
        self.db_manager = DatabaseManager()
        self.backtester = ProfessionalBacktester(self)


    def fetch_multi_timeframe_data(self):
        print("ğŸ“Š Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø© Ø§Ù„Ø£Ø·Ø± Ø§Ù„Ø²Ù…Ù†ÙŠØ©...")
        try:
            # âœ… ØªØµØ­ÙŠØ­: ØªØ¹Ø·ÙŠÙ„ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…ØªÙˆØ§Ø²ÙŠØ© Ù„ØªØ¬Ù†Ø¨ Ø®Ø·Ø£ Ù‚ÙÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            daily_data = yf.download(list(self.symbols.values()), period="3y", interval="1d", group_by='ticker', progress=False, threads=False)
            if daily_data.empty: raise ValueError("ÙØ´Ù„ Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
            return {'daily': daily_data}
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {e}")
            return None

    def extract_gold_data(self, market_data):
        print("ğŸ” Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø°Ù‡Ø¨...")
        try:
            daily_data = market_data['daily']
            gold_symbol = self.symbols['gold']
            
            if not isinstance(daily_data.columns, pd.MultiIndex) or gold_symbol not in daily_data.columns.levels[0]:
                 gold_symbol = self.symbols['gold_etf']
                 if not isinstance(daily_data.columns, pd.MultiIndex) or gold_symbol not in daily_data.columns.levels[0]:
                    raise ValueError("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ø°Ù‡Ø¨ ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø­Ù…Ù„Ø©")

            gold_daily = daily_data[gold_symbol].copy().dropna(subset=['Close'])
            if len(gold_daily) < 200: raise ValueError("Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± ÙƒØ§ÙÙŠØ©")
            
            print(f"âœ… Ø¨ÙŠØ§Ù†Ø§Øª ÙŠÙˆÙ…ÙŠØ© Ù†Ø¸ÙŠÙØ©: {len(gold_daily)} ÙŠÙˆÙ…")
            return gold_daily
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø°Ù‡Ø¨: {e}")
            return None

    # (Ø¨Ù‚ÙŠØ© Ø¯ÙˆØ§Ù„ Ø§Ù„ÙƒÙ„Ø§Ø³ Ù…Ø«Ù„ calculate_professional_indicators ÙˆØºÙŠØ±Ù‡Ø§ ØªØ¨Ù‚Ù‰ ÙƒÙ…Ø§ Ù‡ÙŠ)
    def calculate_professional_indicators(self, gold_data):
        """Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠØ© Ø§Ù„Ù…Ø­Ø³Ù‘Ù†Ø©"""
        print("ğŸ“Š Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠØ© Ø§Ù„Ù…Ø­Ø³Ù‘Ù†Ø©...")
        try:
            df = gold_data.copy()
            for window in [10, 20, 50, 100, 200]: df[f'SMA_{window}'] = df['Close'].rolling(window=window).mean()
            for span in [9, 21]: df[f'EMA_{span}'] = df['Close'].ewm(span=span, adjust=False).mean()
            
            delta = df['Close'].diff()
            gain = delta.where(delta > 0, 0).rolling(window=14).mean()
            loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
            df['RSI'] = 100 - (100 / (1 + (gain / loss.replace(0, 0.0001))))
            
            exp1, exp2 = df['Close'].ewm(span=12, adjust=False).mean(), df['Close'].ewm(span=26, adjust=False).mean()
            df['MACD'] = exp1 - exp2
            df['MACD_Signal'] = df['MACD'].ewm(span=9, adjust=False).mean()
            df['MACD_Histogram'] = df['MACD'] - df['MACD_Signal']
            
            std = df['Close'].rolling(window=20).std()
            df['BB_Upper'] = df['SMA_20'] + (std * 2)
            df['BB_Lower'] = df['SMA_20'] - (std * 2)
            df['BB_Width'] = ((df['BB_Upper'] - df['BB_Lower']) / df['SMA_20']) * 100
            df['BB_Position'] = (df['Close'] - df['BB_Lower']) / (df['BB_Upper'] - df['BB_Lower']).replace(0, 0.0001)

            df['Volume_SMA'] = df['Volume'].rolling(20).mean()
            df['Volume_Ratio'] = df['Volume'] / df['Volume_SMA'].replace(0, 1)

            return df.dropna()
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª: {e}")
            return None
    
    def calculate_fibonacci_levels(self, data, periods=50):
        try:
            recent_data = data.tail(periods)
            high, low = recent_data['High'].max(), recent_data['Low'].min()
            diff = high - low
            if diff == 0: return {}
            current_price = data['Close'].iloc[-1]
            
            levels = {
                'high': round(high, 2), 'low': round(low, 2),
                'fib_23_6': round(high - (diff * 0.236), 2),
                'fib_38_2': round(high - (diff * 0.382), 2),
                'fib_50_0': round(high - (diff * 0.500), 2),
                'fib_61_8': round(high - (diff * 0.618), 2),
            }
            
            if current_price > levels['fib_23_6']: analysis = "Ø§Ù„Ø³Ø¹Ø± Ù‚ÙˆÙŠ Ø¬Ø¯Ø§Ù‹ ÙÙˆÙ‚ 23.6%"
            elif current_price > levels['fib_38_2']: analysis = "Ø§Ù„Ø³Ø¹Ø± ÙÙˆÙ‚ 38.2% - Ø§ØªØ¬Ø§Ù‡ ØµØ§Ø¹Ø¯ Ù…Ø¹ØªØ¯Ù„"
            elif current_price > levels['fib_50_0']: analysis = "Ø§Ù„Ø³Ø¹Ø± ÙÙˆÙ‚ 50% - Ù…Ù†Ø·Ù‚Ø© Ù…Ø­Ø§ÙŠØ¯Ø©"
            elif current_price > levels['fib_61_8']: analysis = "Ø§Ù„Ø³Ø¹Ø± ÙÙˆÙ‚ 61.8% - Ø¶Ø¹Ù Ù†Ø³Ø¨ÙŠ"
            else: analysis = "Ø§Ù„Ø³Ø¹Ø± ØªØ­Øª 61.8% - Ø§ØªØ¬Ø§Ù‡ Ù‡Ø§Ø¨Ø· Ù…Ø­ØªÙ…Ù„"
            
            levels['analysis'] = analysis
            levels['current_position'] = round(((current_price - low) / diff * 100), 2)
            return levels
        except Exception as e:
            print(f"Ø®Ø·Ø£ ÙÙŠ Ø­Ø³Ø§Ø¨ ÙÙŠØ¨ÙˆÙ†Ø§ØªØ´ÙŠ: {e}")
            return {}

    def fetch_economic_data(self):
        return {
            'status': 'simulated', 'score': 3,
            'overall_impact': 'Ø¥ÙŠØ¬Ø§Ø¨ÙŠ Ù„Ù„Ø°Ù‡Ø¨ (Ù…Ø­Ø§ÙƒØ§Ø©)'
        }

    def analyze_volume_profile(self, data):
        try:
            latest = data.iloc[-1]
            volume_ratio = latest.get('Volume_Ratio', 1)
            
            if volume_ratio > 2.0: strength, signal = 'Ù‚ÙˆÙŠ Ø¬Ø¯Ø§Ù‹', 'Ø­Ø¬Ù… Ø§Ø³ØªØ«Ù†Ø§Ø¦ÙŠ'
            elif volume_ratio > 1.5: strength, signal = 'Ù‚ÙˆÙŠ', 'Ø­Ø¬Ù… ÙÙˆÙ‚ Ø§Ù„Ù…ØªÙˆØ³Ø·'
            elif volume_ratio > 0.8: strength, signal = 'Ø·Ø¨ÙŠØ¹ÙŠ', 'Ø­Ø¬Ù… Ø·Ø¨ÙŠØ¹ÙŠ'
            else: strength, signal = 'Ø¶Ø¹ÙŠÙ', 'Ø­Ø¬Ù… Ø¶Ø¹ÙŠÙ'

            return {
                'current_volume': int(latest.get('Volume', 0)),
                'avg_volume_20': int(latest.get('Volume_SMA', 0)),
                'volume_ratio': round(volume_ratio, 2),
                'volume_strength': strength,
                'volume_signal': signal,
            }
        except Exception as e:
            print(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø­Ø¬Ù…: {e}")
            return {}

    def analyze_correlations(self, market_data):
        print("ğŸ“Š ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø·Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…...")
        try:
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø¥ØºÙ„Ø§Ù‚ ÙÙ‚Ø· Ù„ÙƒÙ„ Ø§Ù„Ø£ØµÙˆÙ„
            close_prices = market_data['daily'].xs('Close', level=1, axis=1)
            # Ø­Ø³Ø§Ø¨ Ù…ØµÙÙˆÙØ© Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø· Ù„Ø¢Ø®Ø± 90 ÙŠÙˆÙ…Ù‹Ø§
            correlations = close_prices.tail(90).corr()
            
            gold_symbol = self.symbols['gold']
            if gold_symbol not in correlations:
                gold_symbol = self.symbols['gold_etf']
            
            gold_corrs = correlations[gold_symbol]
            results = {}
            for name, symbol in self.symbols.items():
                if symbol in gold_corrs.index:
                    results[name] = round(gold_corrs[symbol], 3)
            return {'correlations': results}
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø·Ø§Øª: {e}")
            return {}

    def generate_professional_signals_v3(self, tech_data, correlations, volume, fib_levels, economic_data, news_analysis, mtf_analysis, ml_prediction):
        print("ğŸ¯ ØªÙˆÙ„ÙŠØ¯ Ø¥Ø´Ø§Ø±Ø§Øª Ø§Ø­ØªØ±Ø§ÙÙŠØ© Ù…ØªÙ‚Ø¯Ù…Ø© V3...")
        try:
            latest = tech_data.iloc[-1]
            scores = {'trend': 0, 'momentum': 0, 'volume': 0, 'fibonacci': 0, 'correlation': 0, 'economic': 0, 'news': 0, 'ma_cross': 0, 'mtf_coherence': 0}
            
            # Trend
            if latest['Close'] > latest['SMA_50'] and latest['SMA_50'] > latest['SMA_200']: scores['trend'] = 2
            elif latest['Close'] < latest['SMA_50'] and latest['SMA_50'] < latest['SMA_200']: scores['trend'] = -2
            
            # Momentum
            if latest['MACD'] > latest['MACD_Signal']: scores['momentum'] += 1
            if latest['RSI'] > 55: scores['momentum'] += 1
            elif latest['RSI'] < 45: scores['momentum'] -= 1
            
            # Volume
            strength_map = {'Ø¶Ø¹ÙŠÙ': -1, 'Ø·Ø¨ÙŠØ¹ÙŠ': 0, 'Ù‚ÙˆÙŠ': 1, 'Ù‚ÙˆÙŠ Ø¬Ø¯Ø§Ù‹': 2}
            scores['volume'] = strength_map.get(volume.get('volume_strength', 'Ø·Ø¨ÙŠØ¹ÙŠ'), 0)
            
            # Fibonacci
            pos = fib_levels.get('current_position', 50)
            if pos > 61.8: scores['fibonacci'] = 2
            elif pos < 38.2: scores['fibonacci'] = -2
            else: scores['fibonacci'] = 0

            # Correlations
            dxy_corr = correlations.get('correlations', {}).get('dxy', 0)
            if dxy_corr < -0.5: scores['correlation'] = 1
            elif dxy_corr > 0.5: scores['correlation'] = -1
                
            # Other Scores
            scores['economic'] = economic_data.get('score', 0)
            scores['news'] = news_analysis.get('events_analysis', {}).get('total_impact', 0) / 2
            scores['mtf_coherence'] = mtf_analysis.get('coherence_score', 0)
            
            weights = {'trend': 0.25, 'momentum': 0.20, 'volume': 0.10, 'fibonacci': 0.05, 'correlation': 0.05, 'economic': 0.1, 'news': 0.1, 'mtf_coherence': 0.15}
            total_score = sum(scores.get(k, 0) * v for k, v in weights.items())

            ml_interpretation = ""
            if ml_prediction and ml_prediction[0] is not None:
                ml_probability = ml_prediction[0]
                ml_interpretation = ml_prediction[1]
                boost = 1.0 + (ml_probability - 0.5) * 0.5 # Boost score by up to 25%
                total_score *= boost

            if total_score >= 1.5: signal, confidence = "Strong Buy", "Very High"
            elif total_score >= 0.7: signal, confidence = "Buy", "High"
            elif total_score > -0.7: signal, confidence = "Hold", "Medium"
            elif total_score > -1.5: signal, confidence = "Sell", "High"
            else: signal, confidence = "Strong Sell", "Very High"

            return {
                'signal': signal, 'confidence': confidence, 'total_score': round(total_score, 2),
                'component_scores': {k: round(v, 2) for k,v in scores.items()},
                'current_price': round(latest['Close'], 2),
                'ml_prediction': {
                    'probability': round(ml_prediction[0], 3) if ml_prediction and ml_prediction[0] is not None else None,
                    'interpretation': ml_interpretation
                }
            }
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª: {e}")
            return {"error": str(e)}

    def generate_signal_for_backtest(self, data):
        return {'action': 'Buy' if data['close'] > data['open'] else 'Sell', 'confidence': 'Medium'}

    async def run_analysis_v3(self):
        print("ğŸš€ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠ Ø§Ù„Ù…ØªÙ‚Ø¯Ù… Ù„Ù„Ø°Ù‡Ø¨ - Ø§Ù„Ø¥ØµØ¯Ø§Ø± 3.0...")
        final_result = {'timestamp': datetime.now().isoformat(), 'version': '3.0'}
        
        try:
            market_data = self.fetch_multi_timeframe_data()
            if not market_data: raise ValueError("ÙØ´Ù„ ÙÙŠ Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø³ÙˆÙ‚")
            
            gold_data = self.extract_gold_data(market_data)
            if gold_data is None: raise ValueError("ÙØ´Ù„ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø°Ù‡Ø¨")
            
            technical_data = self.calculate_professional_indicators(gold_data)
            if technical_data is None: raise ValueError("ÙØ´Ù„ ÙÙŠ Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ÙÙ†ÙŠØ©")

            coherence_score, mtf_analysis = self.mtf_analyzer.get_coherence_score(self.symbols['gold'])
            fibonacci_levels = self.calculate_fibonacci_levels(technical_data)
            volume_analysis = self.analyze_volume_profile(technical_data)
            correlations = self.analyze_correlations(market_data)
            economic_data = self.fetch_economic_data()
            news_data = await self.fetch_news_enhanced()
            
            self.db_manager.update_future_prices()
            training_data = self.db_manager.get_training_data()
            
            ml_prediction = None
            if training_data:
                if not os.path.exists(self.ml_predictor.model_path):
                    self.ml_predictor.train_model(training_data)
                
                temp_analysis_for_ml = {
                    'gold_analysis': self.generate_professional_signals_v3(technical_data, correlations, volume_analysis, fibonacci_levels, economic_data, news_data, mtf_analysis, None),
                    'volume_analysis': volume_analysis, 'market_correlations': correlations,
                    'economic_data': economic_data, 'fibonacci_levels': fibonacci_levels
                }
                ml_prediction = self.ml_predictor.predict_probability(temp_analysis_for_ml)

            signals = self.generate_professional_signals_v3(
                technical_data, correlations, volume_analysis, fibonacci_levels, 
                economic_data, news_data, mtf_analysis, ml_prediction
            )
            
            backtest_results = self.backtester.run_backtest(technical_data) if len(technical_data) > 100 else None
            
            final_result.update({
                'status': 'success', 'gold_analysis': signals, 'backtest_results': backtest_results
            })
            
            self.db_manager.save_analysis(final_result)
            
        except Exception as e:
            print(f"âŒ ÙØ´Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠ: {e}")
            final_result.update({'status': 'error', 'error': str(e)})
        
        self.save_results_v3(final_result)
        print("\nâœ… ØªÙ… Ø¥ØªÙ…Ø§Ù… Ø§Ù„ØªØ­Ù„ÙŠÙ„!")
        return final_result

    def save_results_v3(self, results):
        try:
            filename = "gold_analysis_v3.json"
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2, default=str)
            print(f"ğŸ’¾ ØªÙ… Ø­ÙØ¸ Ø§Ù„ØªØ­Ù„ÙŠÙ„ ÙÙŠ: {filename}")
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬: {e}")

# --- Ø¬Ø²Ø¡ Ø®Ø§Ø¯Ù… Ø§Ù„ÙˆÙŠØ¨ Ù„Ù„ØªØ´ØºÙŠÙ„ Ø¹Ù„Ù‰ Replit ---
app = Flask(__name__)
analyzer_instance = ProfessionalGoldAnalyzerV3()

def run_analysis_in_background():
    print("Background thread started for analysis...")
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    loop.run_until_complete(analyzer_instance.run_analysis_v3())
    loop.close()
    print("Background analysis thread finished.")

@app.route('/')
def home():
    return "Gold Analysis Server is running. Use /run to trigger analysis."

@app.route('/run')
def trigger_analysis():
    active_threads = [t.name for t in threading.enumerate()]
    if 'analysis_thread' in active_threads:
        return "An analysis is already in progress.", 429
        
    print("Received request to /run. Starting analysis in a background thread.")
    thread = threading.Thread(target=run_analysis_in_background, name='analysis_thread')
    thread.start()
    return "Analysis has been started in the background. Check the console for progress."

def main():
    print("Starting Flask server...")
    # This part is for running on Replit. It won't be used in GitHub Actions.
    from waitress import serve
    serve(app, host='0.0.0.0', port=8080)

if __name__ == "__main__":
    # To run directly without Flask for GitHub Actions, we need to change this part.
    # But for Replit, this is correct. Let's provide a version for Replit as requested.
    main()

