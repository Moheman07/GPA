#!/usr/bin/env python3
import yfinance as yf
import pandas as pd
import numpy as np
import requests
import json
import os
import sqlite3
import logging
from datetime import datetime, timedelta
from transformers import pipeline
import pytz
import pandas_ta as ta
import warnings
from typing import Dict, List, Tuple, Optional

warnings.filterwarnings('ignore')

# Ø¥Ø¹Ø¯Ø§Ø¯ Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù…Ø­Ø³Ù†
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('gold_analysis.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class ProfessionalGoldAnalyzerV2:
    def __init__(self):
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø±Ù…ÙˆØ² Ø£ÙƒØ«Ø± Ø¯Ù‚Ø© Ù„Ù„Ø°Ù‡Ø¨
        self.symbols = {
            'gold': 'GC=F',  # Gold Futures - Ø£ÙƒØ«Ø± Ø¯Ù‚Ø© Ù…Ù† GLD
            'gold_etf': 'GLD',  # ÙƒØ¨Ø¯ÙŠÙ„ Ø§Ø­ØªÙŠØ§Ø·ÙŠ
            'dxy': 'DX-Y.NYB', 
            'vix': '^VIX',
            'treasury': '^TNX', 
            'oil': 'CL=F', 
            'spy': 'SPY',
            'silver': 'SI=F',  # Ø¥Ø¶Ø§ÙØ© Ø§Ù„ÙØ¶Ø© Ù„Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø¹Ø§Ø¯Ù† Ø§Ù„Ø«Ù…ÙŠÙ†Ø©
            'copper': 'HG=F'   # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù†Ø­Ø§Ø³ ÙƒÙ…Ø¤Ø´Ø± Ø§Ù‚ØªØµØ§Ø¯ÙŠ
        }
        
        self.news_api_key = os.getenv("NEWS_API_KEY")
        self.sentiment_pipeline = None
        self.db_path = "gold_analysis_history.db"
        
        # Ø¥Ø¹Ø¯Ø§Ø¯ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        self._setup_database()
        
        # ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±
        self._load_sentiment_model()
        
        logger.info("ğŸš€ ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ù…Ø­Ù„Ù„ Ø§Ù„Ø°Ù‡Ø¨ Ø§Ù„Ù…ØªÙ‚Ø¯Ù… Ø¨Ù†Ø¬Ø§Ø­")

    def _setup_database(self):
        """Ø¥Ø¹Ø¯Ø§Ø¯ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø³Ø¬Ù„ Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠ"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ©
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS analysis_history (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp_utc TEXT NOT NULL,
                    signal TEXT NOT NULL,
                    total_score REAL NOT NULL,
                    trend_score REAL,
                    momentum_score REAL,
                    correlation_score REAL,
                    news_score REAL,
                    volatility_score REAL,
                    gold_price REAL,
                    dxy_value REAL,
                    vix_value REAL,
                    signal_strength TEXT,
                    stop_loss_price REAL,
                    news_sentiment_score REAL,
                    market_volatility TEXT,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ù…Ø±ØªØ¨Ø·Ø© Ø¨Ø§Ù„Ø°Ù‡Ø¨
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS news_history (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    analysis_id INTEGER,
                    headline TEXT,
                    source TEXT,
                    sentiment_score REAL,
                    relevance_score INTEGER,
                    published_at TEXT,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    FOREIGN KEY (analysis_id) REFERENCES analysis_history (id)
                )
            ''')
            
            conn.commit()
            conn.close()
            logger.info("âœ… ØªÙ… Ø¥Ø¹Ø¯Ø§Ø¯ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ù†Ø¬Ø§Ø­")
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¥Ø¹Ø¯Ø§Ø¯ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {e}")

    def _load_sentiment_model(self):
        """ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ø§Ù„Ù…Ø§Ù„ÙŠ"""
        try:
            logger.info("ğŸ§  ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ø§Ù„Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…ØªØ®ØµØµ...")
            self.sentiment_pipeline = pipeline(
                "sentiment-analysis", 
                model="ProsusAI/finbert",
                return_all_scores=True
            )
            logger.info("âœ… Ù†Ù…ÙˆØ°Ø¬ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ø¬Ø§Ù‡Ø²")
        except Exception as e:
            logger.error(f"âš ï¸ ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±: {e}")

    def fetch_market_data(self) -> Optional[pd.DataFrame]:
        """Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø³ÙˆÙ‚ Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø£ÙØ¶Ù„ Ù„Ù„Ø£Ø®Ø·Ø§Ø¡"""
        logger.info("ğŸ“Š Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø³ÙˆÙ‚ Ø§Ù„Ù…Ø­Ø³Ù†Ø©...")
        
        try:
            # Ù…Ø­Ø§ÙˆÙ„Ø© Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¹Ù‚ÙˆØ¯ Ø§Ù„Ø¢Ø¬Ù„Ø© Ù„Ù„Ø°Ù‡Ø¨ Ø£ÙˆÙ„Ø§Ù‹
            symbols_to_fetch = list(self.symbols.values())
            data = yf.download(symbols_to_fetch, period="2y", interval="1d", threads=True)
            
            if data.empty:
                raise ValueError("ÙØ´Ù„ ÙÙŠ Ø¬Ù„Ø¨ Ø£ÙŠ Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Yahoo Finance")
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø°Ù‡Ø¨
            gold_column = ('Close', self.symbols["gold"])
            if gold_column not in data.columns or data[gold_column].dropna().empty:
                logger.warning("âš ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ø¹Ù‚ÙˆØ¯ Ø§Ù„Ø¢Ø¬Ù„Ø©ØŒ Ø§Ù„ØªØ¨Ø¯ÙŠÙ„ Ø¥Ù„Ù‰ GLD...")
                # Ø§Ù„ØªØ¨Ø¯ÙŠÙ„ Ø¥Ù„Ù‰ GLD ÙƒØ¨Ø¯ÙŠÙ„
                self.symbols['gold'] = 'GLD'
                symbols_to_fetch[0] = 'GLD'
                data = yf.download(symbols_to_fetch, period="2y", interval="1d", threads=True)
            
            # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            data = data.dropna(subset=[('Close', self.symbols["gold"])])
            
            if len(data) < 100:
                raise ValueError(f"Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± ÙƒØ§ÙÙŠØ©: {len(data)} ÙŠÙˆÙ… ÙÙ‚Ø·")
            
            logger.info(f"âœ… ØªÙ… Ø¬Ù„Ø¨ {len(data)} ÙŠÙˆÙ… Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ù†Ø¬Ø§Ø­")
            return data
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø³ÙˆÙ‚: {e}")
            return None

    def analyze_gold_news(self) -> Dict:
        """
        Ù…Ø­Ø±Ùƒ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ù…ØªØ®ØµØµ ÙˆØ§Ù„Ù…Ø­Ø³Ù† Ù„Ù„Ø°Ù‡Ø¨
        """
        logger.info("ğŸ“° Ø¨Ø¯Ø¡ ØªØ­Ù„ÙŠÙ„ Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ø°Ù‡Ø¨ Ø§Ù„Ù…ØªØ®ØµØµ...")
        
        if not self.news_api_key or not self.sentiment_pipeline:
            logger.warning("âš ï¸ Ù…ÙØªØ§Ø­ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø£Ùˆ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± ØºÙŠØ± Ù…ØªØ§Ø­")
            return {"status": "skipped", "news_score": 0, "headlines": [], "analysis_details": {}}

        try:
            # ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ© Ù…ØªØ®ØµØµØ© Ù„Ù„Ø°Ù‡Ø¨ Ù…Ø¹ Ø£ÙˆØ²Ø§Ù† Ù…Ø­Ø³Ù†Ø©
            gold_keywords = {
                # ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø°Ù‡Ø¨ Ø§Ù„Ù…Ø¨Ø§Ø´Ø±Ø© - Ø£Ø¹Ù„Ù‰ ÙˆØ²Ù†
                'gold': 5, 'xau': 5, 'bullion': 5, 'precious metal': 5, 'precious metals': 5,
                
                # Ø§Ù„Ø¹ÙˆØ§Ù…Ù„ Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ÙŠØ© Ø§Ù„Ù…Ø¤Ø«Ø±Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø°Ù‡Ø¨ - ÙˆØ²Ù† Ù…ØªÙˆØ³Ø· Ø¹Ø§Ù„ÙŠ
                'federal reserve': 4, 'fed': 4, 'interest rate': 4, 'interest rates': 4,
                'inflation': 4, 'cpi': 4, 'consumer price index': 4,
                'quantitative easing': 4, 'monetary policy': 4,
                'dollar index': 4, 'dxy': 4, 'dollar strength': 4, 'dollar weakness': 4,
                
                # Ø§Ù„Ø¹ÙˆØ§Ù…Ù„ Ø§Ù„Ø¬ÙŠÙˆØ³ÙŠØ§Ø³ÙŠØ© - ÙˆØ²Ù† Ù…ØªÙˆØ³Ø·
                'geopolitical': 3, 'geopolitical tension': 3, 'war': 3, 'conflict': 3,
                'sanctions': 3, 'trade war': 3, 'tariff': 3, 'tariffs': 3,
                'safe haven': 3, 'safe-haven': 3, 'risk-off': 3, 'risk off': 3,
                
                # Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ÙŠØ© - ÙˆØ²Ù† Ù…ØªÙˆØ³Ø· Ù…Ù†Ø®ÙØ¶
                'nfp': 2, 'non-farm payroll': 2, 'unemployment': 2, 'gdp': 2,
                'retail sales': 2, 'manufacturing': 2, 'pmi': 2,
                
                # Ø£Ø³ÙˆØ§Ù‚ Ø£Ø®Ø±Ù‰ Ù…Ø¤Ø«Ø±Ø© - ÙˆØ²Ù† Ù…Ù†Ø®ÙØ¶
                'stock market': 1, 'equity': 1, 'bonds': 1, 'treasury': 1,
                'oil prices': 1, 'commodity': 1, 'mining': 1
            }

            # Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø© Ù„Ø¶Ù…Ø§Ù† Ø´Ù…ÙˆÙ„ÙŠØ© Ø£ÙƒØ¨Ø±
            queries = [
                'gold OR XAU OR bullion OR "precious metals"',
                '"interest rates" OR "federal reserve" OR inflation OR CPI',
                '"dollar index" OR DXY OR "monetary policy"',
                'geopolitical OR "safe haven" OR "risk off"'
            ]

            all_articles = []
            
            for query in queries:
                try:
                    url = (
                        f"https://newsapi.org/v2/everything?"
                        f"q={query}&language=en&sortBy=publishedAt&pageSize=50&"
                        f"from={(datetime.now() - timedelta(days=3)).date()}&"
                        f"apiKey={self.news_api_key}"
                    )
                    
                    response = requests.get(url, timeout=15)
                    response.raise_for_status()
                    articles = response.json().get('articles', [])
                    all_articles.extend(articles)
                    logger.info(f"ğŸ“¥ Ø¬Ù„Ø¨ {len(articles)} Ù…Ù‚Ø§Ù„ Ù…Ù† Ø§Ø³ØªØ¹Ù„Ø§Ù…: {query[:30]}...")
                    
                except Exception as e:
                    logger.warning(f"âš ï¸ ÙØ´Ù„ ÙÙŠ Ø§Ø³ØªØ¹Ù„Ø§Ù…: {query[:30]}... - {e}")
                    continue

            if not all_articles:
                raise ValueError("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£ÙŠ Ù…Ù‚Ø§Ù„Ø§Øª")

            # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…Ù‚Ø§Ù„Ø§Øª Ø§Ù„Ù…ÙƒØ±Ø±Ø©
            unique_articles = []
            seen_titles = set()
            for article in all_articles:
                title = article.get('title', '').lower()
                if title and title not in seen_titles:
                    seen_titles.add(title)
                    unique_articles.append(article)

            logger.info(f"ğŸ” ØªÙ… Ø¬Ù„Ø¨ {len(unique_articles)} Ù…Ù‚Ø§Ù„Ø§Ù‹ ÙØ±ÙŠØ¯Ø§Ù‹")

            # ØªÙ‚ÙŠÙŠÙ… ÙˆÙÙ„ØªØ±Ø© Ø§Ù„Ù…Ù‚Ø§Ù„Ø§Øª
            relevant_articles = []
            for article in unique_articles:
                content_text = f"{(article.get('title') or '').lower()} {(article.get('description') or '').lower()}"
                
                # Ø­Ø³Ø§Ø¨ Ù†Ù‚Ø§Ø· Ø§Ù„ØµÙ„Ø© Ø¨Ø§Ù„Ø°Ù‡Ø¨
                relevance_score = 0
                matched_keywords = []
                
                for keyword, weight in gold_keywords.items():
                    if keyword in content_text:
                        relevance_score += weight
                        matched_keywords.append(keyword)
                
                # Ù‚Ø¨ÙˆÙ„ Ø§Ù„Ù…Ù‚Ø§Ù„Ø§Øª Ø°Ø§Øª Ø§Ù„ØµÙ„Ø© Ø§Ù„Ø¹Ø§Ù„ÙŠØ© Ø¨Ø§Ù„Ø°Ù‡Ø¨
                if relevance_score >= 3:  # ØªÙ… ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰
                    article['relevance_score'] = relevance_score
                    article['matched_keywords'] = matched_keywords
                    relevant_articles.append(article)

            if not relevant_articles:
                raise ValueError("Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ù‚Ø§Ù„Ø§Øª Ø°Ø§Øª ØµÙ„Ø© ÙƒØ§ÙÙŠØ© Ø¨Ø§Ù„Ø°Ù‡Ø¨")

            logger.info(f"ğŸ¯ ØªÙ… Ø§Ø®ØªÙŠØ§Ø± {len(relevant_articles)} Ù…Ù‚Ø§Ù„Ø§Ù‹ Ø°Ø§ ØµÙ„Ø© Ø¹Ø§Ù„ÙŠØ© Ø¨Ø§Ù„Ø°Ù‡Ø¨")

            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ø§Ù„Ù…ÙØµÙ„
            sentiment_scores = []
            processed_articles = []

            for article in relevant_articles:
                try:
                    text_for_analysis = article.get('description') or article.get('title') or ""
                    if not text_for_analysis:
                        continue
                        
                    # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ù…Ø¹ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ÙƒØ§Ù…Ù„Ø©
                    sentiment_results = self.sentiment_pipeline(text_for_analysis[:512])  # Ù‚Ø·Ø¹ Ø§Ù„Ù†Øµ Ù„Ù„Ø·ÙˆÙ„ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨
                    
                    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
                    positive_score = next((s['score'] for s in sentiment_results[0] if s['label'] == 'positive'), 0)
                    negative_score = next((s['score'] for s in sentiment_results[0] if s['label'] == 'negative'), 0)
                    neutral_score = next((s['score'] for s in sentiment_results[0] if s['label'] == 'neutral'), 0)
                    
                    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© (Ø¨ÙŠÙ† -1 Ùˆ +1)
                    final_sentiment = positive_score - negative_score
                    
                    # ÙˆØ²Ù† Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø­Ø³Ø¨ Ø£Ù‡Ù…ÙŠØ© Ø§Ù„Ù…Ù‚Ø§Ù„
                    weighted_sentiment = final_sentiment * (article['relevance_score'] / 10)
                    
                    sentiment_scores.append(weighted_sentiment)
                    
                    processed_articles.append({
                        'title': article['title'],
                        'source': article.get('source', {}).get('name', 'Unknown'),
                        'sentiment_score': round(final_sentiment, 3),
                        'relevance_score': article['relevance_score'],
                        'matched_keywords': article['matched_keywords'][:3],  # Ø£Ù‡Ù… 3 ÙƒÙ„Ù…Ø§Øª
                        'published_at': article.get('publishedAt')
                    })
                    
                except Exception as e:
                    logger.warning(f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ù…Ø´Ø§Ø¹Ø± Ù…Ù‚Ø§Ù„: {e}")
                    continue

            if not sentiment_scores:
                raise ValueError("ÙØ´Ù„ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ù…Ø´Ø§Ø¹Ø± Ø£ÙŠ Ù…Ù† Ø§Ù„Ù…Ù‚Ø§Ù„Ø§Øª")

            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
            average_sentiment = np.mean(sentiment_scores)
            sentiment_std = np.std(sentiment_scores)
            
            # ØªØ±ØªÙŠØ¨ Ø§Ù„Ù…Ù‚Ø§Ù„Ø§Øª Ø­Ø³Ø¨ Ø§Ù„Ø£Ù‡Ù…ÙŠØ© ÙˆØ§Ù„ØµÙ„Ø©
            processed_articles.sort(key=lambda x: (x['relevance_score'], abs(x['sentiment_score'])), reverse=True)

            analysis_details = {
                'total_articles_analyzed': len(processed_articles),
                'average_sentiment': round(average_sentiment, 3),
                'sentiment_volatility': round(sentiment_std, 3),
                'positive_articles': len([a for a in processed_articles if a['sentiment_score'] > 0.1]),
                'negative_articles': len([a for a in processed_articles if a['sentiment_score'] < -0.1]),
                'neutral_articles': len([a for a in processed_articles if abs(a['sentiment_score']) <= 0.1])
            }

            logger.info(f"ğŸ“Š ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ù…ÙƒØªÙ…Ù„: Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© {average_sentiment:.3f}")

            return {
                "status": "success",
                "news_score": round(average_sentiment, 3),
                "headlines": processed_articles[:8],  # Ø£Ù‡Ù… 8 Ù…Ù‚Ø§Ù„Ø§Øª
                "analysis_details": analysis_details
            }

        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ø°Ù‡Ø¨: {e}")
            return {
                "status": "error", 
                "news_score": 0, 
                "headlines": [],
                "analysis_details": {"error": str(e)}
            }

    def calculate_technical_indicators(self, gold_data: pd.DataFrame) -> pd.DataFrame:
        """Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ÙÙ†ÙŠØ© Ø§Ù„Ù…Ø­Ø³Ù†Ø©"""
        logger.info("ğŸ“ˆ Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ÙÙ†ÙŠØ© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©...")
        
        try:
            # Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
            gold_data['SMA_20'] = ta.sma(gold_data['Close'], length=20)
            gold_data['SMA_50'] = ta.sma(gold_data['Close'], length=50)
            gold_data['SMA_200'] = ta.sma(gold_data['Close'], length=200)
            gold_data['EMA_12'] = ta.ema(gold_data['Close'], length=12)
            gold_data['EMA_26'] = ta.ema(gold_data['Close'], length=26)
            
            # Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø²Ø®Ù…
            gold_data['RSI'] = ta.rsi(gold_data['Close'], length=14)
            macd = ta.macd(gold_data['Close'])
            gold_data['MACD'] = macd['MACD_12_26_9']
            gold_data['MACD_Signal'] = macd['MACDs_12_26_9']
            gold_data['MACD_Hist'] = macd['MACDh_12_26_9']
            
            # Bollinger Bands
            bbands = ta.bbands(gold_data['Close'])
            gold_data['BB_Upper'] = bbands['BBU_5_2.0']
            gold_data['BB_Middle'] = bbands['BBM_5_2.0']
            gold_data['BB_Lower'] = bbands['BBL_5_2.0']
            
            # Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ØªÙ‚Ù„Ø¨Ø§Øª
            gold_data['ATR'] = ta.atr(gold_data['High'], gold_data['Low'], gold_data['Close'], length=14)
            
            # Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø­Ø¬Ù…
            gold_data['OBV'] = ta.obv(gold_data['Close'], gold_data['Volume'])
            
            # Ù…Ø¤Ø´Ø±Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ© Ù„Ù„Ø°Ù‡Ø¨
            gold_data['Williams_R'] = ta.willr(gold_data['High'], gold_data['Low'], gold_data['Close'])
            gold_data['CCI'] = ta.cci(gold_data['High'], gold_data['Low'], gold_data['Close'])
            gold_data['Stoch_K'] = ta.stoch(gold_data['High'], gold_data['Low'], gold_data['Close'])['STOCHk_14_3_3']
            
            # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØµÙÙˆÙ Ø§Ù„ØªÙŠ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ NaN
            gold_data.dropna(inplace=True)
            logger.info(f"âœ… ØªÙ… Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ÙÙ†ÙŠØ© - Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù†Ø¸ÙŠÙØ©: {len(gold_data)} ØµÙ")
            
            return gold_data
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ÙÙ†ÙŠØ©: {e}")
            return gold_data

    def calculate_adaptive_weights(self, vix_value: float, market_trend: str) -> Dict[str, float]:
        """Ø­Ø³Ø§Ø¨ Ø§Ù„Ø£ÙˆØ²Ø§Ù† Ø§Ù„Ù…ØªÙƒÙŠÙØ© Ø­Ø³Ø¨ Ø¸Ø±ÙˆÙ Ø§Ù„Ø³ÙˆÙ‚"""
        if vix_value > 25:  # Ø³ÙˆÙ‚ Ø¹Ø§Ù„ÙŠ Ø§Ù„ØªÙ‚Ù„Ø¨
            return {
                'trend': 0.25, 'momentum': 0.20, 'correlation': 0.30, 
                'news': 0.15, 'volatility': 0.10
            }
        elif vix_value < 15:  # Ø³ÙˆÙ‚ Ù…Ù†Ø®ÙØ¶ Ø§Ù„ØªÙ‚Ù„Ø¨
            return {
                'trend': 0.40, 'momentum': 0.35, 'correlation': 0.15, 
                'news': 0.05, 'volatility': 0.05
            }
        else:  # Ø³ÙˆÙ‚ Ù…ØªÙˆØ³Ø· Ø§Ù„ØªÙ‚Ù„Ø¨
            return {
                'trend': 0.35, 'momentum': 0.25, 'correlation': 0.20, 
                'news': 0.15, 'volatility': 0.05
            }

    def determine_signal_strength(self, total_score: float) -> str:
        """ØªØ­Ø¯ÙŠØ¯ Ù‚ÙˆØ© Ø§Ù„Ø¥Ø´Ø§Ø±Ø©"""
        if total_score >= 2.0:
            return "Very Strong Buy"
        elif total_score >= 1.5:
            return "Strong Buy"
        elif total_score >= 1.0:
            return "Buy"
        elif total_score >= 0.5:
            return "Weak Buy"
        elif total_score >= -0.5:
            return "Hold"
        elif total_score >= -1.0:
            return "Weak Sell"
        elif total_score >= -1.5:
            return "Sell"
        elif total_score >= -2.0:
            return "Strong Sell"
        else:
            return "Very Strong Sell"

    def calculate_stop_loss(self, current_price: float, atr_value: float, signal: str) -> float:
        """Ø­Ø³Ø§Ø¨ Ù…Ø³ØªÙˆÙ‰ ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø©"""
        if signal.lower() in ['buy', 'strong buy', 'very strong buy']:
            return round(current_price - (2.5 * atr_value), 2)
        elif signal.lower() in ['sell', 'strong sell', 'very strong sell']:
            return round(current_price + (2.5 * atr_value), 2)
        else:
            return current_price

    def save_to_history(self, analysis_result: Dict) -> int:
        """Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ Ø§Ù„Ø³Ø¬Ù„ Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠ"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # Ø­ÙØ¸ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
            cursor.execute('''
                INSERT INTO analysis_history 
                (timestamp_utc, signal, total_score, trend_score, momentum_score, 
                 correlation_score, news_score, volatility_score, gold_price, dxy_value, 
                 vix_value, signal_strength, stop_loss_price, news_sentiment_score, market_volatility)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                analysis_result['timestamp_utc'],
                analysis_result['signal'],
                analysis_result['total_score'],
                analysis_result['components']['trend_score'],
                analysis_result['components']['momentum_score'],
                analysis_result['components']['correlation_score'],
                analysis_result['components']['news_score'],
                analysis_result['components'].get('volatility_score', 0),
                analysis_result['market_data']['gold_price'],
                analysis_result['market_data']['dxy'],
                analysis_result['market_data']['vix'],
                analysis_result['signal_strength'],
                analysis_result.get('stop_loss_price', 0),
                analysis_result['news_analysis'].get('news_sentiment_score', 0),
                analysis_result.get('market_volatility', 'normal')
            ))
            
            analysis_id = cursor.lastrowid
            
            # Ø­ÙØ¸ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ù…Ø±ØªØ¨Ø·Ø©
            headlines = analysis_result['news_analysis'].get('headlines', [])
            for headline in headlines:
                cursor.execute('''
                    INSERT INTO news_history 
                    (analysis_id, headline, source, sentiment_score, relevance_score, published_at)
                    VALUES (?, ?, ?, ?, ?, ?)
                ''', (
                    analysis_id,
                    headline.get('title', ''),
                    headline.get('source', ''),
                    headline.get('sentiment_score', 0),
                    headline.get('relevance_score', 0),
                    headline.get('published_at', '')
                ))
            
            conn.commit()
            conn.close()
            
            logger.info(f"ğŸ’¾ ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ Ø§Ù„Ø³Ø¬Ù„ Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠ - ID: {analysis_id}")
            return analysis_id
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ Ø§Ù„Ø³Ø¬Ù„ Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠ: {e}")
            return -1

    def get_historical_performance(self, days: int = 30) -> Dict:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ©"""
        try:
            conn = sqlite3.connect(self.db_path)
            
            query = '''
                SELECT signal, total_score, gold_price, timestamp_utc, signal_strength
                FROM analysis_history 
                WHERE datetime(timestamp_utc) >= datetime('now', '-{} days')
                ORDER BY timestamp_utc DESC
            '''.format(days)
            
            df = pd.read_sql_query(query, conn)
            conn.close()
            
            if df.empty:
                return {"status": "no_data", "message": "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ØªØ§Ø±ÙŠØ®ÙŠØ© ÙƒØ§ÙÙŠØ©"}
            
            # Ø­Ø³Ø§Ø¨ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡
            performance_stats = {
                "total_signals": len(df),
                "buy_signals": len(df[df['signal'].str.contains('Buy', na=False)]),
                "sell_signals": len(df[df['signal'].str.contains('Sell', na=False)]),
                "hold_signals": len(df[df['signal'] == 'Hold']),
                "average_score": round(df['total_score'].mean(), 3),
                "score_volatility": round(df['total_score'].std(), 3),
                "latest_signals": df.head(10).to_dict('records')
            }
            
            return {"status": "success", "performance": performance_stats}
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠ: {e}")
            return {"status": "error", "error": str(e)}

    def run_comprehensive_analysis(self) -> Dict:
        """ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø´Ø§Ù…Ù„ Ø§Ù„Ù…Ø­Ø³Ù†"""
        logger.info("ğŸš€ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø´Ø§Ù…Ù„ Ù„Ù„Ø°Ù‡Ø¨...")
        
        # Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø³ÙˆÙ‚
        market_data = self.fetch_market_data()
        if market_data is None:
            return {"status": "error", "error": "ÙØ´Ù„ Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø³ÙˆÙ‚"}
        
        # Ø¥Ø¹Ø¯Ø§Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø°Ù‡Ø¨
        gold_ticker = self.symbols['gold']
        gold_data = pd.DataFrame({
            'Open': market_data[('Open', gold_ticker)],
            'High': market_data[('High', gold_ticker)],
            'Low': market_data[('Low', gold_ticker)],
            'Close': market_data[('Close', gold_ticker)],
            'Volume': market_data[('Volume', gold_ticker)]
        }).dropna()
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ÙÙ†ÙŠØ©
        gold_data = self.calculate_technical_indicators(gold_data)
        
        if gold_data.empty:
            return {"status": "error", "error": "ÙØ´Ù„ ÙÙŠ Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ÙÙ†ÙŠØ©"}
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ù…ØªØ®ØµØµ
        logger.info("ğŸ“° Ø¨Ø¯Ø¡ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ù…ØªØ®ØµØµ...")
        news_analysis = self.analyze_gold_news()
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø­Ø§Ù„ÙŠØ©
        latest = gold_data.iloc[-1]
        current_price = latest['Close']
        current_atr = latest['ATR']
        
        # Ù‚ÙŠÙ… Ø§Ù„Ø³ÙˆÙ‚ Ø§Ù„Ø£Ø®Ø±Ù‰
        dxy_current = market_data[('Close', self.symbols['dxy'])].iloc[-1]
        vix_current = market_data[('Close', self.symbols['vix'])].iloc[-1]
        
        # ØªØ­Ø¯ÙŠØ¯ Ø­Ø§Ù„Ø© Ø§Ù„Ø³ÙˆÙ‚
        market_volatility = "high" if vix_current > 25 else "low" if vix_current < 15 else "normal"
        
        # Ø­Ø³Ø§Ø¨ Ù†Ù‚Ø§Ø· Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…Ø­Ø³Ù†Ø©
        scores = {}
        
        # 1. Ù†Ù‚Ø§Ø· Ø§Ù„Ø§ØªØ¬Ø§Ù‡ (Trend Score)
        if current_price > latest['SMA_200']:
            if current_price > latest['SMA_50']:
                scores['trend'] = 3.0 if current_price > latest['SMA_20'] else 2.0
            else:
                scores['trend'] = 1.0
        else:
            if current_price < latest['SMA_50']:
                scores['trend'] = -3.0 if current_price < latest['SMA_20'] else -2.0
            else:
                scores['trend'] = -1.0
        
        # 2. Ù†Ù‚Ø§Ø· Ø§Ù„Ø²Ø®Ù… (Momentum Score)
        momentum_score = 0
        if latest['MACD'] > latest['MACD_Signal']:
            momentum_score += 1.5
        if latest['RSI'] > 50:
            momentum_score += 1.0
        elif latest['RSI'] > 70:
            momentum_score -= 0.5  # ØªØ´Ø¨Ø¹ Ø´Ø±Ø§Ø¡
        if latest['Williams_R'] > -50:
            momentum_score += 0.5
        scores['momentum'] = momentum_score
        
        # 3. Ù†Ù‚Ø§Ø· Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø· (Correlation Score)
        gold_dxy_corr = market_data[('Close', gold_ticker)].tail(50).corr(
            market_data[('Close', self.symbols['dxy'])].tail(50)
        )
        if gold_dxy_corr < -0.6:
            scores['correlation'] = 2.0
        elif gold_dxy_corr < -0.3:
            scores['correlation'] = 1.0
        else:
            scores['correlation'] = -1.0
        
        # 4. Ù†Ù‚Ø§Ø· Ø§Ù„Ø£Ø®Ø¨Ø§Ø±
        scores['news'] = news_analysis.get('news_score', 0) * 2  # ØªØ¶Ø®ÙŠÙ… ØªØ£Ø«ÙŠØ± Ø§Ù„Ø£Ø®Ø¨Ø§Ø±
        
        # 5. Ù†Ù‚Ø§Ø· Ø§Ù„ØªÙ‚Ù„Ø¨Ø§Øª
        if vix_current > 25:
            scores['volatility'] = 1.5  # ØªÙ‚Ù„Ø¨Ø§Øª Ø¹Ø§Ù„ÙŠØ© ØªÙÙŠØ¯ Ø§Ù„Ø°Ù‡Ø¨
        elif vix_current < 15:
            scores['volatility'] = -0.5
        else:
            scores['volatility'] = 0
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø£ÙˆØ²Ø§Ù† Ø§Ù„Ù…ØªÙƒÙŠÙØ©
        weights = self.calculate_adaptive_weights(vix_current, "trend_up" if scores['trend'] > 0 else "trend_down")
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ©
        total_score = sum(scores[key] * weights[key] for key in scores.keys() if key in weights)
        
        # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø¥Ø´Ø§Ø±Ø© ÙˆÙ‚ÙˆØªÙ‡Ø§
        signal_strength = self.determine_signal_strength(total_score)
        basic_signal = "Buy" if total_score >= 1.0 else "Sell" if total_score <= -1.0 else "Hold"
        
        # Ø­Ø³Ø§Ø¨ Ù…Ø³ØªÙˆÙ‰ ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø©
        stop_loss = self.calculate_stop_loss(current_price, current_atr, basic_signal)
        
        # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
        analysis_result = {
            "timestamp_utc": datetime.utcnow().isoformat(),
            "signal": basic_signal,
            "signal_strength": signal_strength,
            "total_score": round(total_score, 3),
            "components": {
                "trend_score": round(scores['trend'], 2),
                "momentum_score": round(scores['momentum'], 2),
                "correlation_score": round(scores['correlation'], 2),
                "news_score": round(scores['news'], 2),
                "volatility_score": round(scores['volatility'], 2)
            },
            "weights_used": weights,
            "market_data": {
                "gold_price": round(current_price, 2),
                "dxy": round(dxy_current, 2),
                "vix": round(vix_current, 2),
                "atr": round(current_atr, 2)
            },
            "market_volatility": market_volatility,
            "stop_loss_price": stop_loss,
            "technical_indicators": {
                "rsi": round(latest['RSI'], 2),
                "macd": round(latest['MACD'], 4),
                "williams_r": round(latest['Williams_R'], 2),
                "sma_50": round(latest['SMA_50'], 2),
                "sma_200": round(latest['SMA_200'], 2)
            },
            "news_analysis": news_analysis
        }
        
        # Ø­ÙØ¸ ÙÙŠ Ø§Ù„Ø³Ø¬Ù„ Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠ
        history_id = self.save_to_history(analysis_result)
        analysis_result["history_id"] = history_id
        
        # Ø­ÙØ¸ ÙÙŠ Ù…Ù„Ù JSON
        with open("gold_analysis_enhanced.json", 'w', encoding='utf-8') as f:
            json.dump(analysis_result, f, ensure_ascii=False, indent=2)
        
        logger.info("âœ… ØªÙ… Ø¥Ù†Ø¬Ø§Ø² Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø´Ø§Ù…Ù„ Ø¨Ù†Ø¬Ø§Ø­")
        
        # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠ
        performance = self.get_historical_performance(30)
        analysis_result["historical_performance"] = performance
        
        return analysis_result

# === ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ­Ù„ÙŠÙ„ ===
if __name__ == "__main__":
    try:
        analyzer = ProfessionalGoldAnalyzerV2()
        results = analyzer.run_comprehensive_analysis()
        
        if results.get("status") == "error":
            logger.error(f"âŒ ÙØ´Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„: {results.get('error')}")
        else:
            logger.info("\n" + "="*60)
            logger.info("ğŸ“‹ Ù…Ù„Ø®Øµ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ")
            logger.info("="*60)
            logger.info(f"ğŸ¯ Ø§Ù„Ø¥Ø´Ø§Ø±Ø©: {results['signal']} ({results['signal_strength']})")
            logger.info(f"ğŸ“Š Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ©: {results['total_score']}")
            logger.info(f"ğŸ’° Ø³Ø¹Ø± Ø§Ù„Ø°Ù‡Ø¨: ${results['market_data']['gold_price']}")
            logger.info(f"ğŸ›‘ ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø©: ${results['stop_loss_price']}")
            logger.info(f"ğŸ“ˆ Ø­Ø§Ù„Ø© Ø§Ù„Ø³ÙˆÙ‚: {results['market_volatility']}")
            logger.info(f"ğŸ“° ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø®Ø¨Ø§Ø±: {results['news_analysis']['status']} "
                      f"(Ø§Ù„Ù†ØªÙŠØ¬Ø©: {results['news_analysis']['news_score']})")
            
            print("\nğŸ‰ ØªÙ… Ø­ÙØ¸ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙƒØ§Ù…Ù„ ÙÙŠ:")
            print("  - gold_analysis_enhanced.json")
            print("  - gold_analysis_history.db") 
            print("  - gold_analysis.log")
            
            # Ø¹Ø±Ø¶ Ø£Ù‡Ù… Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ†
            headlines = results['news_analysis'].get('headlines', [])
            if headlines:
                print(f"\nğŸ“° Ø£Ù‡Ù… {min(5, len(headlines))} Ø£Ø®Ø¨Ø§Ø± Ù…ØªØ¹Ù„Ù‚Ø© Ø¨Ø§Ù„Ø°Ù‡Ø¨:")
                for i, headline in enumerate(headlines[:5], 1):
                    print(f"  {i}. {headline['title'][:80]}... [{headline['source']}]")
                    
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ Ø¹Ø§Ù… ÙÙŠ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚: {e}")