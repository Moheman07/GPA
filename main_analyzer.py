#!/usr/bin/env python3
import yfinance as yf
import pandas as pd
import numpy as np
import requests
import json
import os
import sqlite3
import joblib
from datetime import datetime, timedelta
import warnings
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import xgboost as xgb
from textblob import TextBlob
import spacy
import backtrader as bt
from concurrent.futures import ThreadPoolExecutor, as_completed
import asyncio
import aiohttp

warnings.filterwarnings('ignore')

# ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ spaCy
try:
    nlp = spacy.load("en_core_web_sm")
except:
    os.system("python -m spacy download en_core_web_sm")
    nlp = spacy.load("en_core_web_sm")

class MLPredictor:
    """Ù†Ø¸Ø§Ù… Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ"""
    def __init__(self):
        self.model = None
        self.scaler = StandardScaler()
        self.feature_columns = []
        self.model_path = "gold_ml_model.pkl"
        self.scaler_path = "gold_scaler.pkl"

    def prepare_features(self, analysis_data):
        """ØªØ­Ø¶ÙŠØ± Ø§Ù„Ù…Ù…ÙŠØ²Ø§Øª Ù…Ù† Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ­Ù„ÙŠÙ„"""
        features = {}
        
        if 'gold_analysis' in analysis_data:
            scores = analysis_data['gold_analysis'].get('component_scores', {})
            features.update({f'score_{k}': v for k, v in scores.items()})
            features['total_score'] = analysis_data['gold_analysis'].get('total_score', 0)
            
            tech_summary = analysis_data['gold_analysis'].get('technical_summary', {})
            features.update({f'tech_{k}': v for k, v in tech_summary.items()})

        if 'volume_analysis' in analysis_data:
            vol = analysis_data['volume_analysis']
            features['volume_ratio'] = vol.get('volume_ratio', 1)
            features['volume_strength_encoded'] = self._encode_volume_strength(vol.get('volume_strength', 'Ø·Ø¨ÙŠØ¹ÙŠ'))

        if 'market_correlations' in analysis_data:
            corr = analysis_data['market_correlations'].get('correlations', {})
            features.update({f'corr_{k}': v for k, v in corr.items()})

        if 'economic_data' in analysis_data:
            features['economic_score'] = analysis_data['economic_data'].get('score', 0)

        if 'fibonacci_levels' in analysis_data:
            fib = analysis_data['fibonacci_levels']
            features['fib_position'] = fib.get('current_position', 50)

        return features

    def _encode_volume_strength(self, strength):
        """ØªØ­ÙˆÙŠÙ„ Ù‚ÙˆØ© Ø§Ù„Ø­Ø¬Ù… Ø¥Ù„Ù‰ Ø±Ù‚Ù…"""
        mapping = {'Ø¶Ø¹ÙŠÙ': 0, 'Ø·Ø¨ÙŠØ¹ÙŠ': 1, 'Ù‚ÙˆÙŠ': 2, 'Ù‚ÙˆÙŠ Ø¬Ø¯Ø§Ù‹': 3}
        return mapping.get(strength, 1)

    def train_model(self, historical_data):
        """ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ"""
        print("ğŸ¤– Ø¨Ø¯Ø¡ ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ...")
        
        X, y = [], []
        for record in historical_data:
            features = self.prepare_features(record['analysis'])
            if features:
                X.append(list(features.values()))
                y.append(1 if record['price_change_5d'] > 1.0 else 0)

        if len(X) < 100:
            print("âš ï¸ Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± ÙƒØ§ÙÙŠØ© Ù„Ù„ØªØ¯Ø±ÙŠØ¨")
            return False

        X, y = np.array(X), np.array(y)
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)

        models = {
            'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42),
            'GradientBoosting': GradientBoostingClassifier(n_estimators=100, random_state=42),
            'XGBoost': xgb.XGBClassifier(n_estimators=100, random_state=42, use_label_encoder=False)
        }

        best_model, best_score = None, 0
        
        for name, model in models.items():
            print(f"ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ {name}...")
            model.fit(X_train_scaled, y_train)
            
            y_pred = model.predict(X_test_scaled)
            f1 = f1_score(y_test, y_pred)
            
            print(f"  - F1 Score: {f1:.2%}")
            
            if f1 > best_score:
                best_score = f1
                best_model = model
                self.model = model

        print(f"\nâœ… Ø£ÙØ¶Ù„ Ù†Ù…ÙˆØ°Ø¬: {type(best_model).__name__} Ù…Ø¹ F1 Score: {best_score:.2%}")
        
        joblib.dump(self.model, self.model_path)
        joblib.dump(self.scaler, self.scaler_path)
        
        return True

    def predict_probability(self, analysis_data):
        """Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ© Ù†Ø¬Ø§Ø­ Ø§Ù„Ø¥Ø´Ø§Ø±Ø©"""
        try:
            if self.model is None:
                if os.path.exists(self.model_path):
                    self.model = joblib.load(self.model_path)
                    self.scaler = joblib.load(self.scaler_path)
                else:
                    return None, "Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØºÙŠØ± Ù…Ø¯Ø±Ø¨ Ø¨Ø¹Ø¯"

            features = self.prepare_features(analysis_data)
            X = np.array([list(features.values())])
            
            X_scaled = self.scaler.transform(X)
            probability = self.model.predict_proba(X_scaled)[0][1]
            
            if probability > 0.75:
                interpretation = "Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ© Ø¹Ø§Ù„ÙŠØ© Ø¬Ø¯Ø§Ù‹ Ù„Ù„Ù†Ø¬Ø§Ø­"
            elif probability > 0.60:
                interpretation = "Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ© Ø¬ÙŠØ¯Ø© Ù„Ù„Ù†Ø¬Ø§Ø­"
            elif probability > 0.45:
                interpretation = "Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ© Ù…ØªÙˆØ³Ø·Ø© - Ø­Ø°Ø±"
            else:
                interpretation = "Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ© Ù…Ù†Ø®ÙØ¶Ø© - ØªØ¬Ù†Ø¨"

            return probability, interpretation

        except Exception as e:
            print(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªÙ†Ø¨Ø¤: {e}")
            return None, str(e)

class MultiTimeframeAnalyzer:
    """Ù…Ø­Ù„Ù„ Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ø£Ø·Ø± Ø§Ù„Ø²Ù…Ù†ÙŠØ©"""
    def __init__(self):
        self.timeframes = {
            '1h': {'period': '5d', 'weight': 0.2},
            '4h': {'period': '1mo', 'weight': 0.3},
            '1d': {'period': '3mo', 'weight': 0.5}
        }

    def analyze_timeframe(self, symbol, interval, period):
        """ØªØ­Ù„ÙŠÙ„ Ø¥Ø·Ø§Ø± Ø²Ù…Ù†ÙŠ ÙˆØ§Ø­Ø¯"""
        try:
            data = yf.download(symbol, period=period, interval=interval, progress=False)
            if data.empty:
                return None

            # ØªØµØ­ÙŠØ­: Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª DataFrame ÙˆÙ„ÙŠØ³Øª Series
            if isinstance(data['Close'], pd.Series):
                close_prices = data['Close']
            else:
                close_prices = data['Close'].squeeze()
                
            data['SMA_20'] = close_prices.rolling(20).mean()
            data['RSI'] = self._calculate_rsi(close_prices)
            
            exp1 = close_prices.ewm(span=12).mean()
            exp2 = close_prices.ewm(span=26).mean()
            data['MACD'] = exp1 - exp2
            data['MACD_Signal'] = data['MACD'].ewm(span=9).mean()

            latest = data.iloc[-1]
            score = 0

            if latest['Close'] > latest['SMA_20']:
                score += 1
            else:
                score -= 1

            if 30 <= latest['RSI'] <= 70:
                score += 0.5 if latest['RSI'] > 50 else -0.5
            elif latest['RSI'] < 30:
                score += 1
            else:
                score -= 1

            if latest['MACD'] > latest['MACD_Signal']:
                score += 1
            else:
                score -= 1

            return {
                'score': score,
                'trend': 'ØµØ§Ø¹Ø¯' if score > 0 else 'Ù‡Ø§Ø¨Ø·',
                'strength': abs(score),
                'rsi': latest['RSI'],
                'price': latest['Close']
            }

        except Exception as e:
            print(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¥Ø·Ø§Ø± Ø§Ù„Ø²Ù…Ù†ÙŠ {interval}: {e}")
            return None

    def _calculate_rsi(self, prices, period=14):
        """Ø­Ø³Ø§Ø¨ RSI"""
        delta = prices.diff()
        gain = delta.where(delta > 0, 0).rolling(window=period).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
        rs = gain / loss
        rsi = 100 - (100 / (1 + rs))
        return rsi

    def get_coherence_score(self, symbol):
        """Ø­Ø³Ø§Ø¨ Ù†Ù‚Ø§Ø· Ø§Ù„ØªÙˆØ§ÙÙ‚ Ø¨ÙŠÙ† Ø§Ù„Ø£Ø·Ø± Ø§Ù„Ø²Ù…Ù†ÙŠØ©"""
        print("â° ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø·Ø± Ø§Ù„Ø²Ù…Ù†ÙŠØ© Ø§Ù„Ù…ØªØ¹Ø¯Ø¯Ø©...")
        
        results = {}
        total_weighted_score = 0
        total_weight = 0

        for tf_name, tf_config in self.timeframes.items():
            interval = {'1h': '1h', '4h': '4h', '1d': '1d'}[tf_name]
            
            analysis = self.analyze_timeframe(symbol, interval, tf_config['period'])
            
            if analysis:
                results[tf_name] = analysis
                total_weighted_score += analysis['score'] * tf_config['weight']
                total_weight += tf_config['weight']

        if total_weight == 0:
            return 0, results

        coherence_score = total_weighted_score / total_weight
        
        trends = [r['trend'] for r in results.values() if r]
        if all(t == 'ØµØ§Ø¹Ø¯' for t in trends):
            coherence_score += 2
            coherence_analysis = "ØªÙˆØ§ÙÙ‚ ÙƒØ§Ù…Ù„ ØµØ§Ø¹Ø¯ - Ù‚ÙˆØ© Ø§Ø³ØªØ«Ù†Ø§Ø¦ÙŠØ©"
        elif all(t == 'Ù‡Ø§Ø¨Ø·' for t in trends):
            coherence_score -= 2
            coherence_analysis = "ØªÙˆØ§ÙÙ‚ ÙƒØ§Ù…Ù„ Ù‡Ø§Ø¨Ø· - Ø¶Ø¹Ù Ø´Ø¯ÙŠØ¯"
        elif len(set(trends)) > 1:
            coherence_analysis = "ØªØ¶Ø§Ø±Ø¨ Ø¨ÙŠÙ† Ø§Ù„Ø£Ø·Ø± Ø§Ù„Ø²Ù…Ù†ÙŠØ© - Ø­Ø°Ø±"
        else:
            coherence_analysis = "ØªÙˆØ§ÙÙ‚ Ø¬Ø²Ø¦ÙŠ"

        return coherence_score, {
            'timeframes': results,
            'coherence_score': round(coherence_score, 2),
            'analysis': coherence_analysis,
            'recommendation': self._get_mtf_recommendation(coherence_score)
        }

    def _get_mtf_recommendation(self, score):
        """ØªÙˆØµÙŠØ© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ØªÙˆØ§ÙÙ‚"""
        if score > 2:
            return "Ø¯Ø®ÙˆÙ„ Ù‚ÙˆÙŠ - Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø·Ø± Ù…ØªÙˆØ§ÙÙ‚Ø©"
        elif score > 1:
            return "Ø¯Ø®ÙˆÙ„ Ù…Ø¹ØªØ¯Ù„ - ØªÙˆØ§ÙÙ‚ Ø¬ÙŠØ¯"
        elif score > -1:
            return "Ø§Ù†ØªØ¸Ø§Ø± - Ø¹Ø¯Ù… ÙˆØ¶ÙˆØ­"
        elif score > -2:
            return "ØªØ¬Ù†Ø¨ Ø§Ù„Ø´Ø±Ø§Ø¡ - Ø¶Ø¹Ù"
        else:
            return "Ø¨ÙŠØ¹ Ø£Ùˆ ØªØ¬Ù†Ø¨ ÙƒØ§Ù…Ù„ - ØªÙˆØ§ÙÙ‚ Ù‡Ø§Ø¨Ø·"

class AdvancedNewsAnalyzer:
    """Ù…Ø­Ù„Ù„ Ø£Ø®Ø¨Ø§Ø± Ù…ØªÙ‚Ø¯Ù… Ù…Ø¹ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø­Ø¯Ø§Ø«"""
    def __init__(self, api_key):
        self.api_key = api_key
        self.event_patterns = {
            'interest_rate': {
                'keywords': ['interest rate', 'rate decision', 'fomc', 'federal reserve', 'fed meeting'],
                'entities': ['Federal Reserve', 'Fed', 'FOMC', 'Jerome Powell'],
                'impact_multiplier': 3
            },
            'inflation': {
                'keywords': ['inflation', 'cpi', 'consumer price', 'pce'],
                'entities': ['Bureau of Labor Statistics', 'BLS'],
                'impact_multiplier': 2.5
            },
            'employment': {
                'keywords': ['employment', 'jobs', 'nfp', 'non-farm payroll', 'unemployment'],
                'entities': ['Labor Department', 'BLS'],
                'impact_multiplier': 2
            },
            'geopolitical': {
                'keywords': ['war', 'conflict', 'sanctions', 'crisis', 'tension'],
                'entities': ['Russia', 'China', 'Middle East', 'Ukraine'],
                'impact_multiplier': 2.5
            },
            'central_bank': {
                'keywords': ['central bank', 'ecb', 'boe', 'boj', 'monetary policy'],
                'entities': ['ECB', 'Bank of England', 'Bank of Japan'],
                'impact_multiplier': 2
            },
            'dollar': {
                'keywords': ['dollar', 'dxy', 'usd', 'currency'],
                'entities': ['Dollar Index', 'DXY'],
                'impact_multiplier': 1.5
            }
        }

    def extract_events(self, articles):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø­Ø¯Ø§Ø« Ù…Ù† Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… NLP"""
        extracted_events = []

        for article in articles:
            if not article.get('title'):
                continue

            text = f"{article['title']} {article.get('description', '')}"
            doc = nlp(text)
            
            entities = [(ent.text, ent.label_) for ent in doc.ents]
            event_type = self._classify_event(text.lower(), entities)

            if event_type:
                sentiment_score = self._advanced_sentiment_analysis(text)
                numbers = self._extract_numbers(doc)

                event = {
                    'type': event_type,
                    'title': article['title'],
                    'source': article.get('source', {}).get('name', 'Unknown'),
                    'published': article.get('publishedAt', ''),
                    'entities': entities,
                    'numbers': numbers,
                    'sentiment_score': sentiment_score,
                    'impact_score': self._calculate_impact_score(event_type, sentiment_score),
                                        'url': article.get('url', '')
                }
                extracted_events.append(event)

        return self._analyze_events_impact(extracted_events)

    def _classify_event(self, text, entities):
        """ØªØµÙ†ÙŠÙ Ù†ÙˆØ¹ Ø§Ù„Ø­Ø¯Ø«"""
        for event_type, patterns in self.event_patterns.items():
            if any(keyword in text for keyword in patterns['keywords']):
                return event_type
            
            entity_texts = [ent[0] for ent in entities]
            if any(entity in ' '.join(entity_texts) for entity in patterns['entities']):
                return event_type
        return None

    def _advanced_sentiment_analysis(self, text):
        """ØªØ­Ù„ÙŠÙ„ Ù…ØªÙ‚Ø¯Ù… Ù„Ù„Ù…Ø´Ø§Ø¹Ø±"""
        blob = TextBlob(text)
        basic_sentiment = blob.sentiment.polarity
        
        gold_positive = ['surge', 'rally', 'gain', 'rise', 'bullish', 'support', 'demand']
        gold_negative = ['fall', 'drop', 'decline', 'bearish', 'pressure', 'weak']
        
        positive_count = sum(1 for word in gold_positive if word in text.lower())
        negative_count = sum(1 for word in gold_negative if word in text.lower())
        
        final_sentiment = basic_sentiment + (positive_count - negative_count) * 0.1
        return max(-1, min(1, final_sentiment))

    def _extract_numbers(self, doc):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… ÙˆØ§Ù„Ù†Ø³Ø¨ Ø§Ù„Ù…Ø¦ÙˆÙŠØ©"""
        numbers = []
        for token in doc:
            if token.like_num or '%' in token.text:
                context = []
                for i in range(max(0, token.i - 3), min(len(doc), token.i + 3)):
                    context.append(doc[i].text)
                numbers.append({
                    'value': token.text,
                    'context': ' '.join(context)
                })
        return numbers

    def _calculate_impact_score(self, event_type, sentiment):
        """Ø­Ø³Ø§Ø¨ Ù†Ù‚Ø§Ø· Ø§Ù„ØªØ£Ø«ÙŠØ±"""
        base_impact = self.event_patterns.get(event_type, {}).get('impact_multiplier', 1)
        
        if event_type in ['interest_rate', 'inflation']:
            impact = base_impact * (-sentiment)
        else:
            impact = base_impact * sentiment
            
        return round(impact, 2)

    def _analyze_events_impact(self, events):
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªØ£Ø«ÙŠØ± Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ù„Ù„Ø£Ø­Ø¯Ø§Ø«"""
        if not events:
            return {
                'events': [],
                'total_impact': 0,
                'dominant_theme': None,
                'recommendation': 'Ù„Ø§ ØªÙˆØ¬Ø¯ Ø£Ø­Ø¯Ø§Ø« Ù…Ø¤Ø«Ø±Ø©'
            }

        event_groups = {}
        for event in events:
            event_type = event['type']
            if event_type not in event_groups:
                event_groups[event_type] = []
            event_groups[event_type].append(event)

        total_impact = sum(event['impact_score'] for event in events)
        dominant_theme = max(event_groups.keys(), 
                           key=lambda k: sum(e['impact_score'] for e in event_groups[k]))

        if total_impact > 5:
            recommendation = "Ø£Ø®Ø¨Ø§Ø± Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ© Ù‚ÙˆÙŠØ© Ø¬Ø¯Ø§Ù‹ Ù„Ù„Ø°Ù‡Ø¨"
        elif total_impact > 2:
            recommendation = "Ø£Ø®Ø¨Ø§Ø± Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ© Ù„Ù„Ø°Ù‡Ø¨"
        elif total_impact < -5:
            recommendation = "Ø£Ø®Ø¨Ø§Ø± Ø³Ù„Ø¨ÙŠØ© Ù‚ÙˆÙŠØ© Ø¬Ø¯Ø§Ù‹ Ù„Ù„Ø°Ù‡Ø¨"
        elif total_impact < -2:
            recommendation = "Ø£Ø®Ø¨Ø§Ø± Ø³Ù„Ø¨ÙŠØ© Ù„Ù„Ø°Ù‡Ø¨"
        else:
            recommendation = "ØªØ£Ø«ÙŠØ± Ù…Ø­Ø§ÙŠØ¯ Ø£Ùˆ Ù…Ø®ØªÙ„Ø·"

        return {
            'events': events[:10],
            'event_summary': {t: len(e) for t, e in event_groups.items()},
            'total_impact': round(total_impact, 2),
            'dominant_theme': dominant_theme,
            'recommendation': recommendation
        }

    async def fetch_news_async(self):
        """Ø¬Ù„Ø¨ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø¨Ø´ÙƒÙ„ ØºÙŠØ± Ù…ØªØ²Ø§Ù…Ù†"""
        keywords = ['"gold price"', '"federal reserve"', '"interest rates"', '"inflation data"', '"XAU/USD"']
        
        async with aiohttp.ClientSession() as session:
            tasks = []
            for keyword in keywords:
                url = f"https://newsapi.org/v2/everything?q={keyword}&language=en&sortBy=publishedAt&pageSize=20&apiKey={self.api_key}"
                tasks.append(self._fetch_url(session, url))
            
            results = await asyncio.gather(*tasks)

        all_articles = []
        for result in results:
            if result and 'articles' in result:
                all_articles.extend(result['articles'])

        seen_urls = set()
        unique_articles = []
        for article in all_articles:
            if article.get('url') not in seen_urls:
                seen_urls.add(article.get('url'))
                unique_articles.append(article)

        return unique_articles

    async def _fetch_url(self, session, url):
        """Ø¬Ù„Ø¨ URL ÙˆØ§Ø­Ø¯"""
        try:
            async with session.get(url, timeout=10) as response:
                return await response.json()
        except Exception as e:
            print(f"Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ø§Ù„Ø£Ø®Ø¨Ø§Ø±: {e}")
            return None

class ProfessionalBacktester:
    """Ù†Ø¸Ø§Ù… Ø§Ø®ØªØ¨Ø§Ø± Ø®Ù„ÙÙŠ Ø§Ø­ØªØ±Ø§ÙÙŠ"""
    
    class GoldStrategy(bt.Strategy):
        params = (
            ('analyzer', None),
            ('risk_percent', 0.02),
        )

        def __init__(self):
            self.order = None
            self.buyprice = None
            self.buycomm = None
            self.trades = []

        def next(self):
            if self.order:
                return

            current_data = self._prepare_current_data()
            signal = self.params.analyzer.generate_signal_for_backtest(current_data)

            if not self.position:
                if signal['action'] in ['Strong Buy', 'Buy']:
                    size = self._calculate_position_size(signal['confidence'], self.data.close[0])
                    if size > 0:
                        self.order = self.buy(size=size)
            else:
                if signal['action'] in ['Strong Sell', 'Sell']:
                    self.order = self.sell()
                elif self.position.size > 0:
                    current_price = self.data.close[0]
                    entry_price = self.position.price
                    
                    if current_price < entry_price * 0.98:
                        self.order = self.sell()
                    elif current_price > entry_price * 1.05:
                        self.order = self.sell()

        def _prepare_current_data(self):
            """ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø­Ø§Ù„ÙŠØ© Ù„Ù„ØªØ­Ù„ÙŠÙ„"""
            return {
                'close': self.data.close[0],
                'open': self.data.open[0],
                'high': self.data.high[0],
                'low': self.data.low[0],
                'volume': self.data.volume[0]
            }

        def _calculate_position_size(self, confidence, price):
            """Ø­Ø³Ø§Ø¨ Ø­Ø¬Ù… Ø§Ù„Ù…Ø±ÙƒØ²"""
            if price <= 0:
                return 0
                
            cash_to_risk = self.broker.getcash() * self.params.risk_percent
            base_size = cash_to_risk / price
            
            if confidence == 'Very High':
                return base_size * 2
            elif confidence == 'High':
                return base_size * 1.5
            else:
                return base_size

        def notify_order(self, order):
            if order.status in [order.Submitted, order.Accepted]:
                return

            if order.status in [order.Completed]:
                if order.isbuy():
                    self.buyprice = order.executed.price
                    self.buycomm = order.executed.comm
                else:
                    profit = (order.executed.price - self.buyprice) * order.executed.size
                    self.trades.append({
                        'profit': profit,
                        'return': (order.executed.price - self.buyprice) / self.buyprice
                    })

            self.order = None

    def __init__(self, analyzer):
        self.analyzer = analyzer

    def run_backtest(self, data, initial_cash=10000):
        """ØªØ´ØºÙŠÙ„ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø®Ù„ÙÙŠ"""
        print("ğŸ”„ Ø¨Ø¯Ø¡ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø®Ù„ÙÙŠ Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠ...")
        
        cerebro = bt.Cerebro()
        data_feed = bt.feeds.PandasData(dataname=data)
        cerebro.adddata(data_feed)
        
        cerebro.addstrategy(self.GoldStrategy, analyzer=self.analyzer)
        
        cerebro.broker.setcash(initial_cash)
        cerebro.broker.setcommission(commission=0.001)
        
        cerebro.addanalyzer(bt.analyzers.SharpeRatio, _name='sharpe')
        cerebro.addanalyzer(bt.analyzers.DrawDown, _name='drawdown')
        cerebro.addanalyzer(bt.analyzers.Returns, _name='returns')
        cerebro.addanalyzer(bt.analyzers.TradeAnalyzer, _name='trades')
        
        results = cerebro.run()
        strat = results[0]
        
        sharpe = strat.analyzers.sharpe.get_analysis()
        drawdown = strat.analyzers.drawdown.get_analysis()
        returns = strat.analyzers.returns.get_analysis()
        trades = strat.analyzers.trades.get_analysis()
        
        final_value = cerebro.broker.getvalue()
        total_return = (final_value - initial_cash) / initial_cash * 100
        
        backtest_results = {
            'initial_capital': initial_cash,
            'final_value': round(final_value, 2),
            'total_return': round(total_return, 2),
            'sharpe_ratio': round(sharpe.get('sharperatio', 0), 3),
            'max_drawdown': round(drawdown.get('max', {}).get('drawdown', 0), 2),
            'total_trades': trades.get('total', {}).get('total', 0),
            'winning_trades': trades.get('won', {}).get('total', 0),
            'losing_trades': trades.get('lost', {}).get('total', 0),
            'win_rate': round(trades.get('won', {}).get('total', 0) / max(trades.get('total', {}).get('total', 1), 1) * 100, 2),
            'avg_trade_return': round(returns.get('rtot', 0) / max(trades.get('total', {}).get('total', 1), 1), 4),
            'best_trade': round(trades.get('won', {}).get('pnl', {}).get('max', 0), 2),
            'worst_trade': round(trades.get('lost', {}).get('pnl', {}).get('max', 0), 2),
            'avg_win': round(trades.get('won', {}).get('pnl', {}).get('average', 0), 2),
            'avg_loss': round(trades.get('lost', {}).get('pnl', {}).get('average', 0), 2),
            'profit_factor': self._calculate_profit_factor(trades),
            'recovery_factor': self._calculate_recovery_factor(total_return, drawdown),
            'risk_reward_ratio': self._calculate_risk_reward(trades)
        }
        
        self._generate_backtest_report(backtest_results)
        return backtest_results

    def _calculate_profit_factor(self, trades):
        """Ø­Ø³Ø§Ø¨ Ø¹Ø§Ù…Ù„ Ø§Ù„Ø±Ø¨Ø­"""
        try:
            gross_profit = abs(trades.get('won', {}).get('pnl', {}).get('total', 0))
            gross_loss = abs(trades.get('lost', {}).get('pnl', {}).get('total', 0))
            return round(gross_profit / gross_loss, 2) if gross_loss > 0 else 0
        except:
            return 0

    def _calculate_recovery_factor(self, total_return, drawdown):
        """Ø­Ø³Ø§Ø¨ Ø¹Ø§Ù…Ù„ Ø§Ù„Ø§Ø³ØªØ±Ø¯Ø§Ø¯"""
        try:
            max_dd = abs(drawdown.get('max', {}).get('drawdown', 1))
            return round(total_return / max_dd, 2) if max_dd > 0 else 0
        except:
            return 0

    def _calculate_risk_reward(self, trades):
        """Ø­Ø³Ø§Ø¨ Ù†Ø³Ø¨Ø© Ø§Ù„Ù…Ø®Ø§Ø·Ø±Ø© Ø¥Ù„Ù‰ Ø§Ù„Ù…ÙƒØ§ÙØ£Ø©"""
        try:
            avg_win = abs(trades.get('won', {}).get('pnl', {}).get('average', 0))
            avg_loss = abs(trades.get('lost', {}).get('pnl', {}).get('average', 1))
            return round(avg_win / avg_loss, 2) if avg_loss > 0 else 0
        except:
            return 0

    def _generate_backtest_report(self, results):
        """ØªÙˆÙ„ÙŠØ¯ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø®Ù„ÙÙŠ"""
        print("\n" + "="*60)
        print("ğŸ“Š ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø®Ù„ÙÙŠ Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠ")
        print("="*60)
        
        print(f"\nğŸ’° Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù…Ø§Ù„ÙŠ:")
        print(f"  â€¢ Ø±Ø£Ø³ Ø§Ù„Ù…Ø§Ù„ Ø§Ù„Ø£ÙˆÙ„ÙŠ: ${results['initial_capital']:,}")
        print(f"  â€¢ Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©: ${results['final_value']:,}")
        print(f"  â€¢ Ø§Ù„Ø¹Ø§Ø¦Ø¯ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ: {results['total_return']}%")
        print(f"  â€¢ Ù†Ø³Ø¨Ø© Ø´Ø§Ø±Ø¨: {results['sharpe_ratio']}")
        print(f"  â€¢ Ø£Ù‚ØµÙ‰ Ø§Ù†Ø®ÙØ§Ø¶: {results['max_drawdown']}%")
        
        print(f"\nğŸ“ˆ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ØªØ¯Ø§ÙˆÙ„:")
        print(f"  â€¢ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ØµÙÙ‚Ø§Øª: {results['total_trades']}")
        print(f"  â€¢ Ø§Ù„ØµÙÙ‚Ø§Øª Ø§Ù„Ø±Ø§Ø¨Ø­Ø©: {results['winning_trades']}")
        print(f"  â€¢ Ø§Ù„ØµÙÙ‚Ø§Øª Ø§Ù„Ø®Ø§Ø³Ø±Ø©: {results['losing_trades']}")
        print(f"  â€¢ Ù…Ø¹Ø¯Ù„ Ø§Ù„ÙÙˆØ²: {results['win_rate']}%")
        
        print(f"\nğŸ’µ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø±Ø¨Ø§Ø­ ÙˆØ§Ù„Ø®Ø³Ø§Ø¦Ø±:")
        print(f"  â€¢ Ù…ØªÙˆØ³Ø· Ø§Ù„Ø±Ø¨Ø­: ${results['avg_win']}")
        print(f"  â€¢ Ù…ØªÙˆØ³Ø· Ø§Ù„Ø®Ø³Ø§Ø±Ø©: ${results['avg_loss']}")
        print(f"  â€¢ Ø£ÙØ¶Ù„ ØµÙÙ‚Ø©: ${results['best_trade']}")
        print(f"  â€¢ Ø£Ø³ÙˆØ£ ØµÙÙ‚Ø©: ${results['worst_trade']}")
        print(f"  â€¢ Ø¹Ø§Ù…Ù„ Ø§Ù„Ø±Ø¨Ø­: {results['profit_factor']}")
        print(f"  â€¢ Ù†Ø³Ø¨Ø© Ø§Ù„Ù…Ø®Ø§Ø·Ø±Ø©/Ø§Ù„Ù…ÙƒØ§ÙØ£Ø©: {results['risk_reward_ratio']}")
        
                print(f"\nğŸ¯ ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ©:")
        if results['sharpe_ratio'] > 2:
            print("  âœ… Ø£Ø¯Ø§Ø¡ Ù…Ù…ØªØ§Ø² - Ù†Ø³Ø¨Ø© Ø´Ø§Ø±Ø¨ Ø¹Ø§Ù„ÙŠØ© Ø¬Ø¯Ø§Ù‹")
        elif results['sharpe_ratio'] > 1:
            print("  âœ… Ø£Ø¯Ø§Ø¡ Ø¬ÙŠØ¯ - Ù†Ø³Ø¨Ø© Ø´Ø§Ø±Ø¨ Ø¬ÙŠØ¯Ø©")
        elif results['sharpe_ratio'] > 0.5:
            print("  âš ï¸ Ø£Ø¯Ø§Ø¡ Ù…Ù‚Ø¨ÙˆÙ„ - ÙŠØ­ØªØ§Ø¬ ØªØ­Ø³ÙŠÙ†")
        else:
            print("  âŒ Ø£Ø¯Ø§Ø¡ Ø¶Ø¹ÙŠÙ - ÙŠØ­ØªØ§Ø¬ Ù…Ø±Ø§Ø¬Ø¹Ø© Ø´Ø§Ù…Ù„Ø©")

        if results['win_rate'] > 60:
            print("  âœ… Ù…Ø¹Ø¯Ù„ ÙÙˆØ² Ù…Ù…ØªØ§Ø²")
        elif results['win_rate'] > 50:
            print("  âœ… Ù…Ø¹Ø¯Ù„ ÙÙˆØ² Ø¬ÙŠØ¯")
        else:
            print("  âš ï¸ Ù…Ø¹Ø¯Ù„ ÙÙˆØ² ÙŠØ­ØªØ§Ø¬ ØªØ­Ø³ÙŠÙ†")

        if results['profit_factor'] > 2:
            print("  âœ… Ø¹Ø§Ù…Ù„ Ø±Ø¨Ø­ Ù…Ù…ØªØ§Ø²")
        elif results['profit_factor'] > 1.5:
            print("  âœ… Ø¹Ø§Ù…Ù„ Ø±Ø¨Ø­ Ø¬ÙŠØ¯")
        else:
            print("  âš ï¸ Ø¹Ø§Ù…Ù„ Ø±Ø¨Ø­ Ø¶Ø¹ÙŠÙ")

        print("="*60)

class DatabaseManager:
    """Ù…Ø¯ÙŠØ± Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ©"""
    def __init__(self, db_path="analysis_history.db"):
        self.db_path = db_path
        self.init_database()

    def init_database(self):
        """ØªÙ‡ÙŠØ¦Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        # ØªØµØ­ÙŠØ­: Ø¥Ø¶Ø§ÙØ© IF NOT EXISTS Ù„ØªØ¬Ù†Ø¨ Ø®Ø·Ø£ UNIQUE constraint
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS analysis_history (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                analysis_date DATE UNIQUE,
                gold_price REAL,
                signal TEXT,
                confidence TEXT,
                total_score REAL,
                component_scores TEXT,
                technical_indicators TEXT,
                volume_analysis TEXT,
                correlations TEXT,
                economic_score REAL,
                news_sentiment TEXT,
                mtf_coherence REAL,
                ml_probability REAL,
                price_after_1d REAL,
                price_after_5d REAL,
                price_after_10d REAL,
                price_change_1d REAL,
                price_change_5d REAL,
                price_change_10d REAL,
                signal_success BOOLEAN
            )
        ''')

        cursor.execute('''
            CREATE TABLE IF NOT EXISTS performance_metrics (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                date DATE,
                metric_name TEXT,
                metric_value REAL,
                details TEXT
            )
        ''')

        conn.commit()
        conn.close()

    def save_analysis(self, analysis_data):
        """Ø­ÙØ¸ Ø§Ù„ØªØ­Ù„ÙŠÙ„ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        try:
            gold_analysis = analysis_data.get('gold_analysis', {})
            if not gold_analysis or 'error' in gold_analysis:
                print("âš ï¸ ØªÙ… ØªØ®Ø·ÙŠ Ø§Ù„Ø­ÙØ¸ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø³Ø¨Ø¨ ÙˆØ¬ÙˆØ¯ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„")
                return

            # ØªØµØ­ÙŠØ­: Ø§Ø³ØªØ®Ø¯Ø§Ù… INSERT OR REPLACE Ù„ØªØ¬Ù†Ø¨ Ø®Ø·Ø£ UNIQUE constraint
            cursor.execute('''
                INSERT OR REPLACE INTO analysis_history (
                    analysis_date, gold_price, signal, confidence, total_score,
                    component_scores, technical_indicators, volume_analysis,
                    correlations, economic_score, news_sentiment, mtf_coherence,
                    ml_probability
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                datetime.now().date(),
                gold_analysis.get('current_price'),
                gold_analysis.get('signal'),
                gold_analysis.get('confidence'),
                gold_analysis.get('total_score'),
                json.dumps(gold_analysis.get('component_scores', {})),
                json.dumps(gold_analysis.get('technical_summary', {})),
                json.dumps(analysis_data.get('volume_analysis', {})),
                json.dumps(analysis_data.get('market_correlations', {}).get('correlations', {})),
                analysis_data.get('economic_data', {}).get('score', 0),
                analysis_data.get('news_analysis', {}).get('summary', {}).get('overall_sentiment'),
                analysis_data.get('mtf_analysis', {}).get('coherence_score', 0),
                gold_analysis.get('ml_prediction', {}).get('probability', 0)
            ))

            conn.commit()
            print("âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„ØªØ­Ù„ÙŠÙ„ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")

        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ Ø§Ù„ØªØ­Ù„ÙŠÙ„: {e}")
            conn.rollback()
        finally:
            conn.close()

    def update_future_prices(self):
        """ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø£Ø³Ø¹Ø§Ø± Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠØ© Ù„Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        try:
            # ØªØµØ­ÙŠØ­: Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ù‚Ø¨Ù„ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…
            cursor.execute("PRAGMA table_info(analysis_history)")
            columns = [column[1] for column in cursor.fetchall()]
            
            if 'price_after_10d' not in columns:
                print("âš ï¸ Ø¬Ø¯ÙˆÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙŠØ­ØªØ§Ø¬ ØªØ­Ø¯ÙŠØ«")
                return

            cursor.execute('''
                SELECT id, analysis_date, gold_price 
                FROM analysis_history 
                WHERE price_after_10d IS NULL 
                AND analysis_date <= date('now', '-10 days')
            ''')

            records = cursor.fetchall()

            for record_id, analysis_date, original_price in records:
                future_prices = self._get_future_prices(analysis_date)

                if future_prices:
                    changes = {
                        '1d': ((future_prices.get('1d', original_price) - original_price) / original_price * 100),
                        '5d': ((future_prices.get('5d', original_price) - original_price) / original_price * 100),
                        '10d': ((future_prices.get('10d', original_price) - original_price) / original_price * 100)
                    }

                    signal_success = changes['5d'] > 1.0

                    cursor.execute('''
                        UPDATE analysis_history 
                        SET price_after_1d = ?, price_after_5d = ?, price_after_10d = ?,
                            price_change_1d = ?, price_change_5d = ?, price_change_10d = ?,
                            signal_success = ?
                        WHERE id = ?
                    ''', (
                        future_prices.get('1d'), future_prices.get('5d'), future_prices.get('10d'),
                        changes['1d'], changes['5d'], changes['10d'],
                        signal_success, record_id
                    ))

            conn.commit()
            if len(records) > 0:
                print(f"âœ… ØªÙ… ØªØ­Ø¯ÙŠØ« {len(records)} Ø³Ø¬Ù„ Ø¨Ø§Ù„Ø£Ø³Ø¹Ø§Ø± Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠØ©")

        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø£Ø³Ø¹Ø§Ø± Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠØ©: {e}")
            conn.rollback()
        finally:
            conn.close()

    def _get_future_prices(self, analysis_date):
        """Ø¬Ù„Ø¨ Ø§Ù„Ø£Ø³Ø¹Ø§Ø± Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠØ© Ù„ØªØ§Ø±ÙŠØ® Ù…Ø¹ÙŠÙ†"""
        try:
            if isinstance(analysis_date, str):
                analysis_date = datetime.strptime(analysis_date, '%Y-%m-%d').date()

            end_date = analysis_date + timedelta(days=15)
            data = yf.download('GC=F', start=analysis_date, end=end_date, progress=False)

            if data.empty:
                return None

            prices = {}

            for days in [1, 5, 10]:
                target_date = analysis_date + timedelta(days=days)

                for i in range(5):
                    check_date = target_date + timedelta(days=i)
                    if check_date in data.index:
                        prices[f'{days}d'] = data.loc[check_date, 'Close']
                        break

            return prices

        except Exception as e:
            print(f"Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ø§Ù„Ø£Ø³Ø¹Ø§Ø± Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠØ©: {e}")
            return None

    def get_training_data(self, min_records=100):
        """Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ù„Ù„Ù†Ù…ÙˆØ°Ø¬"""
        conn = sqlite3.connect(self.db_path)

        query = '''
            SELECT * FROM analysis_history 
            WHERE signal_success IS NOT NULL 
            ORDER BY analysis_date DESC 
            LIMIT ?
        '''

        df = pd.read_sql_query(query, conn, params=(min_records * 2,))
        conn.close()

        if len(df) < min_records:
            print(f"âš ï¸ Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± ÙƒØ§ÙÙŠØ© Ù„Ù„ØªØ¯Ø±ÙŠØ¨: {len(df)} Ø³Ø¬Ù„ ÙÙ‚Ø·")
            return None

        training_data = []
        for _, row in df.iterrows():
            record = {
                'analysis': {
                    'gold_analysis': {
                        'current_price': row['gold_price'],
                        'signal': row['signal'],
                        'confidence': row['confidence'],
                        'total_score': row['total_score'],
                        'component_scores': json.loads(row['component_scores'] or '{}'),
                        'technical_summary': json.loads(row['technical_indicators'] or '{}')
                    },
                    'volume_analysis': json.loads(row['volume_analysis'] or '{}'),
                    'market_correlations': {
                        'correlations': json.loads(row['correlations'] or '{}')
                    },
                    'economic_data': {
                        'score': row['economic_score']
                    }
                },
                'price_change_5d': row['price_change_5d'],
                'signal_success': row['signal_success']
            }
            training_data.append(record)

        return training_data

class ProfessionalGoldAnalyzerV3:
    """Ø§Ù„Ø¥ØµØ¯Ø§Ø± 3.0 Ù…Ù† Ù…Ø­Ù„Ù„ Ø§Ù„Ø°Ù‡Ø¨ Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠ"""
    def __init__(self):
        self.symbols = {
            'gold': 'GC=F', 'gold_etf': 'GLD', 'dxy': 'DX-Y.NYB',
            'vix': '^VIX', 'treasury': '^TNX', 'oil': 'CL=F',
            'spy': 'SPY', 'usdeur': 'EURUSD=X', 'silver': 'SI=F'
        }

        self.ml_predictor = MLPredictor()
        self.mtf_analyzer = MultiTimeframeAnalyzer()
        self.news_analyzer = AdvancedNewsAnalyzer(os.getenv("NEWS_API_KEY"))
        self.db_manager = DatabaseManager()
        self.backtester = ProfessionalBacktester(self)

        self.news_api_key = os.getenv("NEWS_API_KEY")
        self.fred_api_key = os.getenv("FRED_API_KEY")

    def fetch_multi_timeframe_data(self):
        """Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø© Ø§Ù„Ø£Ø·Ø± Ø§Ù„Ø²Ù…Ù†ÙŠØ©"""
        print("ğŸ“Š Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø© Ø§Ù„Ø£Ø·Ø± Ø§Ù„Ø²Ù…Ù†ÙŠØ©...")
        try:
            daily_data = yf.download(list(self.symbols.values()), 
                                    period="3y", interval="1d", 
                                    group_by='ticker', progress=False)

            hourly_data = yf.download(self.symbols['gold'], 
                                     period="1mo", interval="1h", 
                                     progress=False)

            weekly_data = yf.download(self.symbols['gold'], 
                                     period="2y", interval="1wk", 
                                     progress=False)

            if daily_data.empty: 
                raise ValueError("ÙØ´Ù„ Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")

            return {
                'daily': daily_data, 
                'hourly': hourly_data,
                'weekly': weekly_data
            }
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {e}")
            return None

    def extract_gold_data(self, market_data):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø°Ù‡Ø¨"""
        print("ğŸ” Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø°Ù‡Ø¨...")
        try:
            daily_data = market_data['daily']
            gold_symbol = self.symbols['gold']

            if not (gold_symbol in daily_data.columns.levels[0] and 
                   not daily_data[gold_symbol].dropna().empty):
                gold_symbol = self.symbols['gold_etf']
                if not (gold_symbol in daily_data.columns.levels[0] and 
                       not daily_data[gold_symbol].dropna().empty):
                    raise ValueError("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ø°Ù‡Ø¨")

            gold_daily = daily_data[gold_symbol].copy()
            gold_daily.dropna(subset=['Close'], inplace=True)

            if len(gold_daily) < 200: 
                raise ValueError("Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± ÙƒØ§ÙÙŠØ©")

            print(f"âœ… Ø¨ÙŠØ§Ù†Ø§Øª ÙŠÙˆÙ…ÙŠØ© Ù†Ø¸ÙŠÙØ©: {len(gold_daily)} ÙŠÙˆÙ…")
            return gold_daily
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø°Ù‡Ø¨: {e}")
            return None

    def calculate_professional_indicators(self, gold_data):
        """Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠØ© Ø§Ù„Ù…Ø­Ø³Ù‘Ù†Ø©"""
        print("ğŸ“Š Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠØ© Ø§Ù„Ù…Ø­Ø³Ù‘Ù†Ø©...")
        try:
            df = gold_data.copy()

            # Ø§Ù„Ù…ØªÙˆØ³Ø·Ø§Øª Ø§Ù„Ù…ØªØ­Ø±ÙƒØ©
            for period in [10, 20, 50, 100, 200]:
                df[f'SMA_{period}'] = df['Close'].rolling(window=period).mean()

            # EMA
            df['EMA_9'] = df['Close'].ewm(span=9).mean()
            df['EMA_21'] = df['Close'].ewm(span=21).mean()
            
            # Ø§Ù„ØªÙ‚Ø§Ø·Ø¹Ø§Øª
            df['Golden_Cross'] = (df['SMA_50'] > df['SMA_200']).astype(int)
            df['Death_Cross'] = (df['SMA_50'] < df['SMA_200']).astype(int)

                        # RSI
            delta = df['Close'].diff()
            gain = delta.where(delta > 0, 0).rolling(window=14).mean()
            loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
            df['RSI'] = 100 - (100 / (1 + gain / loss))
            df['RSI_MA'] = df['RSI'].rolling(window=5).mean()

            # MACD
            exp1 = df['Close'].ewm(span=12).mean()
            exp2 = df['Close'].ewm(span=26).mean()
            df['MACD'] = exp1 - exp2
            df['MACD_Signal'] = df['MACD'].ewm(span=9).mean()
            df['MACD_Histogram'] = df['MACD'] - df['MACD_Signal']
            df['MACD_Cross'] = np.where(df['MACD'] > df['MACD_Signal'], 1, -1)

            # Bollinger Bands
            std = df['Close'].rolling(window=20).std()
            df['BB_Upper'] = df['SMA_20'] + (std * 2)
            df['BB_Lower'] = df['SMA_20'] - (std * 2)
            df['BB_Width'] = ((df['BB_Upper'] - df['BB_Lower']) / df['SMA_20']) * 100
            df['BB_Position'] = (df['Close'] - df['BB_Lower']) / (df['BB_Upper'] - df['BB_Lower'])

            # ATR
            high_low = df['High'] - df['Low']
            high_close = np.abs(df['High'] - df['Close'].shift())
            low_close = np.abs(df['Low'] - df['Close'].shift())
            true_range = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)
            df['ATR'] = true_range.rolling(14).mean()
            df['ATR_Percent'] = (df['ATR'] / df['Close']) * 100

            # Volume Analysis
            df['Volume_SMA'] = df['Volume'].rolling(20).mean()
            df['Volume_Ratio'] = df['Volume'] / df['Volume_SMA']
            df['OBV'] = (df['Volume'] * (~df['Close'].diff().le(0) * 2 - 1)).cumsum()
            df['Volume_Price_Trend'] = ((df['Close'] - df['Close'].shift(1)) / df['Close'].shift(1) * df['Volume']).cumsum()

            # Ù…Ø¤Ø´Ø±Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©
            df['ROC'] = ((df['Close'] - df['Close'].shift(14)) / df['Close'].shift(14)) * 100
            df['Williams_R'] = ((df['High'].rolling(14).max() - df['Close']) / 
                                (df['High'].rolling(14).max() - df['Low'].rolling(14).min())) * -100

            # Stochastic
            low_14 = df['Low'].rolling(14).min()
            high_14 = df['High'].rolling(14).max()
            df['Stoch_K'] = 100 * ((df['Close'] - low_14) / (high_14 - low_14))
            df['Stoch_D'] = df['Stoch_K'].rolling(3).mean()

            # Ichimoku
            high_9 = df['High'].rolling(9).max()
            low_9 = df['Low'].rolling(9).min()
            df['Tenkan_sen'] = (high_9 + low_9) / 2

            high_26 = df['High'].rolling(26).max()
            low_26 = df['Low'].rolling(26).min()
            df['Kijun_sen'] = (high_26 + low_26) / 2

            df['Senkou_Span_A'] = ((df['Tenkan_sen'] + df['Kijun_sen']) / 2).shift(26)

            high_52 = df['High'].rolling(52).max()
            low_52 = df['Low'].rolling(52).min()
            df['Senkou_Span_B'] = ((high_52 + low_52) / 2).shift(26)

            return df.dropna()
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª: {e}")
            return gold_data

    def calculate_support_resistance(self, data, window=20):
        """Ø­Ø³Ø§Ø¨ Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ø¯Ø¹Ù… ÙˆØ§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø©"""
        try:
            recent_data = data.tail(window * 3)

            highs = recent_data['High'].rolling(5, center=True).max() == recent_data['High']
            lows = recent_data['Low'].rolling(5, center=True).min() == recent_data['Low']

            resistance_levels = recent_data.loc[highs, 'High'].nlargest(3).tolist()
            support_levels = recent_data.loc[lows, 'Low'].nsmallest(3).tolist()

            current_price = data['Close'].iloc[-1]

            nearest_resistance = min([r for r in resistance_levels if r > current_price], default=None)
            nearest_support = max([s for s in support_levels if s < current_price], default=None)

            return {
                'resistance_levels': [round(r, 2) for r in resistance_levels],
                'support_levels': [round(s, 2) for s in support_levels],
                'nearest_resistance': round(nearest_resistance, 2) if nearest_resistance else None,
                'nearest_support': round(nearest_support, 2) if nearest_support else None,
                'price_to_resistance': round(((nearest_resistance - current_price) / current_price * 100), 2) if nearest_resistance else None,
                'price_to_support': round(((current_price - nearest_support) / current_price * 100), 2) if nearest_support else None
            }
        except Exception as e:
            print(f"Ø®Ø·Ø£ ÙÙŠ Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¯Ø¹Ù… ÙˆØ§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø©: {e}")
            return {}

    def calculate_fibonacci_levels(self, data, periods=50):
        """Ø­Ø³Ø§Ø¨ Ù…Ø³ØªÙˆÙŠØ§Øª ÙÙŠØ¨ÙˆÙ†Ø§ØªØ´ÙŠ"""
        try:
            recent_data = data.tail(periods)
            high, low = recent_data['High'].max(), recent_data['Low'].min()
            diff = high - low
            current_price = data['Close'].iloc[-1]

            fib_levels = {
                'high': round(high, 2),
                'low': round(low, 2),
                'fib_23_6': round(high - (diff * 0.236), 2),
                'fib_38_2': round(high - (diff * 0.382), 2),
                'fib_50_0': round(high - (diff * 0.500), 2),
                'fib_61_8': round(high - (diff * 0.618), 2),
                'fib_78_6': round(high - (diff * 0.786), 2)
            }

            if current_price > fib_levels['fib_23_6']:
                fib_analysis = "Ø§Ù„Ø³Ø¹Ø± Ù‚ÙˆÙŠ Ø¬Ø¯Ø§Ù‹ ÙÙˆÙ‚ 23.6% - Ø§ØªØ¬Ø§Ù‡ ØµØ§Ø¹Ø¯ Ù‚ÙˆÙŠ"
            elif current_price > fib_levels['fib_38_2']:
                fib_analysis = "Ø§Ù„Ø³Ø¹Ø± ÙÙˆÙ‚ 38.2% - Ø§ØªØ¬Ø§Ù‡ ØµØ§Ø¹Ø¯ Ù…Ø¹ØªØ¯Ù„"
            elif current_price > fib_levels['fib_50_0']:
                fib_analysis = "Ø§Ù„Ø³Ø¹Ø± ÙÙˆÙ‚ 50% - Ù…Ù†Ø·Ù‚Ø© Ù…Ø­Ø§ÙŠØ¯Ø©"
            elif current_price > fib_levels['fib_61_8']:
                fib_analysis = "Ø§Ù„Ø³Ø¹Ø± ÙÙˆÙ‚ 61.8% - Ø¶Ø¹Ù Ù†Ø³Ø¨ÙŠ"
            else:
                fib_analysis = "Ø§Ù„Ø³Ø¹Ø± ØªØ­Øª 61.8% - Ø§ØªØ¬Ø§Ù‡ Ù‡Ø§Ø¨Ø· Ù…Ø­ØªÙ…Ù„"

            fib_levels['analysis'] = fib_analysis
            fib_levels['current_position'] = round(((current_price - low) / diff * 100), 2)

            return fib_levels
        except Exception as e:
            print(f"Ø®Ø·Ø£ ÙÙŠ Ø­Ø³Ø§Ø¨ ÙÙŠØ¨ÙˆÙ†Ø§ØªØ´ÙŠ: {e}")
            return {}

    def fetch_economic_data(self):
        """Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ÙŠØ© Ø§Ù„Ù…Ø¤Ø«Ø±Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø°Ù‡Ø¨"""
        economic_data = {
            'status': 'simulated',
            'last_update': datetime.now().isoformat(),
            'indicators': {}
        }

        try:
            economic_data['indicators'] = {
                'US_CPI': {
                    'value': 3.2,
                    'previous': 3.4,
                    'impact': 'Ø¥ÙŠØ¬Ø§Ø¨ÙŠ Ù„Ù„Ø°Ù‡Ø¨ - ØªØ¶Ø®Ù… Ù…Ù†Ø®ÙØ¶',
                    'next_release': '2025-02-12'
                },
                'US_Interest_Rate': {
                    'value': 4.5,
                    'previous': 4.75,
                    'impact': 'Ø¥ÙŠØ¬Ø§Ø¨ÙŠ Ù„Ù„Ø°Ù‡Ø¨ - Ø®ÙØ¶ Ø§Ù„ÙØ§Ø¦Ø¯Ø©',
                    'next_release': '2025-01-29 FOMC'
                },
                'US_NFP': {
                    'value': 256000,
                    'previous': 227000,
                    'impact': 'Ø³Ù„Ø¨ÙŠ Ù„Ù„Ø°Ù‡Ø¨ - Ø³ÙˆÙ‚ Ø¹Ù…Ù„ Ù‚ÙˆÙŠ',
                    'next_release': '2025-02-07'
                },
                'DXY_Index': {
                    'value': 108.5,
                    'trend': 'Ù‡Ø§Ø¨Ø·',
                    'impact': 'Ø¥ÙŠØ¬Ø§Ø¨ÙŠ Ù„Ù„Ø°Ù‡Ø¨ - Ø¶Ø¹Ù Ø§Ù„Ø¯ÙˆÙ„Ø§Ø±'
                },
                'Geopolitical_Risk': {
                    'level': 'Ù…ØªÙˆØ³Ø·',
                    'events': ['ØªÙˆØªØ±Ø§Øª ØªØ¬Ø§Ø±ÙŠØ©', 'Ù‚Ù„Ù‚ Ù…Ù† Ø§Ù„ØªØ¶Ø®Ù…'],
                    'impact': 'Ù…Ø­Ø§ÙŠØ¯ Ø¥Ù„Ù‰ Ø¥ÙŠØ¬Ø§Ø¨ÙŠ Ù„Ù„Ø°Ù‡Ø¨'
                }
            }

            positive_factors = sum(1 for ind in economic_data['indicators'].values() 
                                 if 'Ø¥ÙŠØ¬Ø§Ø¨ÙŠ' in str(ind.get('impact', '')))
            negative_factors = sum(1 for ind in economic_data['indicators'].values() 
                                 if 'Ø³Ù„Ø¨ÙŠ' in str(ind.get('impact', '')))

            if positive_factors > negative_factors:
                economic_data['overall_impact'] = 'Ø¥ÙŠØ¬Ø§Ø¨ÙŠ Ù„Ù„Ø°Ù‡Ø¨'
                economic_data['score'] = positive_factors - negative_factors
            elif negative_factors > positive_factors:
                economic_data['overall_impact'] = 'Ø³Ù„Ø¨ÙŠ Ù„Ù„Ø°Ù‡Ø¨'
                economic_data['score'] = positive_factors - negative_factors
            else:
                economic_data['overall_impact'] = 'Ù…Ø­Ø§ÙŠØ¯'
                economic_data['score'] = 0

        except Exception as e:
            print(f"Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ÙŠØ©: {e}")
            economic_data['error'] = str(e)

        return economic_data

    def analyze_volume_profile(self, data):
        """ØªØ­Ù„ÙŠÙ„ Ù…Ø­Ø³Ù‘Ù† Ù„Ø­Ø¬Ù… Ø§Ù„ØªØ¯Ø§ÙˆÙ„"""
        try:
            latest = data.iloc[-1]
            prev_5 = data.tail(5)
            prev_20 = data.tail(20)

            current_volume = int(latest.get('Volume', 0))
            avg_volume_5 = int(prev_5['Volume'].mean())
            avg_volume_20 = int(prev_20['Volume'].mean())
            volume_ratio = latest.get('Volume_Ratio', 1)

            if volume_ratio > 2.0:
                volume_strength = 'Ù‚ÙˆÙŠ Ø¬Ø¯Ø§Ù‹'
                volume_signal = 'Ø­Ø¬Ù… Ø§Ø³ØªØ«Ù†Ø§Ø¦ÙŠ - Ø§Ø­ØªÙ…Ø§Ù„ Ø­Ø±ÙƒØ© Ù‚ÙˆÙŠØ©'
            elif volume_ratio > 1.5:
                volume_strength = 'Ù‚ÙˆÙŠ'
                volume_signal = 'Ø­Ø¬Ù… ÙÙˆÙ‚ Ø§Ù„Ù…ØªÙˆØ³Ø· - Ø§Ù‡ØªÙ…Ø§Ù… Ù…ØªØ²Ø§ÙŠØ¯'
            elif volume_ratio > 0.8:
                volume_strength = 'Ø·Ø¨ÙŠØ¹ÙŠ'
                volume_signal = 'Ø­Ø¬Ù… Ø·Ø¨ÙŠØ¹ÙŠ - Ù„Ø§ Ø¥Ø´Ø§Ø±Ø§Øª Ø®Ø§ØµØ©'
            else:
                volume_strength = 'Ø¶Ø¹ÙŠÙ'
                volume_signal = 'Ø­Ø¬Ù… Ø¶Ø¹ÙŠÙ - Ø­Ø°Ø± Ù…Ù† Ø§Ù„Ø­Ø±ÙƒØ© Ø§Ù„ÙˆÙ‡Ù…ÙŠØ©'

            obv_trend = 'ØµØ§Ø¹Ø¯' if data['OBV'].iloc[-1] > data['OBV'].iloc[-5] else 'Ù‡Ø§Ø¨Ø·'

            return {
                'current_volume': current_volume,
                'avg_volume_5': avg_volume_5,
                'avg_volume_20': avg_volume_20,
                'volume_ratio': round(volume_ratio, 2),
                'volume_strength': volume_strength,
                'volume_signal': volume_signal,
                'obv_trend': obv_trend,
                'volume_price_correlation': 'Ø¥ÙŠØ¬Ø§Ø¨ÙŠ' if (latest['Close'] > data['Close'].iloc[-2] and current_volume > avg_volume_20) else 'Ø³Ù„Ø¨ÙŠ'
            }
        except Exception as e:
            print(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø­Ø¬Ù…: {e}")
            return {}

    def analyze_correlations(self, market_data):
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø·Ø§Øª Ù…Ø¹ ØªÙØ³ÙŠØ± Ù…Ø­Ø³Ù‘Ù†"""
        try:
            print("ğŸ“Š ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø·Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…...")
            daily_data = market_data['daily']
            correlations = {}
            strength = {}
            interpretation = {}

            if hasattr(daily_data.columns, 'levels'):
                available_symbols = daily_data.columns.get_level_values(0).unique()
                gold_symbol = self.symbols['gold'] if self.symbols['gold'] in available_symbols else self.symbols['gold_etf']

                if gold_symbol in available_symbols:
                    gold_prices = daily_data[gold_symbol]['Close'].dropna()

                    for name, symbol in self.symbols.items():
                        if name not in ['gold', 'gold_etf'] and symbol in available_symbols:
                            if not daily_data[symbol].empty:
                                asset_prices = daily_data[symbol]['Close'].dropna()
                                common_index = gold_prices.index.intersection(asset_prices.index)

                                if len(common_index) > 30:
                                    corr = gold_prices.loc[common_index].corr(asset_prices.loc[common_index])

                                    if pd.notna(corr):
                                        correlations[name] = round(corr, 3)

                                        if abs(corr) > 0.7:
                                            strength[name] = 'Ù‚ÙˆÙŠ Ø¬Ø¯Ø§Ù‹'
                                        elif abs(corr) > 0.5:
                                            strength[name] = 'Ù‚ÙˆÙŠ'
                                        elif abs(corr) > 0.3:
                                            strength[name] = 'Ù…ØªÙˆØ³Ø·'
                                        else:
                                            strength[name] = 'Ø¶Ø¹ÙŠÙ'

                                        if name == 'dxy':
                                            if corr < -0.5:
                                                                                                interpretation[name] = 'Ø§Ø±ØªØ¨Ø§Ø· Ø¹ÙƒØ³ÙŠ Ù‚ÙˆÙŠ - Ø¥ÙŠØ¬Ø§Ø¨ÙŠ Ù„Ù„Ø°Ù‡Ø¨ Ø¹Ù†Ø¯ Ø¶Ø¹Ù Ø§Ù„Ø¯ÙˆÙ„Ø§Ø±'
                                            elif corr < -0.3:
                                                interpretation[name] = 'Ø§Ø±ØªØ¨Ø§Ø· Ø¹ÙƒØ³ÙŠ Ù…Ø¹ØªØ¯Ù„ - ÙØ±ØµØ© Ù…Ø­ØªÙ…Ù„Ø©'
                                            else:
                                                interpretation[name] = 'Ø§Ø±ØªØ¨Ø§Ø· Ø¶Ø¹ÙŠÙ - ØªØ£Ø«ÙŠØ± Ù…Ø­Ø¯ÙˆØ¯'

                                        elif name == 'vix':
                                            if corr > 0.3:
                                                interpretation[name] = 'Ø§Ù„Ø°Ù‡Ø¨ ÙŠØ³ØªÙÙŠØ¯ Ù…Ù† Ø²ÙŠØ§Ø¯Ø© Ø§Ù„ØªÙ‚Ù„Ø¨Ø§Øª'
                                            else:
                                                interpretation[name] = 'ØªØ£Ø«ÙŠØ± Ù…Ø­Ø¯ÙˆØ¯ Ù…Ù† Ø§Ù„ØªÙ‚Ù„Ø¨Ø§Øª'

                                        elif name == 'oil':
                                            if abs(corr) > 0.5:
                                                interpretation[name] = 'Ø§Ø±ØªØ¨Ø§Ø· Ù‚ÙˆÙŠ - Ù…Ø¤Ø´Ø± Ø¹Ù„Ù‰ Ø§Ù„ØªØ¶Ø®Ù…'
                                            else:
                                                interpretation[name] = 'Ø§Ø±ØªØ¨Ø§Ø· Ø¶Ø¹ÙŠÙ'

            return {
                'correlations': correlations,
                'strength_analysis': strength,
                'interpretation': interpretation
            }
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø·Ø§Øª: {e}")
            return {}

    async def fetch_news_enhanced(self):
        """Ø¬Ù„Ø¨ ÙˆØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø¨Ø´ÙƒÙ„ Ù…ØªÙ‚Ø¯Ù…"""
        print("ğŸ“° Ø¬Ù„Ø¨ ÙˆØªØ­Ù„ÙŠÙ„ Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ø°Ù‡Ø¨ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…...")

        if not self.news_api_key:
            return {"status": "no_api_key", "message": "ÙŠØªØ·Ù„Ø¨ Ù…ÙØªØ§Ø­ API Ù„Ù„Ø£Ø®Ø¨Ø§Ø±"}

        try:
            articles = await self.news_analyzer.fetch_news_async()
            events_analysis = self.news_analyzer.extract_events(articles)

            return {
                "status": "success",
                "events_analysis": events_analysis,
                "articles_count": len(articles)
            }

        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ø§Ù„Ø£Ø®Ø¨Ø§Ø±: {e}")
            return {"status": "error", "message": str(e)}

    def generate_professional_signals_v3(self, tech_data, correlations, volume, fib_levels, 
                                       support_resistance, economic_data, news_analysis, 
                                       mtf_analysis, ml_prediction):
        """ØªÙˆÙ„ÙŠØ¯ Ø¥Ø´Ø§Ø±Ø§Øª Ø§Ø­ØªØ±Ø§ÙÙŠØ© Ù…Ø­Ø³Ù‘Ù†Ø© V3"""
        print("ğŸ¯ ØªÙˆÙ„ÙŠØ¯ Ø¥Ø´Ø§Ø±Ø§Øª Ø§Ø­ØªØ±Ø§ÙÙŠØ© Ù…ØªÙ‚Ø¯Ù…Ø© V3...")

        try:
            latest = tech_data.iloc[-1]
            prev = tech_data.iloc[-2]

            scores = {
                'trend': 0, 'momentum': 0, 'volume': 0, 'fibonacci': 0,
                'correlation': 0, 'support_resistance': 0, 'economic': 0,
                'news': 0, 'ma_cross': 0, 'mtf_coherence': 0
            }

            # 1. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§ØªØ¬Ø§Ù‡
            if latest['Close'] > latest['SMA_200']:
                scores['trend'] += 2
                if latest['Close'] > latest['SMA_50']:
                    scores['trend'] += 1
                    if latest['Close'] > latest['SMA_20']:
                        scores['trend'] += 1
            else:
                scores['trend'] -= 2
                if latest['Close'] < latest['SMA_50']:
                    scores['trend'] -= 1
                    if latest['Close'] < latest['SMA_20']:
                        scores['trend'] -= 1

            if latest.get('Golden_Cross', 0) == 1:
                scores['ma_cross'] = 3
            elif latest.get('Death_Cross', 0) == 1:
                scores['ma_cross'] = -3

            # 2. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø²Ø®Ù…
            if latest['MACD'] > latest['MACD_Signal']:
                scores['momentum'] += 1
                if latest['MACD_Histogram'] > prev['MACD_Histogram']:
                    scores['momentum'] += 1
            else:
                scores['momentum'] -= 1
                if latest['MACD_Histogram'] < prev['MACD_Histogram']:
                    scores['momentum'] -= 1

            if 30 <= latest['RSI'] <= 70:
                if 45 <= latest['RSI'] <= 55:
                    scores['momentum'] += 0.5
                elif latest['RSI'] > 55:
                    scores['momentum'] += 1
                else:
                    scores['momentum'] -= 0.5
            elif latest['RSI'] < 30:
                scores['momentum'] += 2
            elif latest['RSI'] > 70:
                scores['momentum'] -= 2

            if latest.get('Stoch_K', 50) > latest.get('Stoch_D', 50):
                scores['momentum'] += 0.5

            # 3. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø­Ø¬Ù…
            if volume.get('volume_strength') == 'Ù‚ÙˆÙŠ Ø¬Ø¯Ø§Ù‹':
                scores['volume'] = 3
            elif volume.get('volume_strength') == 'Ù‚ÙˆÙŠ':
                scores['volume'] = 2
            elif volume.get('volume_strength') == 'Ø·Ø¨ÙŠØ¹ÙŠ':
                scores['volume'] = 0
            else:
                scores['volume'] = -1

            if volume.get('obv_trend') == 'ØµØ§Ø¹Ø¯':
                scores['volume'] += 1

            # 4. ØªØ­Ù„ÙŠÙ„ ÙÙŠØ¨ÙˆÙ†Ø§ØªØ´ÙŠ
            if fib_levels:
                current_price = latest['Close']
                if current_price > fib_levels.get('fib_38_2', 0):
                    scores['fibonacci'] = 2
                elif current_price > fib_levels.get('fib_50_0', 0):
                    scores['fibonacci'] = 1
                elif current_price > fib_levels.get('fib_61_8', 0):
                    scores['fibonacci'] = -1
                else:
                    scores['fibonacci'] = -2

            # 5. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¯Ø¹Ù… ÙˆØ§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø©
            if support_resistance:
                if support_resistance.get('price_to_support') and support_resistance['price_to_support'] < 2:
                    scores['support_resistance'] = 2
                elif support_resistance.get('price_to_resistance') and support_resistance['price_to_resistance'] < 2:
                    scores['support_resistance'] = -2

            # 6. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø·Ø§Øª
            dxy_corr = correlations.get('correlations', {}).get('dxy', 0)
            if dxy_corr < -0.7:
                scores['correlation'] = 2
            elif dxy_corr < -0.5:
                scores['correlation'] = 1
            elif dxy_corr > 0.5:
                scores['correlation'] = -1

            # 7. Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ÙŠØ©
            if economic_data:
                econ_score = economic_data.get('score', 0)
                scores['economic'] = min(max(econ_score, -3), 3)

            # 8. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø®Ø¨Ø§Ø±
            if news_analysis and news_analysis.get('status') == 'success':
                events = news_analysis.get('events_analysis', {})
                total_impact = events.get('total_impact', 0)

                if total_impact > 5:
                    scores['news'] = 3
                elif total_impact > 2:
                    scores['news'] = 2
                elif total_impact < -5:
                    scores['news'] = -3
                elif total_impact < -2:
                    scores['news'] = -2
                else:
                    scores['news'] = 0

            # 9. ØªÙˆØ§ÙÙ‚ Ø§Ù„Ø£Ø·Ø± Ø§Ù„Ø²Ù…Ù†ÙŠØ©
            if mtf_analysis:
                coherence_score = mtf_analysis.get('coherence_score', 0)
                scores['mtf_coherence'] = coherence_score

            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
            weights = {
                'trend': 0.20, 'momentum': 0.15, 'volume': 0.10,
                'fibonacci': 0.08, 'correlation': 0.05, 'support_resistance': 0.08,
                'economic': 0.08, 'news': 0.06, 'ma_cross': 0.10,
                'mtf_coherence': 0.10
            }

            total_score = sum(scores[key] * weights.get(key, 0) for key in scores)

            # Ø¯Ù…Ø¬ Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ
            confidence_boost = 1.0
            ml_interpretation = ""

            if ml_prediction and ml_prediction[0] is not None:
                ml_probability = ml_prediction[0]
                ml_interpretation = ml_prediction[1]

                if ml_probability > 0.75:
                    confidence_boost = 1.3
                elif ml_probability > 0.60:
                    confidence_boost = 1.15
                elif ml_probability < 0.40:
                    confidence_boost = 0.7
                elif ml_probability < 0.25:
                    confidence_boost = 0.5

                total_score *= confidence_boost

            # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø¥Ø´Ø§Ø±Ø© ÙˆØ§Ù„Ø«Ù‚Ø©
            if total_score >= 2.5:
                signal = "Strong Buy"
                confidence = "Very High"
                action = "Ø´Ø±Ø§Ø¡ Ù‚ÙˆÙŠ - Ø­Ø¬Ù… ÙƒØ¨ÙŠØ±"
            elif total_score >= 1.5:
                signal = "Buy"
                confidence = "High"
                action = "Ø´Ø±Ø§Ø¡ - Ø­Ø¬Ù… Ù…ØªÙˆØ³Ø·"
            elif total_score >= 0.5:
                signal = "Weak Buy"
                confidence = "Medium"
                action = "Ø´Ø±Ø§Ø¡ Ø­Ø°Ø± - Ø­Ø¬Ù… ØµØºÙŠØ±"
            elif total_score <= -2.5:
                signal = "Strong Sell"
                confidence = "Very High"
                action = "Ø¨ÙŠØ¹ Ù‚ÙˆÙŠ - Ø­Ø¬Ù… ÙƒØ¨ÙŠØ±"
            elif total_score <= -1.5:
                signal = "Sell"
                confidence = "High"
                action = "Ø¨ÙŠØ¹ - Ø­Ø¬Ù… Ù…ØªÙˆØ³Ø·"
            elif total_score <= -0.5:
                signal = "Weak Sell"
                confidence = "Medium"
                action = "Ø¨ÙŠØ¹ Ø­Ø°Ø± - Ø­Ø¬Ù… ØµØºÙŠØ±"
            else:
                signal = "Hold"
                confidence = "Low"
                action = "Ø§Ù†ØªØ¸Ø§Ø± - Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¥Ø´Ø§Ø±Ø© ÙˆØ§Ø¶Ø­Ø©"

            # Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ø®Ø§Ø·Ø±
            atr = latest.get('ATR', latest['Close'] * 0.02)
            price = latest['Close']
            volatility = latest.get('ATR_Percent', 2)

            sl_multiplier = 1.5 if volatility < 1.5 else (2.0 if volatility < 2.5 else 2.5)

            if ml_prediction and ml_prediction[0] is not None:
                if ml_prediction[0] < 0.4:
                    sl_multiplier *= 0.8

            risk_management = {
                'stop_loss_levels': {
                    'tight': round(price - (atr * sl_multiplier * 0.75), 2),
                    'conservative': round(price - (atr * sl_multiplier), 2),
                    'moderate': round(price - (atr * sl_multiplier * 1.5), 2),
                    'wide': round(price - (atr * sl_multiplier * 2), 2)
                },
                'profit_targets': {
                    'target_1': round(price + (atr * 1.5), 2),
                    'target_2': round(price + (atr * 3), 2),
                    'target_3': round(price + (atr * 5), 2),
                    'target_4': round(price + (atr * 8), 2)
                },
                'position_size_recommendation': self._calculate_position_size_v3(confidence, volatility, ml_prediction),
                'risk_reward_ratio': round(3 / sl_multiplier, 2),
                'max_risk_per_trade': '2%' if confidence in ['Very High', 'High'] else '1%',
                'volatility_adjusted': True,
                'ml_adjusted': ml_prediction is not None and ml_prediction[0] is not None
            }

            entry_strategy = self._generate_entry_strategy_v3(scores, latest, support_resistance, mtf_analysis)
            upcoming_events = self._analyze_upcoming_events(economic_data, news_analysis)

            return {
                'signal': signal,
                'confidence': confidence,
                'action_recommendation': action,
                'total_score': round(total_score, 2),
                'component_scores': scores,
                'current_price': round(price, 2),
                'risk_management': risk_management,
                'entry_strategy': entry_strategy,
                'ml_prediction': {
                    'probability': round(ml_prediction[0], 3) if ml_prediction and ml_prediction[0] is not None else None,
                    'interpretation': ml_interpretation
                },
                'mtf_summary': mtf_analysis.get('analysis', '') if mtf_analysis else '',
                'upcoming_events': upcoming_events,
                'technical_summary': {
                    'rsi': round(latest.get('RSI', 0), 1),
                    'macd': round(latest.get('MACD', 0), 2),
                    'williams_r': round(latest.get('Williams_R', 0), 1),
                    'stoch_k': round(latest.get('Stoch_K', 0), 1),
                    'bb_position': round(latest.get('BB_Position', 0.5), 2),
                    'volume_ratio': round(latest.get('Volume_Ratio', 1), 2)
                },
                'key_levels': {
                    'sma_20': round(latest.get('SMA_20', 0), 2),
                    'sma_50': round(latest.get('SMA_50', 0), 2),
                    'sma_200': round(latest.get('SMA_200', 0), 2),
                    'bb_upper': round(latest.get('BB_Upper', 0), 2),
                    'bb_lower': round(latest.get('BB_Lower', 0), 2)
                }
            }

        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª: {e}")
            return {"error": str(e)}

    def _calculate_position_size_v3(self, confidence, volatility, ml_prediction):
        """Ø­Ø³Ø§Ø¨ Ø­Ø¬Ù… Ø§Ù„Ù…Ø±ÙƒØ² Ø§Ù„Ù…Ø­Ø³Ù‘Ù†"""
        base_recommendation = ""

        if confidence == "Very High" and volatility < 2:
            base_recommendation = "ÙƒØ¨ÙŠØ± (75-100% Ù…Ù† Ø±Ø£Ø³ Ø§Ù„Ù…Ø§Ù„ Ø§Ù„Ù…Ø®ØµØµ)"
        elif confidence == "High" and volatility < 2.5:
            base_recommendation = "Ù…ØªÙˆØ³Ø·-ÙƒØ¨ÙŠØ± (50-75%)"
        elif confidence == "High" or (confidence == "Medium" and volatility < 2):
            base_recommendation = "Ù…ØªÙˆØ³Ø· (25-50%)"
        elif confidence == "Medium":
            base_recommendation = "ØµØºÙŠØ± (10-25%)"
                else:
            base_recommendation = "ØµØºÙŠØ± Ø¬Ø¯Ø§Ù‹ (5-10%) Ø£Ùˆ Ø¹Ø¯Ù… Ø§Ù„Ø¯Ø®ÙˆÙ„"

        if ml_prediction and ml_prediction[0] is not None:
            if ml_prediction[0] > 0.75:
                base_recommendation += " (ML ÙŠØ¤ÙƒØ¯ Ø¨Ù‚ÙˆØ©)"
            elif ml_prediction[0] < 0.4:
                base_recommendation += " (ML ÙŠØ­Ø°Ø± - Ù‚Ù„Ù„ Ø§Ù„Ø­Ø¬Ù…)"

        return base_recommendation

    def _generate_entry_strategy_v3(self, scores, latest_data, support_resistance, mtf_analysis):
        """ØªÙˆÙ„ÙŠØ¯ Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø¯Ø®ÙˆÙ„ Ù…Ø­Ø³Ù‘Ù†Ø©"""
        strategy = {
            'entry_type': '',
            'entry_zones': [],
            'conditions': [],
            'warnings': [],
            'mtf_confirmation': ''
        }

        if mtf_analysis:
            if mtf_analysis.get('coherence_score', 0) > 2:
                strategy['mtf_confirmation'] = 'âœ… ØªÙˆØ§ÙÙ‚ Ù‚ÙˆÙŠ Ø¹Ø¨Ø± Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø·Ø± Ø§Ù„Ø²Ù…Ù†ÙŠØ©'
                strategy['entry_type'] = 'Ø¯Ø®ÙˆÙ„ Ù…Ø¤ÙƒØ¯ - ØªÙˆØ§ÙÙ‚ Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ø£Ø·Ø±'
            elif mtf_analysis.get('coherence_score', 0) < -1:
                strategy['warnings'].append('âš ï¸ ØªØ¶Ø§Ø±Ø¨ Ø¨ÙŠÙ† Ø§Ù„Ø£Ø·Ø± Ø§Ù„Ø²Ù…Ù†ÙŠØ©')
                strategy['entry_type'] = 'Ø§Ù†ØªØ¸Ø§Ø± ØªÙˆØ¶ÙŠØ­ Ø§Ù„Ø§ØªØ¬Ø§Ù‡'
            else:
                strategy['mtf_confirmation'] = 'ØªÙˆØ§ÙÙ‚ Ø¬Ø²Ø¦ÙŠ - Ø­Ø°Ø± Ù…Ø·Ù„ÙˆØ¨'

        if scores['trend'] > 2 and scores['momentum'] > 1 and scores['mtf_coherence'] > 1:
            strategy['entry_type'] = 'Ø¯Ø®ÙˆÙ„ Ù‚ÙˆÙŠ - Ø§ØªØ¬Ø§Ù‡ ÙˆØ§Ø¶Ø­ Ù…Ø¹ ØªÙˆØ§ÙÙ‚'
            strategy['entry_zones'].append(f"Ø¯Ø®ÙˆÙ„ ÙÙˆØ±ÙŠ Ø¹Ù†Ø¯ {round(latest_data['Close'], 2)}")
        elif scores['support_resistance'] == 2:
            strategy['entry_type'] = 'Ø¯Ø®ÙˆÙ„ Ù…Ù† Ø§Ù„Ø¯Ø¹Ù…'
            if support_resistance.get('nearest_support'):
                strategy['entry_zones'].append(f"Ø§Ù†ØªØ¸Ø± Ø§Ø±ØªØ¯Ø§Ø¯ Ù…Ù† {support_resistance['nearest_support']}")
        elif scores['momentum'] < -1:
            strategy['warnings'].append('âš ï¸ Ø°Ø±ÙˆØ© Ø´Ø±Ø§Ø¡ - Ø§Ù†ØªØ¸Ø± ØªØµØ­ÙŠØ­')
            strategy['entry_type'] = 'Ø§Ù†ØªØ¸Ø§Ø± ØªØµØ­ÙŠØ­'
        else:
            strategy['entry_type'] = 'Ø¯Ø®ÙˆÙ„ ØªØ¯Ø±ÙŠØ¬ÙŠ'
            strategy['entry_zones'].append('Ù‚Ø³Ù‘Ù… Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø¹Ù„Ù‰ 2-3 Ù…Ø±Ø§Ø­Ù„')

        if latest_data.get('RSI', 50) > 70:
            strategy['conditions'].append('Ø§Ù†ØªØ¸Ø± RSI < 70')
        if latest_data.get('Volume_Ratio', 1) < 0.8:
            strategy['warnings'].append('âš ï¸ Ø­Ø¬Ù… Ø¶Ø¹ÙŠÙ - ØªØ£ÙƒÙŠØ¯ Ù…Ø·Ù„ÙˆØ¨')

        if latest_data.get('BB_Position', 0.5) < 0.2:
            strategy['entry_zones'].append(f"Ù‚Ø±Ø¨ Ø§Ù„Ø­Ø¯ Ø§Ù„Ø³ÙÙ„ÙŠ Ù„Ø¨ÙˆÙ„ÙŠÙ†Ø¬Ø± - ÙØ±ØµØ© Ø´Ø±Ø§Ø¡ Ø¹Ù†Ø¯ {round(latest_data.get('BB_Lower', 0), 2)}")
        elif latest_data.get('BB_Position', 0.5) > 0.8:
            strategy['warnings'].append('âš ï¸ Ù‚Ø±Ø¨ Ø§Ù„Ø­Ø¯ Ø§Ù„Ø¹Ù„ÙˆÙŠ Ù„Ø¨ÙˆÙ„ÙŠÙ†Ø¬Ø± - Ø§Ø­ØªÙ…Ø§Ù„ ØªØµØ­ÙŠØ­')

        return strategy

    def _analyze_upcoming_events(self, economic_data, news_analysis):
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø­Ø¯Ø§Ø« Ø§Ù„Ù‚Ø§Ø¯Ù…Ø© Ø§Ù„Ù…Ø¤Ø«Ø±Ø©"""
        events = []

        if economic_data and 'indicators' in economic_data:
            for indicator, data in economic_data['indicators'].items():
                if 'next_release' in data:
                    events.append({
                        'type': 'economic',
                        'name': indicator,
                        'date': data['next_release'],
                        'expected_impact': data.get('impact', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')
                    })

        if news_analysis and news_analysis.get('status') == 'success':
            events_data = news_analysis.get('events_analysis', {})
            if 'dominant_theme' in events_data:
                events.append({
                    'type': 'news_theme',
                    'name': events_data['dominant_theme'],
                    'impact': 'Ù…Ø³ØªÙ…Ø±',
                    'recommendation': events_data.get('recommendation', '')
                })

        return events

    def generate_signal_for_backtest(self, data):
        """ØªÙˆÙ„ÙŠØ¯ Ø¥Ø´Ø§Ø±Ø© Ù…Ø¨Ø³Ø·Ø© Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø®Ù„ÙÙŠ"""
        score = 0

        if 'close' in data and 'open' in data:
            if data['close'] > data['open']:
                score += 1
            else:
                score -= 1

        if score > 0:
            return {'action': 'Buy', 'confidence': 'Medium'}
        elif score < 0:
            return {'action': 'Sell', 'confidence': 'Medium'}
        else:
            return {'action': 'Hold', 'confidence': 'Low'}

    def generate_report_v3(self, analysis_result):
        """ØªÙˆÙ„ÙŠØ¯ ØªÙ‚Ø±ÙŠØ± Ù†ØµÙŠ Ø´Ø§Ù…Ù„"""
        try:
            report = []
            report.append("=" * 80)
            report.append("ğŸ“Š ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠ Ù„Ù„Ø°Ù‡Ø¨ - Ø§Ù„Ø¥ØµØ¯Ø§Ø± 3.0")
            report.append("=" * 80)
            report.append(f"Ø§Ù„ØªØ§Ø±ÙŠØ®: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            report.append("")

            if 'gold_analysis' in analysis_result:
                ga = analysis_result['gold_analysis']
                report.append("ğŸ¯ Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©:")
                report.append(f"  â€¢ Ø§Ù„Ø¥Ø´Ø§Ø±Ø©: {ga.get('signal', 'N/A')}")
                report.append(f"  â€¢ Ø§Ù„Ø«Ù‚Ø©: {ga.get('confidence', 'N/A')}")
                report.append(f"  â€¢ Ø§Ù„ØªÙˆØµÙŠØ©: {ga.get('action_recommendation', 'N/A')}")
                report.append(f"  â€¢ Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ø­Ø§Ù„ÙŠ: ${ga.get('current_price', 'N/A')}")
                report.append(f"  â€¢ Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ©: {ga.get('total_score', 'N/A')}")
                report.append("")

                if 'ml_prediction' in ga and ga['ml_prediction'].get('probability') is not None:
                    report.append("ğŸ¤– ØªÙ†Ø¨Ø¤ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ:")
                    report.append(f"  â€¢ Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ© Ø§Ù„Ù†Ø¬Ø§Ø­: {ga['ml_prediction']['probability']:.1%}")
                    report.append(f"  â€¢ Ø§Ù„ØªÙØ³ÙŠØ±: {ga['ml_prediction']['interpretation']}")
                    report.append("")

                if 'mtf_summary' in ga and ga['mtf_summary']:
                    report.append("â° ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø·Ø± Ø§Ù„Ø²Ù…Ù†ÙŠØ© Ø§Ù„Ù…ØªØ¹Ø¯Ø¯Ø©:")
                    report.append(f"  â€¢ {ga['mtf_summary']}")
                    report.append("")

                if 'component_scores' in ga:
                    report.append("ğŸ“ˆ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª:")
                    for component, score in ga['component_scores'].items():
                        report.append(f"  â€¢ {component}: {score}")
                    report.append("")

                if 'risk_management' in ga:
                    rm = ga['risk_management']
                    report.append("âš ï¸ Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ø®Ø§Ø·Ø±:")
                    report.append(f"  â€¢ ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø© Ø§Ù„Ù…Ø­Ø§ÙØ¸: ${rm['stop_loss_levels'].get('conservative', 'N/A')}")
                    report.append(f"  â€¢ Ø§Ù„Ù‡Ø¯Ù Ø§Ù„Ø£ÙˆÙ„: ${rm['profit_targets'].get('target_1', 'N/A')}")
                    report.append(f"  â€¢ Ø§Ù„Ù‡Ø¯Ù Ø§Ù„Ø«Ø§Ù†ÙŠ: ${rm['profit_targets'].get('target_2', 'N/A')}")
                    report.append(f"  â€¢ Ø­Ø¬Ù… Ø§Ù„Ù…Ø±ÙƒØ²: {rm.get('position_size_recommendation', 'N/A')}")
                    if rm.get('ml_adjusted'):
                        report.append("  â€¢ âœ… ØªÙ… ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ù…Ø®Ø§Ø·Ø± Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ")
                    report.append("")

                if 'entry_strategy' in ga:
                    es = ga['entry_strategy']
                    report.append("ğŸ“ Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„Ø¯Ø®ÙˆÙ„:")
                    report.append(f"  â€¢ Ø§Ù„Ù†ÙˆØ¹: {es.get('entry_type', 'N/A')}")
                    if es.get('mtf_confirmation'):
                        report.append(f"  â€¢ {es['mtf_confirmation']}")
                    for zone in es.get('entry_zones', []):
                        report.append(f"  â€¢ {zone}")
                    for warning in es.get('warnings', []):
                        report.append(f"  â€¢ {warning}")
                    report.append("")

                if 'upcoming_events' in ga and ga['upcoming_events']:
                    report.append("ğŸ“… Ø§Ù„Ø£Ø­Ø¯Ø§Ø« Ø§Ù„Ù‚Ø§Ø¯Ù…Ø© Ø§Ù„Ù…Ø¤Ø«Ø±Ø©:")
                    for event in ga['upcoming_events'][:5]:
                        report.append(f"  â€¢ {event.get('name', 'N/A')}: {event.get('date', 'N/A')} - {event.get('expected_impact', 'N/A')}")
                    report.append("")

            if 'mtf_analysis' in analysis_result and analysis_result['mtf_analysis']:
                mtf = analysis_result['mtf_analysis']
                report.append("â±ï¸ ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø£Ø·Ø± Ø§Ù„Ø²Ù…Ù†ÙŠØ©:")
                if 'timeframes' in mtf:
                    for tf_name, tf_data in mtf['timeframes'].items():
                        if tf_data:
                            report.append(f"  â€¢ {tf_name}: {tf_data.get('trend', 'N/A')} (Ù†Ù‚Ø§Ø·: {tf_data.get('score', 0):.1f})")
                report.append(f"  â€¢ Ù†Ù‚Ø§Ø· Ø§Ù„ØªÙˆØ§ÙÙ‚ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ©: {mtf.get('coherence_score', 0)}")
                report.append(f"  â€¢ Ø§Ù„ØªÙˆØµÙŠØ©: {mtf.get('recommendation', 'N/A')}")
                report.append("")

            if 'economic_data' in analysis_result:
                ed = analysis_result['economic_data']
                if ed.get('status') != 'error':
                    report.append("ğŸ’° Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ÙŠØ©:")
                    report.append(f"  â€¢ Ø§Ù„ØªØ£Ø«ÙŠØ± Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ: {ed.get('overall_impact', 'N/A')}")
                    if 'indicators' in ed:
                        for ind_name, ind_data in ed['indicators'].items():
                            if isinstance(ind_data, dict):
                                report.append(f"  â€¢ {ind_name}: {ind_data.get('value', 'N/A')} - {ind_data.get('impact', '')}")
                    report.append("")

            if 'news_analysis' in analysis_result:
                na = analysis_result['news_analysis']
                if na.get('status') == 'success' and 'events_analysis' in na:
                    ea = na['events_analysis']
                    report.append("ğŸ“° ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø­Ø¯Ø§Ø« Ø§Ù„Ø¥Ø®Ø¨Ø§Ø±ÙŠØ©:")
                    report.append(f"  â€¢ Ø§Ù„ØªØ£Ø«ÙŠØ± Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ: {ea.get('total_impact', 0):.1f}")
                    report.append(f"  â€¢ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ù…Ù‡ÙŠÙ…Ù†: {ea.get('dominant_theme', 'N/A')}")
                    report.append(f"  â€¢ Ø§Ù„ØªÙˆØµÙŠØ©: {ea.get('recommendation', 'N/A')}")
                    if 'event_summary' in ea:
                        report.append("  â€¢ Ù…Ù„Ø®Øµ Ø§Ù„Ø£Ø­Ø¯Ø§Ø«:")
                        for event_type, count in ea['event_summary'].items():
                            report.append(f"    - {event_type}: {count} Ø­Ø¯Ø«")
                    report.append("")

            if 'market_correlations' in analysis_result:
                mc = analysis_result['market_correlations']
                if 'correlations' in mc:
                    report.append("ğŸ”— Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø·Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©:")
                    for asset, corr in mc['correlations'].items():
                        interpretation = mc.get('interpretation', {}).get(asset, '')
                        report.append(f"  â€¢ {asset.upper()}: {corr} - {interpretation}")
                    report.append("")

            if 'backtest_results' in analysis_result:
                bt_results = analysis_result['backtest_results']
                if bt_results:
                    report.append("ğŸ”„ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø®Ù„ÙÙŠ:")
                    report.append(f"  â€¢ Ø§Ù„Ø¹Ø§Ø¦Ø¯ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ: {bt_results.get('total_return', 0):.2f}%")
                    report.append(f"  â€¢ Ù†Ø³Ø¨Ø© Ø´Ø§Ø±Ø¨: {bt_results.get('sharpe_ratio', 0):.3f}")
                    report.append(f"  â€¢ Ù…Ø¹Ø¯Ù„ Ø§Ù„ÙÙˆØ²: {bt_results.get('win_rate', 0):.1f}%")
                    report.append(f"  â€¢ Ø¹Ø§Ù…Ù„ Ø§Ù„Ø±Ø¨Ø­: {bt_results.get('profit_factor', 0):.2f}")
                    report.append("")

            if 'market_summary' in analysis_result:
                ms = analysis_result['market_summary']
                report.append("ğŸ“Š Ù…Ù„Ø®Øµ Ø­Ø§Ù„Ø© Ø§Ù„Ø³ÙˆÙ‚:")
                report.append(f"  â€¢ Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„Ø¹Ø§Ù…Ø©: {ms.get('market_condition', 'N/A')}")
                report.append(f"  â€¢ Ø¢Ø®Ø± ØªØ­Ø¯ÙŠØ«: {ms.get('last_update', 'N/A')}")
                report.append(f"  â€¢ Ù†Ù‚Ø§Ø· Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {ms.get('data_points', 0)}")
                report.append("")

            report.append("=" * 80)
            report.append("Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„ØªÙ‚Ø±ÙŠØ± - Ø§Ù„Ø¥ØµØ¯Ø§Ø± 3.0")
            report.append("ØªÙ… Ø¯Ù…Ø¬: Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ | ØªØ­Ù„ÙŠÙ„ Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ø£Ø·Ø± | ØªØ­Ù„ÙŠÙ„ Ø£Ø®Ø¨Ø§Ø± Ù…ØªÙ‚Ø¯Ù… | Ø§Ø®ØªØ¨Ø§Ø± Ø®Ù„ÙÙŠ Ø§Ø­ØªØ±Ø§ÙÙŠ")

            return "\n".join(report)

        except Exception as e:
            return f"Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙ‚Ø±ÙŠØ±: {e}"

    async def run_analysis_v3(self):
        """ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠ Ø§Ù„Ø´Ø§Ù…Ù„"""
        print("ğŸš€ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠ Ø§Ù„Ù…ØªÙ‚Ø¯Ù… Ù„Ù„Ø°Ù‡Ø¨ - Ø§Ù„Ø¥ØµØ¯Ø§Ø± 3.0...")
        print("=" * 80)

        try:
            market_data = self.fetch_multi_timeframe_data()
            if market_data is None:
                raise ValueError("ÙØ´Ù„ ÙÙŠ Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø³ÙˆÙ‚")

                        gold_data = self.extract_gold_data(market_data)
            if gold_data is None:
                raise ValueError("ÙØ´Ù„ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø°Ù‡Ø¨")

            technical_data = self.calculate_professional_indicators(gold_data)

            print("\nâ° ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø·Ø± Ø§Ù„Ø²Ù…Ù†ÙŠØ© Ø§Ù„Ù…ØªØ¹Ø¯Ø¯Ø©...")
            coherence_score, mtf_analysis = self.mtf_analyzer.get_coherence_score(self.symbols['gold'])

            fibonacci_levels = self.calculate_fibonacci_levels(technical_data)
            support_resistance = self.calculate_support_resistance(technical_data)
            volume_analysis = self.analyze_volume_profile(technical_data)
            correlations = self.analyze_correlations(market_data)
            economic_data = self.fetch_economic_data()
            news_data = await self.fetch_news_enhanced()

            print("\nğŸ¤– Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ...")
            self.db_manager.update_future_prices()
            training_data = self.db_manager.get_training_data()

            ml_prediction = None
            if training_data and len(training_data) >= 100:
                if not os.path.exists(self.ml_predictor.model_path):
                    print("  â€¢ ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Ø¬Ø¯ÙŠØ¯...")
                    self.ml_predictor.train_model(training_data)

                current_analysis = {
                    'gold_analysis': {
                        'component_scores': {},
                        'technical_summary': {}
                    },
                    'volume_analysis': volume_analysis,
                    'market_correlations': correlations,
                    'economic_data': economic_data
                }
                ml_prediction = self.ml_predictor.predict_probability(current_analysis)
            else:
                print("  â€¢ Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± ÙƒØ§ÙÙŠØ© Ù„Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ")

            signals = self.generate_professional_signals_v3(
                technical_data, correlations, volume_analysis, 
                fibonacci_levels, support_resistance, 
                economic_data, news_data, mtf_analysis, ml_prediction
            )

            backtest_results = None
            if len(technical_data) > 100:
                print("\nğŸ”„ ØªØ´ØºÙŠÙ„ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø®Ù„ÙÙŠ...")
                backtest_results = self.backtester.run_backtest(technical_data)

            final_result = {
                'timestamp': datetime.now().isoformat(),
                'status': 'success',
                'version': '3.0',
                'gold_analysis': signals,
                'mtf_analysis': mtf_analysis,
                'fibonacci_levels': fibonacci_levels,
                'support_resistance': support_resistance,
                'volume_analysis': volume_analysis,
                'market_correlations': correlations,
                'economic_data': economic_data,
                'news_analysis': news_data,
                'backtest_results': backtest_results,
                'market_summary': {
                    'last_update': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                    'data_points': len(technical_data),
                    'timeframe': 'Multi-timeframe',
                    'market_condition': self._determine_market_condition_v3(signals, volume_analysis, mtf_analysis)
                }
            }

            self.db_manager.save_analysis(final_result)
            self.save_results_v3(final_result)

            report = self.generate_report_v3(final_result)
            print(report)

            print("\nâœ… ØªÙ… Ø¥ØªÙ…Ø§Ù… Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠ V3.0 Ø¨Ù†Ø¬Ø§Ø­!")
            return final_result

        except Exception as e:
            error_message = f"âŒ ÙØ´Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠ: {e}"
            print(error_message)
            error_result = {
                'timestamp': datetime.now().isoformat(),
                'status': 'error',
                'version': '3.0',
                'error': str(e)
            }
            self.save_results_v3(error_result)
            return error_result

    def _determine_market_condition_v3(self, signals, volume, mtf_analysis):
        """ØªØ­Ø¯ÙŠØ¯ Ø­Ø§Ù„Ø© Ø§Ù„Ø³ÙˆÙ‚ Ø§Ù„Ø¹Ø§Ù…Ø©"""
        if not signals or 'error' in signals:
            return "ÙØ´Ù„ ØªØ­Ø¯ÙŠØ¯ Ø­Ø§Ù„Ø© Ø§Ù„Ø³ÙˆÙ‚ Ø¨Ø³Ø¨Ø¨ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„"

        conditions = []

        if signals.get('signal') in ['Strong Buy', 'Buy']:
            if volume.get('volume_strength') in ['Ù‚ÙˆÙŠ', 'Ù‚ÙˆÙŠ Ø¬Ø¯Ø§Ù‹']:
                conditions.append('ØµØ§Ø¹Ø¯ Ù‚ÙˆÙŠ')
            else:
                conditions.append('ØµØ§Ø¹Ø¯')
        elif signals.get('signal') in ['Strong Sell', 'Sell']:
            if volume.get('volume_strength') in ['Ù‚ÙˆÙŠ', 'Ù‚ÙˆÙŠ Ø¬Ø¯Ø§Ù‹']:
                conditions.append('Ù‡Ø§Ø¨Ø· Ù‚ÙˆÙŠ')
            else:
                conditions.append('Ù‡Ø§Ø¨Ø·')
        else:
            conditions.append('Ø¹Ø±Ø¶ÙŠ')

        if mtf_analysis and mtf_analysis.get('coherence_score', 0) > 2:
            conditions.append('ØªÙˆØ§ÙÙ‚ Ù‚ÙˆÙŠ')
        elif mtf_analysis and mtf_analysis.get('coherence_score', 0) < -2:
            conditions.append('ØªØ¶Ø§Ø±Ø¨ Ø´Ø¯ÙŠØ¯')

        if signals.get('ml_prediction', {}).get('probability'):
            ml_prob = signals['ml_prediction']['probability']
            if ml_prob > 0.7:
                conditions.append('ML Ø¥ÙŠØ¬Ø§Ø¨ÙŠ')
            elif ml_prob < 0.3:
                conditions.append('ML Ø³Ù„Ø¨ÙŠ')

        if 'ØµØ§Ø¹Ø¯ Ù‚ÙˆÙŠ' in conditions and 'ØªÙˆØ§ÙÙ‚ Ù‚ÙˆÙŠ' in conditions:
            return 'ØµØ§Ø¹Ø¯ Ù‚ÙˆÙŠ Ø¬Ø¯Ø§Ù‹ - ÙØ±ØµØ© Ù…Ù…ØªØ§Ø²Ø©'
        elif 'Ù‡Ø§Ø¨Ø· Ù‚ÙˆÙŠ' in conditions and 'ØªÙˆØ§ÙÙ‚ Ù‚ÙˆÙŠ' in conditions:
            return 'Ù‡Ø§Ø¨Ø· Ù‚ÙˆÙŠ Ø¬Ø¯Ø§Ù‹ - ØªØ¬Ù†Ø¨ Ø§Ù„Ø´Ø±Ø§Ø¡'
        elif 'ØªØ¶Ø§Ø±Ø¨ Ø´Ø¯ÙŠØ¯' in conditions:
            return 'Ù…ØªÙ‚Ù„Ø¨ - Ø¹Ø¯Ù… ÙˆØ¶ÙˆØ­'
        elif 'Ø¹Ø±Ø¶ÙŠ' in conditions:
            return 'Ø¹Ø±Ø¶ÙŠ/Ù…Ø­Ø§ÙŠØ¯ - Ø§Ù†ØªØ¸Ø§Ø±'
        else:
            return ' | '.join(conditions[:2])

    def save_results_v3(self, results):
        """Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ Ù…Ù„ÙØ§Øª"""
        try:
            filename = "gold_analysis_v3.json"
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2, default=str)
            print(f"ğŸ’¾ ØªÙ… Ø­ÙØ¸ Ø§Ù„ØªØ­Ù„ÙŠÙ„ ÙÙŠ: {filename}")

        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬: {e}")

def main():
    """Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…Ø­Ù„Ù„"""
    analyzer = ProfessionalGoldAnalyzerV3()
    asyncio.run(analyzer.run_analysis_v3())

if __name__ == "__main__":
    main()
        