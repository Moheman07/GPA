name: ğŸ† Advanced Gold Analysis (Original Enhanced)
on:
  schedule:
    - cron: '30 13 * * 1-5'  # ÙŠÙˆÙ…ÙŠ
  workflow_dispatch:

env:
  NEWS_API_KEY: ${{ secrets.NEWS_API_KEY }}

jobs:
  advanced-analysis:
    name: ğŸ§  Advanced Gold Analysis
    runs-on: ubuntu-latest
    timeout-minutes: 15
    permissions:
      contents: write
    
    steps:
    - uses: actions/checkout@v4
    - uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        
    - name: ğŸ“¦ Install Advanced Packages
      run: |
        echo "ğŸ”„ Installing advanced analysis packages..."
        pip install --upgrade pip --quiet
        
        # Core packages
        pip install --no-cache-dir --quiet \
          yfinance pandas numpy requests scipy
        
        # AI and NLP
        pip install --no-cache-dir --quiet \
          transformers torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
        
        pip install --no-cache-dir --quiet \
          vaderSentiment textblob nltk scikit-learn
        
        # Technical analysis
        pip install --no-cache-dir --quiet \
          pandas-ta matplotlib seaborn
        
        # Download models
        python -c "
        import nltk
        try:
            nltk.download('punkt', quiet=True)
            nltk.download('vader_lexicon', quiet=True)
            print('âœ… NLTK data downloaded')
        except:
            print('âš ï¸ NLTK download skipped')
        "
        
        echo "âœ… Advanced packages installed"

    - name: ğŸ§  Create Advanced Gold Analyzer (Original)
      run: |
        cat > main_analyzer.py << 'EOF'
        #!/usr/bin/env python3
        # -*- coding: utf-8 -*-
        """
        ğŸ† Ù…Ø­Ù„Ù„ Ø§Ù„Ø°Ù‡Ø¨ Ø§Ù„Ù…ØªÙ‚Ø¯Ù… - Ø§Ù„Ø¥ØµØ¯Ø§Ø± Ø§Ù„Ù…Ø­Ø³Ù†
        Advanced Gold Analysis System with AI
        """
        
        import yfinance as yf
        import pandas as pd
        import numpy as np
        import requests
        import json
        import sqlite3
        import os
        import logging
        import warnings
        from datetime import datetime, timedelta
        from typing import Dict, List, Optional, Any
        import time
        from concurrent.futures import ThreadPoolExecutor
        
        # AI and NLP imports
        try:
            from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification
            import torch
            from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
            from textblob import TextBlob
            AI_AVAILABLE = True
        except ImportError as e:
            print(f"âš ï¸ AI packages not available: {e}")
            AI_AVAILABLE = False
        
        # Technical analysis
        try:
            import pandas_ta as ta
            TA_AVAILABLE = True
        except ImportError:
            TA_AVAILABLE = False
        
        warnings.filterwarnings('ignore')
        
        # Ø¥Ø¹Ø¯Ø§Ø¯ Ù†Ø¸Ø§Ù… Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('gold_analysis.log', encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
        logger = logging.getLogger(__name__)
        
        class AdvancedGoldAnalyzer:
            """Ù…Ø­Ù„Ù„ Ø§Ù„Ø°Ù‡Ø¨ Ø§Ù„Ù…ØªÙ‚Ø¯Ù… Ù…Ø¹ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ"""
            
            def __init__(self):
                self.symbols = {
                    'gold_futures': 'GC=F',
                    'gold_etf': 'GLD', 
                    'silver': 'SLV',
                    'dollar_index': 'DX-Y.NYB',
                    'vix': '^VIX',
                    'treasury_10y': '^TNX',
                    'sp500': 'SPY',
                    'oil': 'CL=F',
                    'bitcoin': 'BTC-USD'
                }
                
                self.news_api_key = os.getenv('NEWS_API_KEY')
                self.db_path = 'gold_analysis_history.db'
                
                # AI Models
                self.sentiment_analyzer = None
                self.financial_sentiment_model = None
                
                # Data storage
                self.market_data = None
                self.gold_data = None
                
                logger.info("ğŸš€ ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ù…Ø­Ù„Ù„ Ø§Ù„Ø°Ù‡Ø¨ Ø§Ù„Ù…ØªÙ‚Ø¯Ù… Ø¨Ù†Ø¬Ø§Ø­")
        
            def setup_database(self):
                """Ø¥Ø¹Ø¯Ø§Ø¯ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©"""
                try:
                    conn = sqlite3.connect(self.db_path)
                    cursor = conn.cursor()
                    
                    # Ø¬Ø¯ÙˆÙ„ Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
                    cursor.execute('''
                        CREATE TABLE IF NOT EXISTS gold_analysis_history (
                            id INTEGER PRIMARY KEY AUTOINCREMENT,
                            timestamp TEXT NOT NULL,
                            signal TEXT NOT NULL,
                            signal_strength TEXT NOT NULL,
                            total_score REAL NOT NULL,
                            gold_price REAL,
                            technical_score REAL,
                            news_sentiment_score REAL,
                            market_condition TEXT,
                            stop_loss REAL,
                            take_profit REAL,
                            rsi REAL,
                            macd_signal TEXT,
                            bb_position REAL,
                            volume_trend TEXT,
                            news_articles_count INTEGER,
                            top_news TEXT,
                            execution_time_ms INTEGER,
                            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                        )
                    ''')
                    
                    # Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ù…ÙØµÙ„
                    cursor.execute('''
                        CREATE TABLE IF NOT EXISTS news_analysis_detail (
                            id INTEGER PRIMARY KEY AUTOINCREMENT,
                            analysis_id INTEGER,
                            headline TEXT,
                            source TEXT,
                            sentiment_score REAL,
                            ai_sentiment_score REAL,
                            relevance_score INTEGER,
                            published_at TEXT,
                            url TEXT,
                            FOREIGN KEY (analysis_id) REFERENCES gold_analysis_history (id)
                        )
                    ''')
                    
                    conn.commit()
                    conn.close()
                    logger.info("âœ… ØªÙ… Ø¥Ø¹Ø¯Ø§Ø¯ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ù†Ø¬Ø§Ø­")
                    
                except Exception as e:
                    logger.error(f"âŒ ÙØ´Ù„ Ø¥Ø¹Ø¯Ø§Ø¯ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {e}")
        
            def initialize_ai_models(self):
                """ØªØ­Ù…ÙŠÙ„ Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø§Ù„Ù…ØªØ®ØµØµØ©"""
                if not AI_AVAILABLE:
                    logger.warning("âš ï¸ Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ØºÙŠØ± Ù…ØªØ§Ø­Ø©")
                    return
                
                try:
                    logger.info("ğŸ§  ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ø§Ù„Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…ØªØ®ØµØµ...")
                    
                    # Ù†Ù…ÙˆØ°Ø¬ Ù…ØªØ®ØµØµ ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø§Ù„ÙŠ
                    model_name = "ProsusAI/finbert"
                    
                    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø®Ø·Ø§Ø¡
                    try:
                        self.financial_sentiment_model = pipeline(
                            "sentiment-analysis",
                            model=model_name,
                            tokenizer=model_name,
                            device=0 if torch.cuda.is_available() else -1,
                            return_all_scores=True
                        )
                    except Exception as e:
                        logger.warning(f"âš ï¸ ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ FinBERTØŒ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø¯ÙŠÙ„: {e}")
                        # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø¯ÙŠÙ„ Ø£Ø®Ù
                        self.financial_sentiment_model = pipeline(
                            "sentiment-analysis",
                            model="cardiffnlp/twitter-roberta-base-sentiment-latest",
                            device=-1,
                            return_all_scores=True
                        )
                    
                    # VADER Ù„Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³Ø±ÙŠØ¹
                    self.sentiment_analyzer = SentimentIntensityAnalyzer()
                    
                    logger.info("âœ… Ù†Ù…ÙˆØ°Ø¬ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ø¬Ø§Ù‡Ø²")
                    
                except Exception as e:
                    logger.error(f"âŒ ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ: {e}")
                    self.financial_sentiment_model = None
                    self.sentiment_analyzer = None
        
            def fetch_enhanced_market_data(self) -> bool:
                """Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø³ÙˆÙ‚ Ø§Ù„Ù…Ø­Ø³Ù†Ø©"""
                logger.info("ğŸ“Š Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø³ÙˆÙ‚ Ø§Ù„Ù…Ø­Ø³Ù†Ø©...")
                
                try:
                    # Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø­Ø³Ù†Ø© Ù„Ù„Ø£Ø®Ø·Ø§Ø¡
                    symbols_list = list(self.symbols.values())
                    
                    # Ù…Ø­Ø§ÙˆÙ„Ø© Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
                    try:
                        self.market_data = yf.download(
                            symbols_list,
                            period="2y",  # ÙØªØ±Ø© Ø£Ø·ÙˆÙ„ Ù„Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹Ù…ÙŠÙ‚
                            interval="1d",
                            progress=True,
                            threads=True
                        )
                    except Exception as e:
                        logger.warning(f"âš ï¸ ÙØ´Ù„ Ø§Ù„Ø¬Ù„Ø¨ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØŒ Ù…Ø­Ø§ÙˆÙ„Ø© Ø¨Ø¯ÙŠÙ„Ø©: {e}")
                        
                        # Ù…Ø­Ø§ÙˆÙ„Ø© Ø¨Ø¯ÙŠÙ„Ø© Ø¨ÙØªØ±Ø© Ø£Ù‚ØµØ±
                        self.market_data = yf.download(
                            ['GLD', 'SLV', 'DX-Y.NYB', '^VIX', 'SPY'],
                            period="1y",
                            interval="1d",
                            progress=True
                        )
                    
                    if self.market_data is None or self.market_data.empty:
                        raise Exception("ÙØ´Ù„ ÙÙŠ Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø³ÙˆÙ‚")
                    
                    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø°Ù‡Ø¨
                    gold_symbol = 'GC=F'  # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¹Ù‚ÙˆØ¯ Ø§Ù„Ø¢Ø¬Ù„Ø© Ø£ÙˆÙ„Ø§Ù‹
                    
                    if ('Close', gold_symbol) not in self.market_data.columns:
                        gold_symbol = 'GLD'  # Ø§Ù„ØªØ¨Ø¯ÙŠÙ„ Ø¥Ù„Ù‰ ETF
                    
                    if ('Close', gold_symbol) in self.market_data.columns:
                        self.gold_data = pd.DataFrame({
                            'Open': self.market_data[('Open', gold_symbol)],
                            'High': self.market_data[('High', gold_symbol)],
                            'Low': self.market_data[('Low', gold_symbol)],
                            'Close': self.market_data[('Close', gold_symbol)],
                            'Volume': self.market_data[('Volume', gold_symbol)]
                        }).dropna()
                    else:
                        # Ø¥Ø°Ø§ ÙØ´Ù„ ÙƒÙ„ Ø´ÙŠØ¡ØŒ Ø¬Ù„Ø¨ GLD Ù…Ù†ÙØ±Ø¯Ø§Ù‹
                        logger.warning("âš ï¸ Ù…Ø­Ø§ÙˆÙ„Ø© Ø¬Ù„Ø¨ GLD Ù…Ù†ÙØ±Ø¯Ø§Ù‹...")
                        gold_data_single = yf.download('GLD', period='1y', progress=False)
                        if not gold_data_single.empty:
                            self.gold_data = gold_data_single
                        else:
                            raise Exception("ÙØ´Ù„ ÙÙŠ Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø°Ù‡Ø¨")
                    
                    logger.info(f"âœ… ØªÙ… Ø¬Ù„Ø¨ {len(self.market_data)} ÙŠÙˆÙ… Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ù†Ø¬Ø§Ø­")
                    return True
                    
                except Exception as e:
                    logger.error(f"âŒ ÙØ´Ù„ Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø³ÙˆÙ‚: {e}")
                    return False
        
            def calculate_advanced_technical_indicators(self):
                """Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ÙÙ†ÙŠØ© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©"""
                logger.info("ğŸ“ˆ Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ÙÙ†ÙŠØ© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©...")
                
                if self.gold_data is None or self.gold_data.empty:
                    logger.error("âŒ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø°Ù‡Ø¨ Ù„Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙÙ†ÙŠ")
                    return None
                
                try:
                    df = self.gold_data.copy()
                    
                    # Ø§Ù„Ù…ØªÙˆØ³Ø·Ø§Øª Ø§Ù„Ù…ØªØ­Ø±ÙƒØ©
                    df['SMA_20'] = df['Close'].rolling(20, min_periods=1).mean()
                    df['SMA_50'] = df['Close'].rolling(50, min_periods=1).mean()
                    df['SMA_200'] = df['Close'].rolling(200, min_periods=1).mean()
                    df['EMA_12'] = df['Close'].ewm(span=12).mean()
                    df['EMA_26'] = df['Close'].ewm(span=26).mean()
                    
                    # Ù…Ø¤Ø´Ø± Ø§Ù„Ù‚ÙˆØ© Ø§Ù„Ù†Ø³Ø¨ÙŠØ© RSI
                    delta = df['Close'].diff()
                    gain = delta.where(delta > 0, 0).rolling(14, min_periods=1).mean()
                    loss = (-delta.where(delta < 0, 0)).rolling(14, min_periods=1).mean()
                    rs = gain / loss.replace(0, np.inf)
                    df['RSI'] = 100 - (100 / (1 + rs))
                    
                    # MACD
                    df['MACD'] = df['EMA_12'] - df['EMA_26']
                    df['MACD_Signal'] = df['MACD'].ewm(span=9).mean()
                    df['MACD_Histogram'] = df['MACD'] - df['MACD_Signal']
                    
                    # Bollinger Bands
                    df['BB_Middle'] = df['Close'].rolling(20, min_periods=1).mean()
                    df['BB_Std'] = df['Close'].rolling(20, min_periods=1).std()
                    df['BB_Upper'] = df['BB_Middle'] + (df['BB_Std'] * 2)
                    df['BB_Lower'] = df['BB_Middle'] - (df['BB_Std'] * 2)
                    df['BB_Position'] = (df['Close'] - df['BB_Lower']) / (df['BB_Upper'] - df['BB_Lower'])
                    
                    # Stochastic Oscillator
                    low_14 = df['Low'].rolling(14, min_periods=1).min()
                    high_14 = df['High'].rolling(14, min_periods=1).max()
                    df['Stoch_K'] = 100 * ((df['Close'] - low_14) / (high_14 - low_14))
                    df['Stoch_D'] = df['Stoch_K'].rolling(3, min_periods=1).mean()
                    
                    # Williams %R
                    df['Williams_R'] = -100 * (high_14 - df['Close']) / (high_14 - low_14)
                    
                    # Ù…Ø¤Ø´Ø± Ø§Ù„Ø­Ø¬Ù…
                    df['Volume_SMA'] = df['Volume'].rolling(20, min_periods=1).mean()
                    df['Volume_Ratio'] = df['Volume'] / df['Volume_SMA']
                    
                    # ATR Ù„Ù„ØªÙ‚Ù„Ø¨Ø§Øª
                    tr1 = df['High'] - df['Low']
                    tr2 = abs(df['High'] - df['Close'].shift(1))
                    tr3 = abs(df['Low'] - df['Close'].shift(1))
                    tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)
                    df['ATR'] = tr.rolling(14, min_periods=1).mean()
                    
                    # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
                    df = df.dropna()
                    
                    # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
                    self.gold_data = df
                    
                    logger.info(f"âœ… ØªÙ… Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ÙÙ†ÙŠØ© - Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù†Ø¸ÙŠÙØ©: {len(df)} ØµÙ")
                    return df
                    
                except Exception as e:
                    logger.error(f"âŒ ÙØ´Ù„ Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ÙÙ†ÙŠØ©: {e}")
                    return None
        
            def analyze_specialized_news(self) -> Dict[str, Any]:
                """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ù…ØªØ®ØµØµ Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ"""
                logger.info("ğŸ“° Ø¨Ø¯Ø¡ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ù…ØªØ®ØµØµ...")
                
                if not self.news_api_key:
                    return {
                        'status': 'no_api_key',
                        'sentiment_score': 0,
                        'articles_count': 0,
                        'top_articles': []
                    }
                
                try:
                    logger.info("ğŸ“° Ø¨Ø¯Ø¡ ØªØ­Ù„ÙŠÙ„ Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ø°Ù‡Ø¨ Ø§Ù„Ù…ØªØ®ØµØµ...")
                    
                    # Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª Ù…ØªØ®ØµØµØ© Ù„Ù„Ø°Ù‡Ø¨
                    specialized_queries = [
                        'gold OR XAU OR bullion OR "precious metals" OR "gold price"',
                        '"interest rates" OR "federal reserve" OR "monetary policy" OR "inflation"',
                        '"dollar index" OR DXY OR "monetary policy" OR "currency"',
                        'geopolitical OR "safe haven" OR crisis OR "market volatility"'
                    ]
                    
                    all_articles = []
                    
                    # Ø¬Ù„Ø¨ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø¨Ø´ÙƒÙ„ Ù…ØªÙˆØ§Ø²ÙŠ
                    for query in specialized_queries:
                        try:
                            url = f"https://newsapi.org/v2/everything?q={query}&language=en&sortBy=publishedAt&pageSize=50&from={(datetime.now() - timedelta(days=3)).date()}&apiKey={self.news_api_key}"
                            
                            response = requests.get(url, timeout=10)
                            if response.status_code == 200:
                                articles = response.json().get('articles', [])
                                all_articles.extend(articles)
                                logger.info(f"ğŸ“¥ Ø¬Ù„Ø¨ {len(articles)} Ù…Ù‚Ø§Ù„ Ù…Ù† Ø§Ø³ØªØ¹Ù„Ø§Ù…: {query[:50]}...")
                            
                        except Exception as e:
                            logger.warning(f"âš ï¸ ÙØ´Ù„ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…: {e}")
                            continue
                    
                    if not all_articles:
                        return {
                            'status': 'no_articles',
                            'sentiment_score': 0,
                            'articles_count': 0,
                            'top_articles': []
                        }
                    
                    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±
                    unique_articles = []
                    seen_urls = set()
                    
                    for article in all_articles:
                        url = article.get('url', '')
                        if url not in seen_urls and len(article.get('title', '')) > 10:
                            seen_urls.add(url)
                            unique_articles.append(article)
                    
                    logger.info(f"ğŸ” ØªÙ… Ø¬Ù„Ø¨ {len(unique_articles)} Ù…Ù‚Ø§Ù„Ø§Ù‹ ÙØ±ÙŠØ¯Ø§Ù‹")
                    
                    # ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙ„Ø© Ø¨Ø§Ù„Ø°Ù‡Ø¨
                    gold_keywords = [
                        'gold', 'xau', 'bullion', 'precious', 'fed', 'federal reserve',
                        'interest rate', 'inflation', 'dollar', 'dxy', 'monetary',
                        'geopolitical', 'safe haven', 'crisis', 'volatility'
                    ]
                    
                    relevant_articles = []
                    
                    for article in unique_articles:
                        title = article.get('title', '').lower()
                        description = article.get('description', '').lower() if article.get('description') else ''
                        content = f"{title} {description}"
                        
                        # Ø­Ø³Ø§Ø¨ Ù†Ù‚Ø§Ø· Ø§Ù„ØµÙ„Ø©
                        relevance_score = sum(1 for keyword in gold_keywords if keyword in content)
                        
                        if relevance_score >= 2:  # ÙŠØ¬Ø¨ Ø£Ù† ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ÙƒÙ„Ù…ØªÙŠÙ† Ù…ÙØªØ§Ø­ÙŠØªÙŠÙ† Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„
                            article['relevance_score'] = relevance_score
                            relevant_articles.append(article)
                    
                    logger.info(f"ğŸ¯ ØªÙ… Ø§Ø®ØªÙŠØ§Ø± {len(relevant_articles)} Ù…Ù‚Ø§Ù„Ø§Ù‹ Ø°Ø§ ØµÙ„Ø© Ø¹Ø§Ù„ÙŠØ© Ø¨Ø§Ù„Ø°Ù‡Ø¨")
                    
                    if not relevant_articles:
                        return {
                            'status': 'no_relevant_articles',
                            'sentiment_score': 0,
                            'articles_count': 0,
                            'top_articles': []
                        }
                    
                    # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ø§Ù„Ù…ØªÙ‚Ø¯Ù…
                    analyzed_articles = []
                    sentiment_scores = []
                    
                    for article in relevant_articles[:50]:  # ØªØ­Ù„ÙŠÙ„ Ø£ÙØ¶Ù„ 50 Ù…Ù‚Ø§Ù„
                        try:
                            title = article.get('title', '')
                            description = article.get('description', '') or ''
                            text = f"{title}. {description}"
                            
                            # ØªØ­Ù„ÙŠÙ„ VADER Ø§Ù„Ø³Ø±ÙŠØ¹
                            vader_score = 0
                            if self.sentiment_analyzer:
                                vader_result = self.sentiment_analyzer.polarity_scores(text)
                                vader_score = vader_result['compound']
                            
                            # ØªØ­Ù„ÙŠÙ„ AI Ø§Ù„Ù…ØªØ®ØµØµ
                            ai_score = 0
                            if self.financial_sentiment_model:
                                try:
                                    # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù†Øµ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø·ÙˆÙŠÙ„Ø§Ù‹
                                    text_truncated = text[:500]  # Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ù„Ù†Ù…ÙˆØ°Ø¬
                                    ai_result = self.financial_sentiment_model(text_truncated)
                                    
                                    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
                                    if isinstance(ai_result[0], list):
                                        # FinBERT format
                                        scores = {item['label']: item['score'] for item in ai_result[0]}
                                        ai_score = scores.get('positive', 0) - scores.get('negative', 0)
                                    else:
                                        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø¹Ø§Ø¯ÙŠ
                                        if ai_result[0]['label'] in ['POSITIVE', 'positive']:
                                            ai_score = ai_result[0]['score']
                                        elif ai_result[0]['label'] in ['NEGATIVE', 'negative']:
                                            ai_score = -ai_result[0]['score']
                                        else:
                                            ai_score = 0
                                            
                                except Exception as e:
                                    logger.warning(f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ AI: {e}")
                                    ai_score = vader_score  # Ø§Ø³ØªØ®Ø¯Ø§Ù… VADER ÙƒØ¨Ø¯ÙŠÙ„
                            
                            # Ø§Ù„Ø¬Ù…Ø¹ Ø¨ÙŠÙ† Ø§Ù„Ù†ØªØ§Ø¦Ø¬
                            combined_score = (vader_score * 0.4) + (ai_score * 0.6)
                            
                            # ÙˆØ²Ù† Ø­Ø³Ø¨ Ø§Ù„ØµÙ„Ø©
                            relevance_weight = min(article['relevance_score'] / 5, 1.0)
                            final_score = combined_score * relevance_weight
                            
                            analyzed_article = {
                                'title': title,
                                'source': article.get('source', {}).get('name', 'Unknown'),
                                'published_at': article.get('publishedAt', ''),
                                'url': article.get('url', ''),
                                'relevance_score': article['relevance_score'],
                                'vader_sentiment': round(vader_score, 3),
                                'ai_sentiment': round(ai_score, 3),
                                'combined_sentiment': round(combined_score, 3),
                                'final_sentiment': round(final_score, 3)
                            }
                            
                            analyzed_articles.append(analyzed_article)
                            sentiment_scores.append(final_score)
                            
                        except Exception as e:
                            logger.warning(f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù‚Ø§Ù„: {e}")
                            continue
                    
                    if not sentiment_scores:
                        return {
                            'status': 'analysis_failed',
                            'sentiment_score': 0,
                            'articles_count': 0,
                            'top_articles': []
                        }
                    
                    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
                    overall_sentiment = np.mean(sentiment_scores)
                    sentiment_std = np.std(sentiment_scores)
                    
                    # ØªØ±ØªÙŠØ¨ Ø§Ù„Ù…Ù‚Ø§Ù„Ø§Øª Ø­Ø³Ø¨ Ø§Ù„ØªØ£Ø«ÙŠØ±
                    analyzed_articles.sort(key=lambda x: (x['relevance_score'], abs(x['final_sentiment'])), reverse=True)
                    
                    logger.info(f"ğŸ“Š ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ù…ÙƒØªÙ…Ù„: Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© {overall_sentiment:.3f}")
                    
                    return {
                        'status': 'success',
                        'sentiment_score': round(overall_sentiment, 4),
                        'articles_count': len(analyzed_articles),
                        'positive_count': len([s for s in sentiment_scores if s > 0.1]),
                        'negative_count': len([s for s in sentiment_scores if s < -0.1]),
                        'neutral_count': len([s for s in sentiment_scores if abs(s) <= 0.1]),
                        'sentiment_std': round(sentiment_std, 4),
                        'top_articles': analyzed_articles[:15],
                        'confidence': min(1.0, len(analyzed_articles) / 20),
                        'summary': f"ØªÙ… ØªØ­Ù„ÙŠÙ„ {len(analyzed_articles)} Ù…Ù‚Ø§Ù„Ø§Ù‹ Ø°Ø§ ØµÙ„Ø© Ø¹Ø§Ù„ÙŠØ© Ø¨Ø§Ù„Ø°Ù‡Ø¨"
                    }
                    
                except Exception as e:
                    logger.error(f"âŒ ÙØ´Ù„ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø®Ø¨Ø§Ø±: {e}")
                    return {
                        'status': 'error',
                        'error': str(e),
                        'sentiment_score': 0,
                        'articles_count': 0,
                        'top_articles': []
                    }
        
            def generate_comprehensive_signal(self, technical_data, news_data) -> Dict[str, Any]:
                """ØªÙˆÙ„ÙŠØ¯ Ø¥Ø´Ø§Ø±Ø© Ø§Ù„ØªØ¯Ø§ÙˆÙ„ Ø§Ù„Ø´Ø§Ù…Ù„Ø©"""
                try:
                    if technical_data is None or technical_data.empty:
                        return {
                            'signal': 'Hold',
                            'strength': 'Neutral',
                            'total_score': 0,
                            'confidence': 0
                        }
                    
                    latest = technical_data.iloc[-1]
                    
                    # Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ÙÙ†ÙŠØ© (70%)
                    technical_score = 0
                    
                    # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§ØªØ¬Ø§Ù‡
                    current_price = latest['Close']
                    sma_20 = latest['SMA_20']
                    sma_50 = latest['SMA_50']
                    sma_200 = latest['SMA_200']
                    
                    if current_price > sma_200: technical_score += 3
                    if current_price > sma_50: technical_score += 2
                    if current_price > sma_20: technical_score += 1.5
                    if sma_20 > sma_50: technical_score += 1
                    if sma_50 > sma_200: technical_score += 0.5
                    
                    # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø²Ø®Ù…
                    rsi = latest['RSI']
                    macd = latest['MACD']
                    macd_signal = latest['MACD_Signal']
                    
                    if macd > macd_signal: technical_score += 2
                    if 30 <= rsi <= 70: technical_score += 1
                    elif rsi < 30: technical_score += 2  # ØªØ´Ø¨Ø¹ Ø¨ÙŠØ¹ - ÙØ±ØµØ© Ø´Ø±Ø§Ø¡
                    elif rsi > 70: technical_score -= 1  # ØªØ´Ø¨Ø¹ Ø´Ø±Ø§Ø¡
                    
                    # ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙ‚Ù„Ø¨Ø§Øª
                    bb_position = latest['BB_Position']
                    if bb_position < 0.2: technical_score += 1.5  # Ù‚Ø±Ø¨ Ø§Ù„Ø­Ø¯ Ø§Ù„Ø³ÙÙ„ÙŠ
                    elif bb_position > 0.8: technical_score -= 1  # Ù‚Ø±Ø¨ Ø§Ù„Ø­Ø¯ Ø§Ù„Ø¹Ù„ÙˆÙŠ
                    
                    # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø­Ø¬Ù…
                    volume_ratio = latest['Volume_Ratio']
                    if volume_ratio > 1.5: technical_score += 0.5  # Ø­Ø¬Ù… Ø¹Ø§Ù„ÙŠ ÙŠØ¤ÙƒØ¯ Ø§Ù„Ø­Ø±ÙƒØ©
                    
                    # ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„ÙÙ†ÙŠØ©
                    technical_score_normalized = max(-1, min(1, (technical_score - 5) / 5))
                    
                    # Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¥Ø®Ø¨Ø§Ø±ÙŠØ© (30%)
                    news_score_normalized = 0
                    if news_data.get('status') == 'success':
                        news_score = news_data.get('sentiment_score', 0)
                        news_confidence = news_data.get('confidence', 0)
                        news_score_normalized = news_score * news_confidence
                    
                    # Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ©
                    total_score = (technical_score_normalized * 0.7) + (news_score_normalized * 0.3)
                    
                    # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø¥Ø´Ø§Ø±Ø©
                    if total_score >= 0.7:
                        signal = 'Strong Buy'
                        strength = 'Very Strong'
                    elif total_score >= 0.4:
                        signal = 'Buy'
                        strength = 'Strong'
                    elif total_score >= 0.1:
                        signal = 'Weak Buy'
                        strength = 'Moderate'
                    elif total_score <= -0.7:
                        signal = 'Strong Sell'
                        strength = 'Very Strong'
                    elif total_score <= -0.4:
                        signal = 'Sell'
                        strength = 'Strong'
                    elif total_score <= -0.1:
                        signal = 'Weak Sell'
                        strength = 'Moderate'
                    else:
                        signal = 'Hold'
                        strength = 'Neutral'
                    
                    # Ø­Ø³Ø§Ø¨ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø©
                    confidence = min(1.0, abs(total_score) + 0.3)
                    
                    # Ù†Ù‚Ø§Ø· ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø© ÙˆØ§Ù„Ù‡Ø¯Ù
                    atr = latest['ATR']
                    
                    if 'Buy' in signal:
                        stop_loss = current_price - (2.5 * atr)
                        take_profit = current_price + (4 * atr)
                    elif 'Sell' in signal:
                        stop_loss = current_price + (2.5 * atr)
                        take_profit = current_price - (4 * atr)
                    else:
                        stop_loss = current_price - (1.5 * atr)
                        take_profit = current_price + (2 * atr)
                    
                    return {
                        'signal': signal,
                        'strength': strength,
                        'total_score': round(total_score, 3),
                        'technical_score': round(technical_score_normalized, 3),
                        'news_score': round(news_score_normalized, 3),
                        'confidence': round(confidence, 3),
                        'current_price': round(current_price, 2),
                        'stop_loss': round(stop_loss, 2),
                        'take_profit': round(take_profit, 2),
                        'rsi': round(rsi, 1),
                        'macd_signal': 'Bullish' if macd > macd_signal else 'Bearish',
                        'bb_position': round(bb_position, 3),
                        'volume_trend': 'High' if volume_ratio > 1.5 else 'Normal' if volume_ratio > 0.8 else 'Low',
                        'market_condition': self._assess_market_condition(technical_data)
                    }
                    
                except Exception as e:
                    logger.error(f"âŒ ÙØ´Ù„ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¥Ø´Ø§Ø±Ø©: {e}")
                    return {
                        'signal': 'Hold',
                        'strength': 'Neutral',
                        'total_score': 0,
                        'confidence': 0
                    }
        
            def _assess_market_condition(self, technical_data) -> str:
                """ØªÙ‚ÙŠÙŠÙ… Ø­Ø§Ù„Ø© Ø§Ù„Ø³ÙˆÙ‚ Ø§Ù„Ø¹Ø§Ù…Ø©"""
                try:
                    latest = technical_data.iloc[-1]
                    
                    # ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙ‚Ù„Ø¨Ø§Øª
                    atr = latest['ATR']
                    price = latest['Close']
                    volatility = atr / price
                    
                    # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§ØªØ¬Ø§Ù‡
                    sma_20 = latest['SMA_20']
                    sma_50 = latest['SMA_50']
                    
                    if volatility > 0.03:
                        condition = 'high_volatility'
                    elif volatility < 0.015:
                        condition = 'low_volatility'
                    elif price > sma_50 and sma_20 > sma_50:
                        condition = 'bullish_trend'
                    elif price < sma_50 and sma_20 < sma_50:
                        condition = 'bearish_trend'
                    else:
                        condition = 'sideways'
                    
                    return condition
                    
                except:
                    return 'normal'
        
            def save_analysis_results(self, signal_data, technical_data, news_data, execution_time) -> int:
                """Ø­ÙØ¸ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
                try:
                    conn = sqlite3.connect(self.db_path)
                    cursor = conn.cursor()
                    
                    # Ø­ÙØ¸ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
                    cursor.execute('''
                        INSERT INTO gold_analysis_history (
                            timestamp, signal, signal_strength, total_score, gold_price,
                            technical_score, news_sentiment_score, market_condition,
                            stop_loss, take_profit, rsi, macd_signal, bb_position,
                            volume_trend, news_articles_count, top_news, execution_time_ms
                        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                    ''', (
                        datetime.now().isoformat(),
                        signal_data.get('signal', 'Hold'),
                        signal_data.get('strength', 'Neutral'),
                        signal_data.get('total_score', 0),
                        signal_data.get('current_price', 0),
                        signal_data.get('technical_score', 0),
                        signal_data.get('news_score', 0),
                        signal_data.get('market_condition', 'normal'),
                        signal_data.get('stop_loss', 0),
                        signal_data.get('take_profit', 0),
                        signal_data.get('rsi', 50),
                        signal_data.get('macd_signal', 'Neutral'),
                        signal_data.get('bb_position', 0.5),
                        signal_data.get('volume_trend', 'Normal'),
                        news_data.get('articles_count', 0),
                        json.dumps([article['title'] for article in news_data.get('top_articles', [])[:5]], ensure_ascii=False),
                        execution_time
                    ))
                    
                    analysis_id = cursor.lastrowid
                    
                    # Ø­ÙØ¸ ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø£Ø®Ø¨Ø§Ø±
                    for article in news_data.get('top_articles', [])[:10]:
                        cursor.execute('''
                            INSERT INTO news_analysis_detail (
                                analysis_id, headline, source, sentiment_score,
                                ai_sentiment_score, relevance_score, published_at, url
                            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                        ''', (
                            analysis_id,
                            article.get('title', '')[:500],
                            article.get('source', '')[:100],
                            article.get('vader_sentiment', 0),
                            article.get('ai_sentiment', 0),
                            article.get('relevance_score', 0),
                            article.get('published_at', ''),
                            article.get('url', '')[:500]
                        ))
                    
                    conn.commit()
                    conn.close()
                    
                    logger.info(f"ğŸ’¾ ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ Ø§Ù„Ø³Ø¬Ù„ Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠ - ID: {analysis_id}")
                    return analysis_id
                    
                except Exception as e:
                    logger.error(f"âŒ ÙØ´Ù„ Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬: {e}")
                    return -1
        
            def run_comprehensive_analysis(self):
                """ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø´Ø§Ù…Ù„"""
                start_time = time.time()
                logger.info("ğŸš€ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø´Ø§Ù…Ù„ Ù„Ù„Ø°Ù‡Ø¨...")
                
                try:
                    # Ø¥Ø¹Ø¯Ø§Ø¯ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
                    self.setup_database()
                    
                    # ØªØ­Ù…ÙŠÙ„ Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
                    self.initialize_ai_models()
                    
                    # Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø³ÙˆÙ‚
                    if not self.fetch_enhanced_market_data():
                        raise Exception("ÙØ´Ù„ ÙÙŠ Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø³ÙˆÙ‚")
                    
                    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ÙÙ†ÙŠØ©
                    technical_data = self.calculate_advanced_technical_indicators()
                    if technical_data is None:
                        raise Exception("ÙØ´Ù„ ÙÙŠ Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ÙÙ†ÙŠØ©")
                    
                    # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø®Ø¨Ø§Ø±
                    news_data = self.analyze_specialized_news()
                    
                    # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ø§Ù„Ø´Ø§Ù…Ù„Ø©
                    signal_data = self.generate_comprehensive_signal(technical_data, news_data)
                    
                    # Ø­Ø³Ø§Ø¨ ÙˆÙ‚Øª Ø§Ù„ØªÙ†ÙÙŠØ°
                    execution_time = int((time.time() - start_time) * 1000)
                    
                    # Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
                    analysis_id = self.save_analysis_results(signal_data, technical_data, news_data, execution_time)
                    
                    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
                    final_report = {
                        'timestamp': datetime.now().isoformat(),
                        'analysis_id': analysis_id,
                        'execution_time_ms': execution_time,
                        'status': 'success',
                        'signal': signal_data,
                        'technical_analysis': {
                            'data_points': len(technical_data),
                            'current_price': signal_data.get('current_price', 0),
                            'rsi': signal_data.get('rsi', 0),
                            'macd_signal': signal_data.get('macd_signal', 'Neutral'),
                            'bb_position': signal_data.get('bb_position', 0.5),
                            'volume_trend': signal_data.get('volume_trend', 'Normal'),
                            'market_condition': signal_data.get('market_condition', 'normal')
                        },
                        'news_analysis': {
                            'status': news_data.get('status', 'unknown'),
                            'articles_count': news_data.get('articles_count', 0),
                            'sentiment_score': news_data.get('sentiment_score', 0),
                            'top_headlines': [article['title'] for article in news_data.get('top_articles', [])[:5]]
                        },
                        'risk_management': {
                            'stop_loss': signal_data.get('stop_loss', 0),
                            'take_profit': signal_data.get('take_profit', 0),
                            'risk_reward_ratio': round((signal_data.get('take_profit', 0) - signal_data.get('current_price', 0)) / 
                                                      (signal_data.get('current_price', 0) - signal_data.get('stop_loss', 0)), 2) 
                                                      if signal_data.get('stop_loss', 0) != signal_data.get('current_price', 0) else 0
                        }
                    }
                    
                    # Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
                    with open('gold_analysis_enhanced.json', 'w', encoding='utf-8') as f:
                        json.dump(final_report, f, ensure_ascii=False, indent=2, default=str)
                    
                    logger.info("âœ… ØªÙ… Ø¥Ù†Ø¬Ø§Ø² Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø´Ø§Ù…Ù„ Ø¨Ù†Ø¬Ø§Ø­")
                    
                    # Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„Ù…Ù„Ø®Øµ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
                    self._print_final_summary(signal_data, news_data)
                    
                    return final_report
                    
                except Exception as e:
                    logger.error(f"âŒ ÙØ´Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø´Ø§Ù…Ù„: {e}")
                    return {
                        'status': 'error',
                        'error': str(e),
                        'timestamp': datetime.now().isoformat()
                    }
        
            def _print_final_summary(self, signal_data, news_data):
                """Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„Ù…Ù„Ø®Øµ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ"""
                logger.info("")
                logger.info("=" * 60)
                logger.info("ğŸ“‹ Ù…Ù„Ø®Øµ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ")
                logger.info("=" * 60)
                logger.info(f"ğŸ¯ Ø§Ù„Ø¥Ø´Ø§Ø±Ø©: {signal_data.get('signal', 'N/A')} ({signal_data.get('strength', 'N/A')})")
                logger.info(f"ğŸ“Š Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ©: {signal_data.get('total_score', 0)}")
                logger.info(f"ğŸ’° Ø³Ø¹Ø± Ø§Ù„Ø°Ù‡Ø¨: ${signal_data.get('current_price', 0)}")
                logger.info(f"ğŸ›‘ ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø©: ${signal_data.get('stop_loss', 0)}")
                logger.info(f"ğŸ“ˆ Ø­Ø§Ù„Ø© Ø§Ù„Ø³ÙˆÙ‚: {signal_data.get('market_condition', 'normal')}")
                logger.info(f"ğŸ“° ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø®Ø¨Ø§Ø±: {news_data.get('status', 'unknown')} (Ø§Ù„Ù†ØªÙŠØ¬Ø©: {news_data.get('sentiment_score', 0)})")
        
        def main():
            """Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"""
            try:
                analyzer = AdvancedGoldAnalyzer()
                result = analyzer.run_comprehensive_analysis()
                
                if result.get('status') == 'success':
                    print("\nğŸ‰ ØªÙ… Ø­ÙØ¸ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙƒØ§Ù…Ù„ ÙÙŠ:")
                    print(" - gold_analysis_enhanced.json")
                    print(" - gold_analysis_history.db")
                    print(" - gold_analysis.log")
                    
                    # Ø·Ø¨Ø§Ø¹Ø© Ø£Ù‡Ù… Ø§Ù„Ø£Ø®Ø¨Ø§Ø±
                    news_headlines = result.get('news_analysis', {}).get('top_headlines', [])
                    if news_headlines:
                        print(f"\nğŸ“° Ø£Ù‡Ù… {len(news_headlines)} Ø£Ø®Ø¨Ø§Ø± Ù…ØªØ¹Ù„Ù‚Ø© Ø¨Ø§Ù„Ø°Ù‡Ø¨:")
                        for i, headline in enumerate(news_headlines, 1):
                            print(f" {i}. {headline[:80]}...")
                    
                    return 0
                else:
                    print(f"âŒ ÙØ´Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„: {result.get('error', 'Ø®Ø·Ø£ ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ')}")
                    return 1
                    
            except Exception as e:
                print(f"ğŸ’¥ Ø®Ø·Ø£ Ø­Ø±Ø¬: {e}")
                return 1
        
        if __name__ == "__main__":
            exit(main())
        EOF

    - name: ğŸ§  Execute Advanced Analysis
      id: analysis
      run: |
        echo "ğŸš€ Starting Advanced Gold Analysis..."
        timeout 900 python main_analyzer.py
        echo "analysis_status=success" >> $GITHUB_OUTPUT

    - name: ğŸ“Š Display Results
      if: steps.analysis.outputs.analysis_status == 'success'
      run: |
        if [ -f "gold_analysis_enhanced.json" ]; then
          echo "ğŸ‰ Advanced Analysis Results:"
          echo "=================================="
          
          python -c "
        import json
        
        with open('gold_analysis_enhanced.json', 'r') as f:
            data = json.load(f)
        
        signal = data['signal']
        technical = data['technical_analysis']
        news = data['news_analysis']
        
        print(f'ğŸ¯ Signal: {signal[\"signal\"]} ({signal[\"strength\"]})')
        print(f'ğŸ“Š Total Score: {signal[\"total_score\"]}')
        print(f'ğŸ’° Gold Price: \${signal[\"current_price\"]:,.2f}')
        print(f'ğŸ›‘ Stop Loss: \${signal[\"stop_loss\"]:,.2f}')
        print(f'ğŸ¯ Take Profit: \${signal[\"take_profit\"]:,.2f}')
        print(f'ğŸ“ˆ RSI: {signal[\"rsi\"]}')
        print(f'ğŸ“Š MACD: {signal[\"macd_signal\"]}')
        print(f'ğŸ“° News Articles: {news[\"articles_count\"]}')
        print(f'ğŸ“Š News Sentiment: {news[\"sentiment_score\"]:+.4f}')
        print(f'âš¡ Execution: {data[\"execution_time_ms\"]}ms')
        print(f'ğŸ†” Analysis ID: {data[\"analysis_id\"]}')
        "
        else
          echo "âŒ Results file not found"
        fi

    - name: ğŸ“ Create Enhanced README
      if: steps.analysis.outputs.analysis_status == 'success'
      run: |
        python -c "
        import json
        from datetime import datetime
        
        with open('gold_analysis_enhanced.json', 'r') as f:
            data = json.load(f)
        
        signal = data['signal']
        technical = data['technical_analysis']
        news = data['news_analysis']
        risk = data['risk_management']
        
        readme = f'''# ğŸ† Advanced Gold Analysis System
        
        **Generated:** {datetime.fromisoformat(data['timestamp']).strftime('%Y-%m-%d %H:%M:%S UTC')}
        
        ## ğŸ¯ Trading Signal
        
        **{signal['signal']}** - {signal['strength']}
        
        - **Total Score:** {signal['total_score']}
        - **Confidence:** {signal['confidence']:.1%}
        - **Technical Score:** {signal['technical_score']:+.3f}
        - **News Score:** {signal['news_score']:+.3f}
        
        ## ğŸ’° Market Data
        
        | Metric | Value |
        |--------|-------|
        | Gold Price | \${signal['current_price']:,.2f} |
        | RSI (14) | {signal['rsi']:.1f} |
        | MACD Signal | {signal['macd_signal']} |
        | Bollinger Position | {signal['bb_position']:.1%} |
        | Volume Trend | {signal['volume_trend']} |
        | Market Condition | {signal['market_condition'].replace('_', ' ').title()} |
        
        ## ğŸ”§ Risk Management
        
        - **Stop Loss:** \${signal['stop_loss']:,.2f}
        - **Take Profit:** \${signal['take_profit']:,.2f}
        - **Risk/Reward Ratio:** {risk['risk_reward_ratio']:.2f}
        
        ## ğŸ“° News Analysis
        
        - **Status:** {news['status'].title()}
        - **Articles Analyzed:** {news['articles_count']}
        - **Sentiment Score:** {news['sentiment_score']:+.4f}
        '''
        
        headlines = news.get('top_headlines', [])
        if headlines:
            readme += '''
        ## ğŸ“‹ Top Headlines
        '''
            for i, headline in enumerate(headlines, 1):
                readme += f'''
        {i}. {headline}
        '''
        
        readme += f'''
        
        ---
        
        **Analysis ID:** {data['analysis_id']} | **Execution:** {data['execution_time_ms']}ms | **Data Points:** {technical['data_points']}
        
        *Advanced AI-powered analysis with specialized financial sentiment models*
        '''
        
        with open('README.md', 'w', encoding='utf-8') as f:
            f.write(readme)
        
        print('âœ… Enhanced README created')
        "

    - name: ğŸ’¾ Commit Advanced Results
      if: steps.analysis.outputs.analysis_status == 'success'
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "ğŸ† Advanced Gold Analysis"
        
        git add gold_analysis_enhanced.json README.md
        git add gold_analysis_history.db gold_analysis.log
        
        if git diff --staged --quiet; then
          echo "âš ï¸ No changes to commit"
        else
          SIGNAL=$(python -c "import json; data=json.load(open('gold_analysis_enhanced.json')); print(f\"{data['signal']['signal']} ({data['signal']['total_score']})\")" 2>/dev/null || echo 'Advanced Analysis')
          
          git commit -m "ğŸ† Advanced Gold Analysis: $SIGNAL - $(date -u '+%Y-%m-%d %H:%M UTC')"
          git push
          echo "âœ… Advanced results pushed"
        fi

    - name: ğŸ“¤ Upload Complete Analysis
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: advanced-gold-analysis
        path: |
          gold_analysis_enhanced.json
          gold_analysis_history.db
          gold_analysis.log
          README.md
        retention-days: 90

    - name: ğŸ‰ Success Summary
      if: success()
      run: |
        echo "ğŸ† ADVANCED GOLD ANALYSIS COMPLETE!"
        echo "====================================="
        
        python -c "
        try:
            import json
            with open('gold_analysis_enhanced.json', 'r') as f:
                data = json.load(f)
            
            print(f'ğŸ¯ Final Signal: {data[\"signal\"][\"signal\"]} ({data[\"signal\"][\"strength\"]})')
            print(f'ğŸ“Š Total Score: {data[\"signal\"][\"total_score\"]}')
            print(f'ğŸ’° Gold Price: \${data[\"signal\"][\"current_price\"]:,.2f}')
            print(f'ğŸ“° News Articles: {data[\"news_analysis\"][\"articles_count\"]}')
            print(f'âš¡ Execution: {data[\"execution_time_ms\"]}ms')
            print(f'ğŸ†” Analysis ID: {data[\"analysis_id\"]}')
            print(f'\\nğŸ‰ Advanced AI analysis with specialized financial models!')
        except:
            print('âœ… Analysis completed successfully')
        "