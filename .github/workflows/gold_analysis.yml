name: ğŸ† Enhanced Gold Analysis (Fixed)
on:
  schedule:
    - cron: '30 13 * * 1-5'  # ÙŠÙˆÙ…ÙŠ
  workflow_dispatch:

env:
  NEWS_API_KEY: ${{ secrets.NEWS_API_KEY }}

jobs:
  enhanced-analysis:
    name: ğŸ§  Enhanced Gold Analysis
    runs-on: ubuntu-latest
    timeout-minutes: 10
    permissions:
      contents: write
    
    steps:
    - uses: actions/checkout@v4
    - uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        
    - name: ğŸ“¦ Install Core Packages
      run: |
        pip install --upgrade pip --quiet
        pip install --no-cache-dir --quiet yfinance pandas numpy requests vaderSentiment textblob nltk scikit-learn matplotlib
        
        python -c "
        import nltk
        try:
            nltk.download('punkt', quiet=True)
            nltk.download('vader_lexicon', quiet=True)
            print('âœ… NLTK ready')
        except:
            print('âš ï¸ NLTK skipped')
        "

    - name: ğŸ—ï¸ Create Fixed Gold Analyzer
      run: |
        cat > fixed_analyzer.py << 'EOF'
        #!/usr/bin/env python3
        """
        ğŸ† Ù…Ø­Ù„Ù„ Ø§Ù„Ø°Ù‡Ø¨ Ø§Ù„Ù…ØµØ­Ø­ - Fixed Version
        """
        
        import yfinance as yf
        import pandas as pd
        import numpy as np
        import requests
        import json
        import sqlite3
        import os
        import logging
        import warnings
        from datetime import datetime, timedelta
        from typing import Dict, List, Optional, Any
        import time
        from concurrent.futures import ThreadPoolExecutor, as_completed
        
        try:
            from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
            from textblob import TextBlob
            SENTIMENT_AVAILABLE = True
        except ImportError:
            SENTIMENT_AVAILABLE = False
        
        warnings.filterwarnings('ignore')
        
        # Setup logging
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('gold_analysis.log', encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
        logger = logging.getLogger(__name__)
        
        class FixedGoldAnalyzer:
            """Ù…Ø­Ù„Ù„ Ø§Ù„Ø°Ù‡Ø¨ Ø§Ù„Ù…ØµØ­Ø­"""
            
            def __init__(self):
                self.symbols = {
                    'gold_futures': 'GC=F',
                    'gold_etf': 'GLD', 
                    'silver_etf': 'SLV',
                    'dollar_index': 'DX-Y.NYB',
                    'vix': '^VIX',
                    'treasury_10y': '^TNX',
                    'sp500': 'SPY',
                    'oil': 'CL=F'
                }
                
                self.news_api_key = os.getenv('NEWS_API_KEY')
                self.db_path = 'gold_analysis_history.db'
                
                # Initialize sentiment analyzer
                self.sentiment_analyzer = SentimentIntensityAnalyzer() if SENTIMENT_AVAILABLE else None
                
                # Data storage
                self.market_data = None
                self.gold_data = None
                
                logger.info("ğŸš€ ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ù…Ø­Ù„Ù„ Ø§Ù„Ø°Ù‡Ø¨ Ø§Ù„Ù…ØµØ­Ø­ Ø¨Ù†Ø¬Ø§Ø­")
        
            def setup_database(self):
                """Ø¥Ø¹Ø¯Ø§Ø¯ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
                try:
                    conn = sqlite3.connect(self.db_path)
                    cursor = conn.cursor()
                    
                    cursor.execute('''
                        CREATE TABLE IF NOT EXISTS gold_analysis_history (
                            id INTEGER PRIMARY KEY AUTOINCREMENT,
                            timestamp TEXT NOT NULL,
                            signal TEXT NOT NULL,
                            signal_strength TEXT NOT NULL,
                            total_score REAL NOT NULL,
                            gold_price REAL,
                            technical_score REAL,
                            news_sentiment_score REAL,
                            market_condition TEXT,
                            stop_loss REAL,
                            take_profit REAL,
                            rsi REAL,
                            macd_signal TEXT,
                            bb_position REAL,
                            volume_trend TEXT,
                            news_articles_count INTEGER,
                            top_news TEXT,
                            execution_time_ms INTEGER,
                            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                        )
                    ''')
                    
                    cursor.execute('''
                        CREATE TABLE IF NOT EXISTS news_analysis_detail (
                            id INTEGER PRIMARY KEY AUTOINCREMENT,
                            analysis_id INTEGER,
                            headline TEXT,
                            source TEXT,
                            sentiment_score REAL,
                            relevance_score INTEGER,
                            published_at TEXT,
                            url TEXT,
                            FOREIGN KEY (analysis_id) REFERENCES gold_analysis_history (id)
                        )
                    ''')
                    
                    conn.commit()
                    conn.close()
                    logger.info("âœ… ØªÙ… Ø¥Ø¹Ø¯Ø§Ø¯ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ù†Ø¬Ø§Ø­")
                    
                except Exception as e:
                    logger.error(f"âŒ ÙØ´Ù„ Ø¥Ø¹Ø¯Ø§Ø¯ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {e}")
        
            def fetch_gold_data_safe(self) -> bool:
                """Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø°Ù‡Ø¨ Ø¨Ø·Ø±ÙŠÙ‚Ø© Ø¢Ù…Ù†Ø© - FIXED"""
                logger.info("ğŸ“Š Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø°Ù‡Ø¨...")
                
                try:
                    # Try GLD first (most reliable)
                    for symbol in ['GLD', 'GC=F']:
                        try:
                            logger.info(f"ğŸ”„ Ù…Ø­Ø§ÙˆÙ„Ø© Ø¬Ù„Ø¨ {symbol}...")
                            data = yf.download(symbol, period='1y', interval='1d', progress=False)
                            
                            if data is not None and not data.empty and len(data) > 50:
                                self.gold_data = data
                                logger.info(f"âœ… ØªÙ… Ø¬Ù„Ø¨ {len(data)} ÙŠÙˆÙ… Ù…Ù† Ø¨ÙŠØ§Ù†Ø§Øª {symbol}")
                                return True
                        except Exception as e:
                            logger.warning(f"âš ï¸ ÙØ´Ù„ ÙÙŠ Ø¬Ù„Ø¨ {symbol}: {e}")
                            continue
                    
                    logger.error("âŒ ÙØ´Ù„ ÙÙŠ Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø°Ù‡Ø¨ Ù…Ù† Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ØµØ§Ø¯Ø±")
                    return False
                    
                except Exception as e:
                    logger.error(f"âŒ Ø®Ø·Ø£ Ø¹Ø§Ù… ÙÙŠ Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {e}")
                    return False
        
            def calculate_technical_indicators_fixed(self):
                """Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ÙÙ†ÙŠØ© - FIXED"""
                logger.info("ğŸ“ˆ Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ÙÙ†ÙŠØ©...")
                
                if self.gold_data is None or self.gold_data.empty:
                    logger.error("âŒ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø°Ù‡Ø¨")
                    return None
                
                try:
                    df = self.gold_data.copy()
                    
                    # Ensure required columns exist
                    required_cols = ['Open', 'High', 'Low', 'Close', 'Volume']
                    for col in required_cols:
                        if col not in df.columns:
                            if 'Close' in df.columns:
                                df[col] = df['Close']  # Use Close as fallback
                            else:
                                logger.error(f"âŒ Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: {col}")
                                return None
                    
                    # FIXED: Calculate EMAs needed for MACD FIRST
                    df['EMA_12'] = df['Close'].ewm(span=12).mean()
                    df['EMA_26'] = df['Close'].ewm(span=26).mean()
                    
                    # Moving Averages
                    for period in [5, 10, 20, 50, 100, 200]:
                        df[f'SMA_{period}'] = df['Close'].rolling(period, min_periods=1).mean()
                        if period not in [12, 26]:  # Skip if already calculated
                            df[f'EMA_{period}'] = df['Close'].ewm(span=period).mean()
                    
                    # RSI Calculation
                    def safe_rsi(prices, period=14):
                        delta = prices.diff()
                        gain = delta.where(delta > 0, 0).rolling(period, min_periods=1).mean()
                        loss = (-delta.where(delta < 0, 0)).rolling(period, min_periods=1).mean()
                        rs = gain / loss.replace(0, np.inf)
                        rsi = 100 - (100 / (1 + rs))
                        return rsi.fillna(50)  # Fill NaN with neutral 50
                    
                    df['RSI'] = safe_rsi(df['Close'])
                    
                    # MACD - Now safe to calculate
                    df['MACD'] = df['EMA_12'] - df['EMA_26']
                    df['MACD_Signal'] = df['MACD'].ewm(span=9).mean()
                    df['MACD_Histogram'] = df['MACD'] - df['MACD_Signal']
                    
                    # Bollinger Bands
                    df['BB_Middle'] = df['Close'].rolling(20, min_periods=1).mean()
                    df['BB_Std'] = df['Close'].rolling(20, min_periods=1).std().fillna(0)
                    df['BB_Upper'] = df['BB_Middle'] + (df['BB_Std'] * 2)
                    df['BB_Lower'] = df['BB_Middle'] - (df['BB_Std'] * 2)
                    
                    # Safe BB Position calculation
                    bb_range = df['BB_Upper'] - df['BB_Lower']
                    df['BB_Position'] = np.where(bb_range > 0, 
                                                (df['Close'] - df['BB_Lower']) / bb_range, 
                                                0.5)
                    
                    # Stochastic
                    def safe_stochastic(high, low, close, k_period=14):
                        lowest_low = low.rolling(k_period, min_periods=1).min()
                        highest_high = high.rolling(k_period, min_periods=1).max()
                        stoch_range = highest_high - lowest_low
                        k_percent = np.where(stoch_range > 0,
                                           100 * (close - lowest_low) / stoch_range,
                                           50)
                        return pd.Series(k_percent, index=close.index)
                    
                    df['Stoch_K'] = safe_stochastic(df['High'], df['Low'], df['Close'])
                    df['Stoch_D'] = df['Stoch_K'].rolling(3, min_periods=1).mean()
                    
                    # Williams %R
                    def safe_williams_r(high, low, close, period=14):
                        highest_high = high.rolling(period, min_periods=1).max()
                        lowest_low = low.rolling(period, min_periods=1).min()
                        wr_range = highest_high - lowest_low
                        williams_r = np.where(wr_range > 0,
                                            -100 * (highest_high - close) / wr_range,
                                            -50)
                        return pd.Series(williams_r, index=close.index)
                    
                    df['Williams_R'] = safe_williams_r(df['High'], df['Low'], df['Close'])
                    
                    # ATR
                    def safe_atr(high, low, close, period=14):
                        tr1 = high - low
                        tr2 = abs(high - close.shift(1))
                        tr3 = abs(low - close.shift(1))
                        tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)
                        return tr.rolling(period, min_periods=1).mean().fillna(close * 0.02)
                    
                    df['ATR'] = safe_atr(df['High'], df['Low'], df['Close'])
                    
                    # Volume indicators
                    df['Volume_SMA'] = df['Volume'].rolling(20, min_periods=1).mean()
                    df['Volume_Ratio'] = df['Volume'] / df['Volume_SMA'].replace(0, 1)
                    
                    # Additional indicators
                    df['Volatility'] = df['Close'].pct_change().rolling(20, min_periods=1).std().fillna(0.2) * np.sqrt(252)
                    df['Support'] = df['Low'].rolling(20, min_periods=1).min()
                    df['Resistance'] = df['High'].rolling(20, min_periods=1).max()
                    
                    # Clean and validate data
                    df = df.fillna(method='ffill').fillna(method='bfill')
                    
                    if df.empty:
                        logger.error("âŒ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙØ§Ø±ØºØ© Ø¨Ø¹Ø¯ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©")
                        return None
                    
                    self.gold_data = df
                    logger.info(f"âœ… ØªÙ… Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ÙÙ†ÙŠØ© - Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {len(df)} ØµÙ")
                    return df
                    
                except Exception as e:
                    logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ÙÙ†ÙŠØ©: {e}")
                    import traceback
                    traceback.print_exc()
                    return None
        
            def analyze_news_sentiment_simple(self) -> Dict[str, Any]:
                """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ù…Ø¨Ø³Ø·"""
                logger.info("ğŸ“° ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø®Ø¨Ø§Ø±...")
                
                if not self.news_api_key or not SENTIMENT_AVAILABLE:
                    return {
                        'status': 'disabled',
                        'sentiment_score': 0,
                        'articles_count': 0,
                        'top_articles': [],
                        'summary': 'ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± ØºÙŠØ± Ù…ØªØ§Ø­'
                    }
                
                try:
                    # Simple queries
                    queries = [
                        'gold price market',
                        'federal reserve interest rates gold',
                        'inflation dollar gold precious metals',
                        'geopolitical safe haven gold'
                    ]
                    
                    all_articles = []
                    
                    for query in queries:
                        try:
                            url = f"https://newsapi.org/v2/everything?q={query}&language=en&sortBy=publishedAt&pageSize=25&from={(datetime.now() - timedelta(days=2)).date()}&apiKey={self.news_api_key}"
                            
                            response = requests.get(url, timeout=10)
                            if response.status_code == 200:
                                articles = response.json().get('articles', [])
                                all_articles.extend(articles)
                                logger.info(f"ğŸ“¥ Ø¬Ù„Ø¨ {len(articles)} Ù…Ù‚Ø§Ù„")
                            else:
                                logger.warning(f"âš ï¸ Ø®Ø·Ø£ API: {response.status_code}")
                        except Exception as e:
                            logger.warning(f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…: {e}")
                            continue
                    
                    if not all_articles:
                        return {
                            'status': 'no_articles',
                            'sentiment_score': 0,
                            'articles_count': 0,
                            'top_articles': [],
                            'summary': 'Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ù‚Ø§Ù„Ø§Øª'
                        }
                    
                    # Remove duplicates
                    unique_articles = []
                    seen_urls = set()
                    
                    for article in all_articles:
                        url = article.get('url', '')
                        title = article.get('title', '')
                        
                        if url not in seen_urls and len(title) > 15:
                            seen_urls.add(url)
                            unique_articles.append(article)
                    
                    # Filter relevant articles
                    gold_keywords = ['gold', 'xau', 'bullion', 'precious', 'fed', 'federal reserve', 
                                   'interest rate', 'inflation', 'dollar', 'safe haven', 'crisis']
                    
                    relevant_articles = []
                    
                    for article in unique_articles[:40]:
                        title = article.get('title', '').lower()
                        description = article.get('description', '').lower() if article.get('description') else ''
                        content = f"{title} {description}"
                        
                        relevance = sum(1 for keyword in gold_keywords if keyword in content)
                        
                        if relevance >= 2:
                            article['relevance_score'] = relevance
                            relevant_articles.append(article)
                    
                    if not relevant_articles:
                        return {
                            'status': 'no_relevant',
                            'sentiment_score': 0,
                            'articles_count': 0,
                            'top_articles': [],
                            'summary': 'Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ù‚Ø§Ù„Ø§Øª Ø°Ø§Øª ØµÙ„Ø©'
                        }
                    
                    # Sentiment analysis
                    analyzed_articles = []
                    sentiment_scores = []
                    
                    for article in relevant_articles:
                        try:
                            title = article.get('title', '')
                            description = article.get('description', '') or ''
                            text = f"{title}. {description}"
                            
                            # VADER sentiment
                            vader_score = 0
                            if self.sentiment_analyzer:
                                result = self.sentiment_analyzer.polarity_scores(text)
                                vader_score = result['compound']
                            
                            # TextBlob sentiment
                            try:
                                blob = TextBlob(text)
                                textblob_score = blob.sentiment.polarity
                            except:
                                textblob_score = vader_score
                            
                            # Combined score
                            combined_score = (vader_score * 0.6 + textblob_score * 0.4)
                            
                            # Weight by relevance
                            final_score = combined_score * min(article['relevance_score'] / 4, 1.0)
                            
                            analyzed_article = {
                                'title': title[:100],
                                'source': article.get('source', {}).get('name', 'Unknown')[:50],
                                'published_at': article.get('publishedAt', ''),
                                'relevance_score': article['relevance_score'],
                                'sentiment_score': round(final_score, 3),
                                'vader_score': round(vader_score, 3),
                                'textblob_score': round(textblob_score, 3)
                            }
                            
                            analyzed_articles.append(analyzed_article)
                            sentiment_scores.append(final_score)
                            
                        except Exception as e:
                            logger.warning(f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù‚Ø§Ù„: {e}")
                            continue
                    
                    if not sentiment_scores:
                        return {
                            'status': 'analysis_failed',
                            'sentiment_score': 0,
                            'articles_count': 0,
                            'top_articles': []
                        }
                    
                    # Calculate results
                    overall_sentiment = np.mean(sentiment_scores)
                    positive_count = len([s for s in sentiment_scores if s > 0.1])
                    negative_count = len([s for s in sentiment_scores if s < -0.1])
                    
                    # Sort by impact
                    analyzed_articles.sort(key=lambda x: (x['relevance_score'], abs(x['sentiment_score'])), reverse=True)
                    
                    logger.info(f"ğŸ“Š ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ù…ÙƒØªÙ…Ù„: {overall_sentiment:.3f}")
                    
                    return {
                        'status': 'success',
                        'sentiment_score': round(overall_sentiment, 4),
                        'articles_count': len(analyzed_articles),
                        'positive_count': positive_count,
                        'negative_count': negative_count,
                        'neutral_count': len(analyzed_articles) - positive_count - negative_count,
                        'top_articles': analyzed_articles[:10],
                        'summary': f"ØªÙ… ØªØ­Ù„ÙŠÙ„ {len(analyzed_articles)} Ù…Ù‚Ø§Ù„Ø§Ù‹: {positive_count} Ø¥ÙŠØ¬Ø§Ø¨ÙŠØŒ {negative_count} Ø³Ù„Ø¨ÙŠ"
                    }
                    
                except Exception as e:
                    logger.error(f"âŒ ÙØ´Ù„ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø®Ø¨Ø§Ø±: {e}")
                    return {
                        'status': 'error',
                        'error': str(e),
                        'sentiment_score': 0,
                        'articles_count': 0,
                        'top_articles': []
                    }
        
            def generate_trading_signal(self, technical_data, news_data) -> Dict[str, Any]:
                """ØªÙˆÙ„ÙŠØ¯ Ø¥Ø´Ø§Ø±Ø© Ø§Ù„ØªØ¯Ø§ÙˆÙ„"""
                try:
                    if technical_data is None or technical_data.empty:
                        return {
                            'signal': 'Hold',
                            'strength': 'Neutral',
                            'total_score': 0,
                            'confidence': 0
                        }
                    
                    latest = technical_data.iloc[-1]
                    
                    # Technical score (70%)
                    tech_score = 0
                    
                    # Trend analysis
                    current_price = latest['Close']
                    sma_20 = latest['SMA_20']
                    sma_50 = latest['SMA_50']
                    sma_200 = latest['SMA_200'] if 'SMA_200' in latest else sma_50
                    
                    if current_price > sma_200: tech_score += 3
                    if current_price > sma_50: tech_score += 2
                    if current_price > sma_20: tech_score += 1.5
                    if sma_20 > sma_50: tech_score += 1
                    
                    # Momentum analysis
                    rsi = latest['RSI']
                    macd = latest['MACD']
                    macd_signal = latest['MACD_Signal']
                    
                    if macd > macd_signal: tech_score += 2
                    if 30 <= rsi <= 70: tech_score += 1
                    elif rsi < 30: tech_score += 2  # Oversold
                    elif rsi > 70: tech_score -= 1  # Overbought
                    
                    # Volatility analysis
                    bb_position = latest['BB_Position']
                    if bb_position < 0.2: tech_score += 1.5
                    elif bb_position > 0.8: tech_score -= 0.5
                    
                    # Volume analysis
                    volume_ratio = latest['Volume_Ratio']
                    if volume_ratio > 1.5: tech_score += 0.5
                    
                    # Normalize technical score
                    tech_score_norm = max(-1, min(1, (tech_score - 5) / 6))
                    
                    # News score (30%)
                    news_score_norm = 0
                    if news_data.get('status') == 'success':
                        news_score = news_data.get('sentiment_score', 0)
                        article_count = news_data.get('articles_count', 0)
                        count_weight = min(1.0, article_count / 20)
                        news_score_norm = news_score * count_weight
                    
                    # Total score
                    total_score = (tech_score_norm * 0.7) + (news_score_norm * 0.3)
                    
                    # Determine signal
                    if total_score >= 0.6:
                        signal, strength = 'Strong Buy', 'Very Strong'
                    elif total_score >= 0.3:
                        signal, strength = 'Buy', 'Strong'
                    elif total_score >= 0.1:
                        signal, strength = 'Buy', 'Moderate'
                    elif total_score <= -0.6:
                        signal, strength = 'Strong Sell', 'Very Strong'
                    elif total_score <= -0.3:
                        signal, strength = 'Sell', 'Strong'
                    elif total_score <= -0.1:
                        signal, strength = 'Sell', 'Moderate'
                    else:
                        signal, strength = 'Hold', 'Neutral'
                    
                    # Confidence
                    confidence = min(1.0, abs(total_score) + 0.2)
                    
                    # Risk management
                    atr = latest['ATR']
                    
                    if 'Buy' in signal:
                        stop_loss = current_price - (2.5 * atr)
                        take_profit = current_price + (4.0 * atr)
                    elif 'Sell' in signal:
                        stop_loss = current_price + (2.5 * atr)
                        take_profit = current_price - (4.0 * atr)
                    else:
                        stop_loss = current_price - (1.5 * atr)
                        take_profit = current_price + (2.5 * atr)
                    
                    return {
                        'signal': signal,
                        'strength': strength,
                        'total_score': round(total_score, 4),
                        'technical_score': round(tech_score_norm, 4),
                        'news_score': round(news_score_norm, 4),
                        'confidence': round(confidence, 3),
                        'current_price': round(current_price, 2),
                        'stop_loss': round(stop_loss, 2),
                        'take_profit': round(take_profit, 2),
                        'rsi': round(rsi, 1),
                        'macd_signal': 'Bullish' if macd > macd_signal else 'Bearish',
                        'bb_position': round(bb_position, 3),
                        'volume_trend': 'High' if volume_ratio > 1.5 else 'Normal',
                        'market_condition': self._assess_market_condition(technical_data)
                    }
                    
                except Exception as e:
                    logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¥Ø´Ø§Ø±Ø©: {e}")
                    return {
                        'signal': 'Hold',
                        'strength': 'Neutral',
                        'total_score': 0,
                        'confidence': 0
                    }
        
            def _assess_market_condition(self, technical_data) -> str:
                """ØªÙ‚ÙŠÙŠÙ… Ø­Ø§Ù„Ø© Ø§Ù„Ø³ÙˆÙ‚"""
                try:
                    latest = technical_data.iloc[-1]
                    volatility = latest.get('Volatility', 0.2)
                    
                    if volatility > 0.30:
                        return 'high_volatility'
                    elif volatility < 0.15:
                        return 'low_volatility'
                    else:
                        return 'normal'
                except:
                    return 'normal'
        
            def save_results(self, signal_data, technical_data, news_data, execution_time) -> int:
                """Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬"""
                try:
                    conn = sqlite3.connect(self.db_path)
                    cursor = conn.cursor()
                    
                    cursor.execute('''
                        INSERT INTO gold_analysis_history (
                            timestamp, signal, signal_strength, total_score, gold_price,
                            technical_score, news_sentiment_score, market_condition,
                            stop_loss, take_profit, rsi, macd_signal, bb_position,
                            volume_trend, news_articles_count, top_news, execution_time_ms
                        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                    ''', (
                        datetime.now().isoformat(),
                        signal_data.get('signal', 'Hold'),
                        signal_data.get('strength', 'Neutral'),
                        signal_data.get('total_score', 0),
                        signal_data.get('current_price', 0),
                        signal_data.get('technical_score', 0),
                        signal_data.get('news_score', 0),
                        signal_data.get('market_condition', 'normal'),
                        signal_data.get('stop_loss', 0),
                        signal_data.get('take_profit', 0),
                        signal_data.get('rsi', 50),
                        signal_data.get('macd_signal', 'Neutral'),
                        signal_data.get('bb_position', 0.5),
                        signal_data.get('volume_trend', 'Normal'),
                        news_data.get('articles_count', 0),
                        json.dumps([article['title'] for article in news_data.get('top_articles', [])[:5]], ensure_ascii=False),
                        execution_time
                    ))
                    
                    analysis_id = cursor.lastrowid
                    
                    # Save news details
                    for article in news_data.get('top_articles', [])[:10]:
                        cursor.execute('''
                            INSERT INTO news_analysis_detail (
                                analysis_id, headline, source, sentiment_score,
                                relevance_score, published_at, url
                            ) VALUES (?, ?, ?, ?, ?, ?, ?)
                        ''', (
                            analysis_id,
                            article.get('title', '')[:300],
                            article.get('source', '')[:100],
                            article.get('sentiment_score', 0),
                            article.get('relevance_score', 0),
                            article.get('published_at', ''),
                            article.get('url', '')[:300] if 'url' in article else ''
                        ))
                    
                    conn.commit()
                    conn.close()
                    
                    logger.info(f"ğŸ’¾ ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ - ID: {analysis_id}")
                    return analysis_id
                    
                except Exception as e:
                    logger.error(f"âŒ ÙØ´Ù„ Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬: {e}")
                    return -1
        
            def run_complete_analysis(self):
                """ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙƒØ§Ù…Ù„ - FIXED"""
                start_time = time.time()
                logger.info("ğŸš€ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø´Ø§Ù…Ù„ Ù„Ù„Ø°Ù‡Ø¨...")
                
                try:
                    # Setup
                    self.setup_database()
                    
                    # Fetch data
                    if not self.fetch_gold_data_safe():
                        raise Exception("ÙØ´Ù„ ÙÙŠ Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø°Ù‡Ø¨")
                    
                    # Technical analysis
                    logger.info("ğŸ“ˆ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙÙ†ÙŠ...")
                    technical_data = self.calculate_technical_indicators_fixed()
                    if technical_data is None:
                        raise Exception("ÙØ´Ù„ ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙÙ†ÙŠ")
                    
                    # News analysis
                    logger.info("ğŸ“° ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø®Ø¨Ø§Ø±...")
                    news_data = self.analyze_news_sentiment_simple()
                    
                    # Generate signal
                    logger.info("ğŸ¯ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¥Ø´Ø§Ø±Ø©...")
                    signal_data = self.generate_trading_signal(technical_data, news_data)
                    
                    # Calculate execution time
                    execution_time = int((time.time() - start_time) * 1000)
                    
                    # Save results
                    analysis_id = self.save_results(signal_data, technical_data, news_data, execution_time)
                    
                    # Create final report
                    final_report = {
                        'timestamp': datetime.now().isoformat(),
                        'analysis_id': analysis_id,
                        'execution_time_ms': execution_time,
                        'status': 'success',
                        'signal': signal_data,
                        'technical_analysis': {
                            'data_points': len(technical_data),
                            'current_price': signal_data.get('current_price', 0),
                            'rsi': signal_data.get('rsi', 0),
                            'macd_signal': signal_data.get('macd_signal', 'Neutral'),
                            'bb_position': signal_data.get('bb_position', 0.5),
                            'volume_trend': signal_data.get('volume_trend', 'Normal'),
                            'market_condition': signal_data.get('market_condition', 'normal')
                        },
                        'news_analysis': news_data,
                        'risk_management': {
                            'stop_loss': signal_data.get('stop_loss', 0),
                            'take_profit': signal_data.get('take_profit', 0),
                            'risk_reward_ratio': round((signal_data.get('take_profit', 0) - signal_data.get('current_price', 0)) / 
                                                      max(abs(signal_data.get('current_price', 0) - signal_data.get('stop_loss', 0)), 1), 2)
                        }
                    }
                    
                    # Save report
                    with open('gold_analysis_enhanced.json', 'w', encoding='utf-8') as f:
                        json.dump(final_report, f, ensure_ascii=False, indent=2, default=str)
                    
                    logger.info("âœ… ØªÙ… Ø¥Ù†Ø¬Ø§Ø² Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø´Ø§Ù…Ù„ Ø¨Ù†Ø¬Ø§Ø­")
                    self._print_summary(signal_data, news_data)
                    
                    return final_report
                    
                except Exception as e:
                    logger.error(f"âŒ ÙØ´Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø´Ø§Ù…Ù„: {e}")
                    return {
                        'status': 'error',
                        'error': str(e),
                        'timestamp': datetime.now().isoformat()
                    }
        
            def _print_summary(self, signal_data, news_data):
                """Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„Ù…Ù„Ø®Øµ"""
                logger.info("")
                logger.info("=" * 60)
                logger.info("ğŸ“‹ Ù…Ù„Ø®Øµ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ")
                logger.info("=" * 60)
                logger.info(f"ğŸ¯ Ø§Ù„Ø¥Ø´Ø§Ø±Ø©: {signal_data.get('signal', 'N/A')} ({signal_data.get('strength', 'N/A')})")
                logger.info(f"ğŸ“Š Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ©: {signal_data.get('total_score', 0)}")
                logger.info(f"ğŸ’° Ø³Ø¹Ø± Ø§Ù„Ø°Ù‡Ø¨: ${signal_data.get('current_price', 0):,.2f}")
                logger.info(f"ğŸ›‘ ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø©: ${signal_data.get('stop_loss', 0):,.2f}")
                logger.info(f"ğŸ“ˆ Ø­Ø§Ù„Ø© Ø§Ù„Ø³ÙˆÙ‚: {signal_data.get('market_condition', 'normal')}")
                logger.info(f"ğŸ“° ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø®Ø¨Ø§Ø±: {news_data.get('status', 'unknown')} (Ø§Ù„Ù†ØªÙŠØ¬Ø©: {news_data.get('sentiment_score', 0)})")
        
        def main():
            """Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"""
            try:
                print("ğŸ† Ù…Ø­Ù„Ù„ Ø§Ù„Ø°Ù‡Ø¨ Ø§Ù„Ù…ØµØ­Ø­ - Fixed Gold Analyzer")
                print("=" * 60)
                
                analyzer = FixedGoldAnalyzer()
                result = analyzer.run_complete_analysis()
                
                if result.get('status') == 'success':
                    print("\nğŸ‰ ØªÙ… Ø­ÙØ¸ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙƒØ§Ù…Ù„ ÙÙŠ:")
                    print(" - gold_analysis_enhanced.json")
                    print(" - gold_analysis_history.db")
                    print(" - gold_analysis.log")
                    
                    # Display top headlines
                    news_data = result.get('news_analysis', {})
                    if news_data.get('top_articles'):
                        headlines = [article['title'] for article in news_data['top_articles'][:5]]
                        print(f"\nğŸ“° Ø£Ù‡Ù… {len(headlines)} Ø£Ø®Ø¨Ø§Ø± Ù…ØªØ¹Ù„Ù‚Ø© Ø¨Ø§Ù„Ø°Ù‡Ø¨:")
                        for i, headline in enumerate(headlines, 1):
                            print(f" {i}. {headline}")
                    
                    return 0
                else:
                    print(f"âŒ ÙØ´Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„: {result.get('error', 'Ø®Ø·Ø£ ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ')}")
                    return 1
                    
            except Exception as e:
                print(f"ğŸ’¥ Ø®Ø·Ø£ Ø­Ø±Ø¬: {e}")
                return 1
        
        if __name__ == "__main__":
            exit(main())
        EOF

    - name: ğŸš€ Execute Fixed Analysis
      id: analysis
      run: |
        echo "ğŸš€ Starting Fixed Gold Analysis..."
        timeout 600 python fixed_analyzer.py
        echo "analysis_status=success" >> $GITHUB_OUTPUT

    - name: ğŸ“Š Display Fixed Results
      if: steps.analysis.outputs.analysis_status == 'success'
      run: |
        if [ -f "gold_analysis_enhanced.json" ]; then
          echo "ğŸ‰ Fixed Analysis Results:"
          echo "=========================="
          
          python -c "
        import json
        
        with open('gold_analysis_enhanced.json', 'r') as f:
            data = json.load(f)
        
        signal = data['signal']
        technical = data['technical_analysis']
        news = data['news_analysis']
        risk = data['risk_management']
        
        print(f'ğŸ¯ Signal: {signal[\"signal\"]} ({signal[\"strength\"]})')
        print(f'ğŸ“Š Total Score: {signal[\"total_score\"]}')
        print(f'ğŸ’° Gold Price: \${signal[\"current_price\"]:,.2f}')
        print(f'ğŸ›‘ Stop Loss: \${risk[\"stop_loss\"]:,.2f}')
        print(f'ğŸ¯ Take Profit: \${risk[\"take_profit\"]:,.2f}')
        print(f'ğŸ“ˆ RSI: {signal[\"rsi\"]}')
        print(f'ğŸ“Š MACD: {signal[\"macd_signal\"]}')
        print(f'ğŸ“° News Articles: {news[\"articles_count\"]}')
        print(f'ğŸ“Š News Sentiment: {news[\"sentiment_score\"]:+.4f}')
        print(f'âš¡ Execution: {data[\"execution_time_ms\"]}ms')
        print(f'ğŸ†” Analysis ID: {data[\"analysis_id\"]}')
        "
        else
          echo "âŒ Results file not found"
        fi

    - name: ğŸ“ Create README
      if: steps.analysis.outputs.analysis_status == 'success'
      run: |
        python -c "
        import json
        from datetime import datetime
        
        with open('gold_analysis_enhanced.json', 'r') as f:
            data = json.load(f)
        
        signal = data['signal']
        technical = data['technical_analysis']
        news = data['news_analysis']
        risk = data['risk_management']
        
        readme = f'''# ğŸ† Enhanced Gold Analysis System (Fixed)
        
        **Generated:** {datetime.fromisoformat(data['timestamp']).strftime('%Y-%m-%d %H:%M:%S UTC')}
        
        ## ğŸ¯ Trading Signal
        
        **{signal['signal']}** - {signal['strength']}
        
        - **Total Score:** {signal['total_score']}
        - **Confidence:** {signal['confidence']:.1%}
        - **Technical Score:** {signal['technical_score']:+.3f}
        - **News Score:** {signal['news_score']:+.3f}
        
        ## ğŸ’° Market Data
        
        | Metric | Value |
        |--------|-------|
        | Gold Price | \${signal['current_price']:,.2f} |
        | RSI (14) | {signal['rsi']:.1f} |
        | MACD Signal | {signal['macd_signal']} |
        | Bollinger Position | {signal['bb_position']:.1%} |
        | Volume Trend | {signal['volume_trend']} |
        | Market Condition | {signal['market_condition'].replace('_', ' ').title()} |
        
        ## ğŸ”§ Risk Management
        
        - **Stop Loss:** \${risk['stop_loss']:,.2f}
        - **Take Profit:** \${risk['take_profit']:,.2f}
        - **Risk/Reward Ratio:** {risk['risk_reward_ratio']:.2f}
        
        ## ğŸ“° News Analysis
        
        - **Status:** {news['status'].title()}
        - **Articles Analyzed:** {news['articles_count']}
        - **Sentiment Score:** {news['sentiment_score']:+.4f}
        - **Positive/Negative:** {news.get('positive_count', 0)}/{news.get('negative_count', 0)}
        '''
        
        if news.get('top_articles'):
            headlines = [article['title'] for article in news['top_articles'][:5]]
            readme += '''
        ## ğŸ“‹ Top Headlines
        '''
            for i, headline in enumerate(headlines, 1):
                readme += f'''
        {i}. {headline}
        '''
        
        readme += f'''
        
        ---
        
        **Analysis ID:** {data['analysis_id']} | **Execution:** {data['execution_time_ms']}ms | **Data Points:** {technical['data_points']}
        
        *Fixed version with robust error handling and comprehensive analysis*
        '''
        
        with open('README.md', 'w', encoding='utf-8') as f:
            f.write(readme)
        
        print('âœ… README created successfully')
        "

    - name: ğŸ’¾ Commit Fixed Results
      if: steps.analysis.outputs.analysis_status == 'success'
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "ğŸ† Fixed Gold Analysis"
        
        git add gold_analysis_enhanced.json README.md
        git add gold_analysis_history.db gold_analysis.log
        
        if git diff --staged --quiet; then
          echo "âš ï¸ No changes to commit"
        else
          SIGNAL=$(python -c "import json; print(json.load(open('gold_analysis_enhanced.json'))['signal']['signal'])" 2>/dev/null || echo 'Fixed Analysis')
          PRICE=$(python -c "import json; print(f\"\${json.load(open('gold_analysis_enhanced.json'))['signal']['current_price']:,.0f}\")" 2>/dev/null || echo '\$0')
          
          git commit -m "ğŸ† Fixed Gold Analysis: $SIGNAL @ $PRICE - $(date -u '+%Y-%m-%d %H:%M UTC')"
          git push
          echo "âœ… Fixed results committed"
        fi

    - name: ğŸ“¤ Upload Fixed Analysis
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: fixed-gold-analysis
        path: |
          gold_analysis_enhanced.json
          gold_analysis_history.db
          gold_analysis.log
          README.md
        retention-days: 60

    - name: ğŸ‰ Fixed Success Summary
      if: success()
      run: |
        echo "ğŸ† FIXED GOLD ANALYSIS COMPLETE!"
        echo "================================="
        
        python -c "
        try:
            import json
            with open('gold_analysis_enhanced.json', 'r') as f:
                data = json.load(f)
            
            signal = data['signal']
            news = data['news_analysis']
            
            print(f'ğŸ¯ Final Signal: {signal[\"signal\"]} ({signal[\"strength\"]})')
            print(f'ğŸ“Š Total Score: {signal[\"total_score\"]}')
            print(f'ğŸ’° Gold Price: \${signal[\"current_price\"]:,.2f}')
            print(f'ğŸ“° News Articles: {news[\"articles_count\"]}')
            print(f'ğŸ’­ News Sentiment: {news[\"sentiment_score\"]:+.4f}')
            print(f'âš¡ Execution: {data[\"execution_time_ms\"]}ms')
            print(f'ğŸ†” Analysis ID: {data[\"analysis_id\"]}')
            print(f'\\nğŸ‰ Fixed version working perfectly!')
        except Exception as e:
            print(f'âœ… Analysis completed (summary error: {e})')
        "